{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_house_db = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ...,\n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]), 'frame': None, 'target_names': ['MedHouseVal'], 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(ca_house_db.data.shape)\n",
    "print(ca_house_db.target.shape)\n",
    "print(ca_house_db.feature_names)\n",
    "print(ca_house_db.DESCR)\n",
    "print(ca_house_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:  2.4.1\n",
      "Hub bersion:  0.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error \n",
    "\n",
    "print(\"version: \", tf.__version__)\n",
    "print(\"Hub bersion: \", hub.__version__)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ca_house_db.target\n",
    "X = ca_house_db.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 1 Data splitting################################\n",
    "#split samples into two halves (traning process and testing process)\n",
    "X_1, X_test, Y_1, Y_test = train_test_split(X,Y,train_size = 0.5,random_state = 0)\n",
    "#subset of 2064 samples for validation purpose and the rest 8256 samples for training\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_1,Y_1,train_size = (8256/X_1.shape[0]),random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10320, 8) (10320, 8) (10320,) (8256, 8) (2064, 8) (8256,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape, X_test.shape, Y_1.shape, X_train.shape,X_valid.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 2 Model selection################################\n",
    "#Apecify at least three sets of hyper-parameters \n",
    "#Parameter includes 1.number of hidden layers 2.learning rate 3.activation fn\n",
    "# define the keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "seed_value = 0\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model1.add(Dense(15,activation='relu')) #hidden layer2\n",
    "model1.add(Dense(1)) #outputlayer\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model2.add(Dense(15,activation='sigmoid')) #hidden layer2, activation fn = \"sigmoid\"\n",
    "model2.add(Dense(1)) #outputlayer\n",
    "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(15,activation='tanh')) #hidden layer1, activation fn = \"tanh\"\n",
    "model3.add(Dense(15,activation='softmax')) #hidden layer2, activation fn = \"softmax\"\n",
    "model3.add(Dense(1)) #outputlayer\n",
    "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model4.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model4.add(Dense(1)) #outputlayer\n",
    "model4.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss='mse') #learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(1)) #outputlayer\n",
    "model5.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='mse') #learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(20,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model6.add(Dense(20,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model6.add(Dense(20,activation='sigmoid')) #hidden layer1, activation fn = \"sigmoid\"\n",
    "model6.add(Dense(1))  #outputlayer\n",
    "model6.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='mse') #learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 2s 21ms/step - loss: 113234.2174 - val_loss: 19.9821\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 39.3363 - val_loss: 16.4530\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 16.1020 - val_loss: 13.4301\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 15.1897 - val_loss: 12.1107\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 11.9923 - val_loss: 10.5626\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 9.9325 - val_loss: 7.6282\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 6.6069 - val_loss: 3.8587\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.6572 - val_loss: 2.6913\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.9001 - val_loss: 2.6004\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.7630 - val_loss: 2.1207\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.4032 - val_loss: 2.0698\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.1172 - val_loss: 1.5948\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7380 - val_loss: 1.6554\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.6172\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5245 - val_loss: 1.1893\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2958 - val_loss: 2.1230\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3423 - val_loss: 1.0392\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6129 - val_loss: 1.2526\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1680 - val_loss: 1.0094\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4083 - val_loss: 0.9524\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0779 - val_loss: 1.5612\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2278 - val_loss: 0.9007\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2070 - val_loss: 0.9700\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1393 - val_loss: 0.8248\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9258 - val_loss: 0.8063\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 42.8835\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 16.3949 - val_loss: 1.0318\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4192 - val_loss: 0.8625\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0785 - val_loss: 1.5835\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2506 - val_loss: 1.1423\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2292 - val_loss: 0.8058\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9780 - val_loss: 0.8099\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3669 - val_loss: 0.9498\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.7637\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 0.7930\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.7736\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9883 - val_loss: 0.8133\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2940 - val_loss: 1.1282\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0673 - val_loss: 0.7137\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7590 - val_loss: 0.7994\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8856 - val_loss: 0.6690\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0752 - val_loss: 0.7395\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 0.7019\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9623 - val_loss: 8.8630\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.7124 - val_loss: 2.4439\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1544 - val_loss: 0.7115\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7516 - val_loss: 0.7655\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0541 - val_loss: 0.9170\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7948 - val_loss: 1.1627\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8452 - val_loss: 0.8140\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7223 - val_loss: 0.6725\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7865 - val_loss: 0.6463\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7865 - val_loss: 0.7924\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0390 - val_loss: 0.6968\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7372 - val_loss: 0.6952\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7927 - val_loss: 0.9006\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0758 - val_loss: 0.7115\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9030 - val_loss: 3.0824\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5314 - val_loss: 0.8053\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1215 - val_loss: 0.6447\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7426 - val_loss: 0.6209\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0741 - val_loss: 0.6295\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7699 - val_loss: 2.0531\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.7094\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2208 - val_loss: 0.9104\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7847 - val_loss: 0.7872\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 0.8267\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 22.1064 - val_loss: 1.7621\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.9113 - val_loss: 0.7352\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4126 - val_loss: 0.6549\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7883 - val_loss: 1.4250\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5903 - val_loss: 3.1234\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 6.4857 - val_loss: 0.7781\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1336 - val_loss: 1.3732\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1721 - val_loss: 1.0754\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4456 - val_loss: 2.9422\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.0887 - val_loss: 0.6937\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.3708 - val_loss: 0.6236\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.5680 - val_loss: 1.1608\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.2645 - val_loss: 1.4380\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6367 - val_loss: 3.6359\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 5.2348 - val_loss: 2.5990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.2477 - val_loss: 3.1789\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.3332 - val_loss: 3.1337\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3409 - val_loss: 0.7494\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 2.3515\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3755 - val_loss: 1.0656\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 10.5040 - val_loss: 0.7838\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1872 - val_loss: 0.6620\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7585 - val_loss: 0.6169\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 8.0026\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 40.7251 - val_loss: 3.1702\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9586 - val_loss: 1.1462\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.8847 - val_loss: 1.0345\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0588 - val_loss: 3.8263\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.9025 - val_loss: 1.2473\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.0771 - val_loss: 0.8149\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9094 - val_loss: 0.7888\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7229 - val_loss: 0.9168\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4721 - val_loss: 3.8994\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 13.2298 - val_loss: 4.3593\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9173 - val_loss: 1.3337\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4675 - val_loss: 1.3859\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.0104 - val_loss: 1.2295\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7914 - val_loss: 5.3080\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.0618 - val_loss: 1.9301\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9092 - val_loss: 0.6645\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8425 - val_loss: 1.1746\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 0.6342\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7441 - val_loss: 0.7385\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 27.6589 - val_loss: 1.8194\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.6218 - val_loss: 1.0724\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.6892 - val_loss: 3.7117\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6930 - val_loss: 0.6396\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7191 - val_loss: 1.4276\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3332 - val_loss: 0.6135\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8411 - val_loss: 0.9516\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 0.9262\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3740 - val_loss: 0.7279\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7211 - val_loss: 1.3679\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0916 - val_loss: 20.5625\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 8.6220 - val_loss: 1.2017\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 17.9674 - val_loss: 0.7298\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7680 - val_loss: 0.7462\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.8288\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.6566\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 0.6286\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7040 - val_loss: 0.6200\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6833 - val_loss: 0.9621\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8088 - val_loss: 0.5803\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6990 - val_loss: 2.0188\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5328 - val_loss: 0.5897\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7425 - val_loss: 0.6016\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 1.0479\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.1379 - val_loss: 0.8850\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7049 - val_loss: 0.8943\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.6574\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5208 - val_loss: 1.6495\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.2474 - val_loss: 0.5979\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.2476 - val_loss: 1.1956\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0312 - val_loss: 1.2725\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9018 - val_loss: 0.5610\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8331 - val_loss: 0.6235\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.1996 - val_loss: 0.7153\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7345 - val_loss: 0.7056\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6090 - val_loss: 1.1323\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 8.5878 - val_loss: 6.8188\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 8.9098 - val_loss: 8.3321\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.0018 - val_loss: 0.5856\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6286 - val_loss: 0.5738\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5844 - val_loss: 0.8534\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6678 - val_loss: 0.5912\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5820 - val_loss: 0.5595\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6157 - val_loss: 0.5499\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9073 - val_loss: 1.2211\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5356 - val_loss: 0.5499\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5631 - val_loss: 0.6117\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6315 - val_loss: 0.6981\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6500 - val_loss: 4.9993\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.1020 - val_loss: 0.5721\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5709 - val_loss: 0.6004\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6599 - val_loss: 0.5702\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3829 - val_loss: 0.7532\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7606 - val_loss: 0.6326\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1946 - val_loss: 0.6111\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2855 - val_loss: 0.5831\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6685\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6657 - val_loss: 0.6534\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4485 - val_loss: 0.5949\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 1.1656\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.7212\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.9114 - val_loss: 0.7544\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7528 - val_loss: 1.2128\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1707 - val_loss: 0.7771\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8352 - val_loss: 0.7050\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 0.6403\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1815 - val_loss: 0.6349\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.6444\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0160 - val_loss: 0.6230\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.6273\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7501 - val_loss: 1.6118\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5411 - val_loss: 0.9058\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8534 - val_loss: 0.5454\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 0.5266\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2103 - val_loss: 0.5240\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5668 - val_loss: 0.5649\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5726 - val_loss: 0.5187\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5726\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 0.7388\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7455 - val_loss: 0.7687\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0913 - val_loss: 0.5411\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5979 - val_loss: 0.5721\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6202\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 0.9427\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0412 - val_loss: 0.4973\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.5020\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.5701\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.5156\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6223 - val_loss: 0.6131\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6304 - val_loss: 2.2015\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.1903 - val_loss: 0.6031\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.5682\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.5501\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7834 - val_loss: 0.5502\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 1.8142\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8677 - val_loss: 0.5332\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5030\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6341 - val_loss: 0.5773\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6057 - val_loss: 0.4919\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5050\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5692 - val_loss: 0.6872\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.5476\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6721 - val_loss: 0.4737\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 1.2217\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0646 - val_loss: 0.7642\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7711 - val_loss: 0.6146\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6117 - val_loss: 0.5019\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.4770\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.6028\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 0.5048\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7086 - val_loss: 0.4888\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.4599\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5811\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.4727\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.5123\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.6457\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.6879\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6596 - val_loss: 0.4633\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.6140\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.4626\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.8547\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4342 - val_loss: 0.5586\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6483 - val_loss: 0.4740\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.4579\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.4706\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5298\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5999\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8614 - val_loss: 0.5219\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 0.5128\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.5456\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5670 - val_loss: 0.5443\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5744 - val_loss: 0.5563\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 1.0161\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0879 - val_loss: 0.5261\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.4876\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.4794\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.4740\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5701 - val_loss: 0.4675\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.4707\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4632\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.4906\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6998 - val_loss: 0.4643\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4763\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.4700\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.4815\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.6230\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.5182\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4972 - val_loss: 0.4767\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.5307\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.4622\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5015\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.7739\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7143 - val_loss: 0.4882\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.4586\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.4900\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4643\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.4719\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.4843\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.4650\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.5055\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5068\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7974 - val_loss: 8.1596\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.6741 - val_loss: 1.3580\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3582 - val_loss: 1.3155\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2788 - val_loss: 1.3145\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3431 - val_loss: 1.3137\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3142 - val_loss: 1.3141\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2945 - val_loss: 1.3148\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3187 - val_loss: 1.3136\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3849 - val_loss: 1.3147\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2832 - val_loss: 1.3140\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3339 - val_loss: 1.3145\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2977 - val_loss: 1.3139\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3278 - val_loss: 1.3137\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3772 - val_loss: 1.3153\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3298 - val_loss: 1.3128\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3125 - val_loss: 1.3130\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3603 - val_loss: 1.3131\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3450 - val_loss: 1.3130\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3335 - val_loss: 1.3132\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3270 - val_loss: 1.3127\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3236 - val_loss: 1.3137\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3534 - val_loss: 1.3141\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3178 - val_loss: 1.3120\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3283 - val_loss: 1.3130\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3200 - val_loss: 1.3122\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3255 - val_loss: 1.3123\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3307 - val_loss: 1.3140\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3314 - val_loss: 1.3138\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3130 - val_loss: 1.3141\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3155 - val_loss: 1.3130\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3094 - val_loss: 1.3128\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3154 - val_loss: 1.3133\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3031 - val_loss: 1.3127\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2967 - val_loss: 1.3126\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3219 - val_loss: 1.3148\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3114 - val_loss: 1.3127\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3324 - val_loss: 1.3164\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3053 - val_loss: 1.3127\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3306 - val_loss: 1.3143\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2981 - val_loss: 1.3124\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3131 - val_loss: 1.3116\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3013 - val_loss: 1.3115\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3121 - val_loss: 1.3127\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2725 - val_loss: 1.3122\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3679 - val_loss: 1.3130\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3188 - val_loss: 1.3126\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3515 - val_loss: 1.3145\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3135 - val_loss: 1.3138\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3315 - val_loss: 1.3130\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3217 - val_loss: 1.3108\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3300 - val_loss: 1.3119\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3073 - val_loss: 1.3113\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3118 - val_loss: 1.3102\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3486 - val_loss: 1.3121\n",
      "Epoch 326/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3081 - val_loss: 1.3144\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3139 - val_loss: 1.3147\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3472 - val_loss: 1.3158\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3545 - val_loss: 1.3136\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3134 - val_loss: 1.3146\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3474 - val_loss: 1.3113\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3094 - val_loss: 1.3127\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3267 - val_loss: 1.3143\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3427 - val_loss: 1.3134\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3445 - val_loss: 1.3154\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2987 - val_loss: 1.3125\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3062 - val_loss: 1.3124\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3310 - val_loss: 1.3132\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3236 - val_loss: 1.3141\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3316 - val_loss: 1.3165\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2827 - val_loss: 1.3129\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2952 - val_loss: 1.3137\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3317 - val_loss: 1.3155\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3493 - val_loss: 1.3165\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3331 - val_loss: 1.3130\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2830 - val_loss: 1.3142\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2812 - val_loss: 1.3117\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3193 - val_loss: 1.3142\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.3110\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3278 - val_loss: 1.3131\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3300 - val_loss: 1.3144\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2926 - val_loss: 1.3118\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3012 - val_loss: 1.3109\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2977 - val_loss: 1.3087\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3315 - val_loss: 1.3112\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3453 - val_loss: 1.3863\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3127 - val_loss: 1.3143\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3419 - val_loss: 1.3157\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3198 - val_loss: 1.3177\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3178 - val_loss: 1.3152\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3574 - val_loss: 1.3157\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3139 - val_loss: 1.3160\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3466 - val_loss: 1.3146\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2932 - val_loss: 1.3145\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3021 - val_loss: 1.3142\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3579 - val_loss: 1.3168\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3240 - val_loss: 1.3152\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3335 - val_loss: 1.3168\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3235 - val_loss: 1.3165\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3150 - val_loss: 1.3145\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3274 - val_loss: 1.3148\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3544 - val_loss: 1.3148\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2983 - val_loss: 1.3153\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3362 - val_loss: 1.3158\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3122 - val_loss: 1.3156\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3170 - val_loss: 1.3145\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3044 - val_loss: 1.3169\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3126 - val_loss: 1.3152\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3072 - val_loss: 1.3145\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3511 - val_loss: 1.3194\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3145 - val_loss: 1.3160\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2947 - val_loss: 1.3142\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3288 - val_loss: 1.3149\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3327 - val_loss: 1.3146\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2954 - val_loss: 1.3144\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3540 - val_loss: 1.3169\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3440 - val_loss: 1.3168\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3226 - val_loss: 1.3145\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3203 - val_loss: 1.3171\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3551 - val_loss: 1.3172\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3285 - val_loss: 1.3157\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3239 - val_loss: 1.3147\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2435 - val_loss: 1.3145\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3180\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3012 - val_loss: 1.3155\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3036 - val_loss: 1.3152\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3178 - val_loss: 1.3144\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3093 - val_loss: 1.3149\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3212 - val_loss: 1.3174\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3288 - val_loss: 1.3142\n"
     ]
    }
   ],
   "source": [
    "#Step2\n",
    "# Train the the FNN model on the training samples\n",
    "#iteration. = samplesize/batch size\n",
    "#gradient weight u\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "history1 = model1.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 5.3673 - val_loss: 1.3182\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2964 - val_loss: 1.3154\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3449 - val_loss: 1.3250\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.3155\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3842 - val_loss: 1.3141\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3104 - val_loss: 1.3142\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2987 - val_loss: 1.3146\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3611 - val_loss: 1.3178\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3375 - val_loss: 1.3141\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3348 - val_loss: 1.3148\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3062 - val_loss: 1.3142\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 1.3161\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2716 - val_loss: 1.3150\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3556 - val_loss: 1.3157\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3239 - val_loss: 1.3153\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3185 - val_loss: 1.3152\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3067 - val_loss: 1.3145\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2895 - val_loss: 1.3146\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3134 - val_loss: 1.3142\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3456 - val_loss: 1.3160\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3255 - val_loss: 1.3147\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3559 - val_loss: 1.3194\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3300 - val_loss: 1.3157\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3795 - val_loss: 1.3446\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3276 - val_loss: 1.3171\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3394 - val_loss: 1.3185\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3144 - val_loss: 1.3144\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3104 - val_loss: 1.3157\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.3155\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3265 - val_loss: 1.3143\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3648 - val_loss: 1.3169\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3403 - val_loss: 1.3150\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3509 - val_loss: 1.3158\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3408 - val_loss: 1.3152\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3346 - val_loss: 1.3324\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3144 - val_loss: 1.3238\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3227 - val_loss: 1.3187\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3050 - val_loss: 1.3154\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3152\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3034 - val_loss: 1.3146\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3290 - val_loss: 1.3173\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3329 - val_loss: 1.3143\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2928 - val_loss: 1.3141\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3151 - val_loss: 1.3142\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3468 - val_loss: 1.3279\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3040 - val_loss: 1.3150\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.3149\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3203 - val_loss: 1.3140\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3367 - val_loss: 1.3191\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3318 - val_loss: 1.3242\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3672 - val_loss: 1.3140\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2792 - val_loss: 1.3142\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3086 - val_loss: 1.3217\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3718 - val_loss: 1.3173\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3272 - val_loss: 1.3207\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3399 - val_loss: 1.3140\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3498 - val_loss: 1.3213\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3301 - val_loss: 1.3156\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3536 - val_loss: 1.3171\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3108 - val_loss: 1.3163\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3252 - val_loss: 1.3143\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3291 - val_loss: 1.3161\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3372 - val_loss: 1.3163\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3385 - val_loss: 1.3248\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3574 - val_loss: 1.3152\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3269 - val_loss: 1.3141\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3251 - val_loss: 1.3146\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3695 - val_loss: 1.3152\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3909 - val_loss: 1.3196\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3255 - val_loss: 1.3145\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3125 - val_loss: 1.3256\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3504 - val_loss: 1.3204\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3547 - val_loss: 1.3167\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3267 - val_loss: 1.3142\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3198 - val_loss: 1.3205\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3329 - val_loss: 1.3151\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3063 - val_loss: 1.3140\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3287 - val_loss: 1.3141\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2906 - val_loss: 1.3144\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3037 - val_loss: 1.3200\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3548 - val_loss: 1.3162\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3147\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3541 - val_loss: 1.3174\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3194 - val_loss: 1.3154\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3169 - val_loss: 1.3141\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3046 - val_loss: 1.3192\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2838 - val_loss: 1.3188\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3703 - val_loss: 1.3175\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3356 - val_loss: 1.3151\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3504 - val_loss: 1.3153\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3817 - val_loss: 1.3304\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3623 - val_loss: 1.3154\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3911 - val_loss: 1.3172\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3733 - val_loss: 1.3140\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3530 - val_loss: 1.3233\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3397 - val_loss: 1.3190\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3065 - val_loss: 1.3140\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3473 - val_loss: 1.3158\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3158 - val_loss: 1.3145\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3446 - val_loss: 1.3141\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3051 - val_loss: 1.3169\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3321 - val_loss: 1.3142\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3283 - val_loss: 1.3229\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3310 - val_loss: 1.3151\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3492 - val_loss: 1.3211\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3121 - val_loss: 1.3155\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3532 - val_loss: 1.3141\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3295 - val_loss: 1.3198\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3224 - val_loss: 1.3156\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3530 - val_loss: 1.3221\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3439 - val_loss: 1.3199\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3042 - val_loss: 1.3284\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3402 - val_loss: 1.3141\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3430 - val_loss: 1.3270\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.3197\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2988 - val_loss: 1.3175\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3385 - val_loss: 1.3141\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3014 - val_loss: 1.3140\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3608 - val_loss: 1.3140\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3738 - val_loss: 1.3140\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3048 - val_loss: 1.3239\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3272 - val_loss: 1.3162\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3775 - val_loss: 1.3166\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2868 - val_loss: 1.3143\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3563 - val_loss: 1.3140\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3299 - val_loss: 1.3196\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3546 - val_loss: 1.3177\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3086 - val_loss: 1.3170\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3030 - val_loss: 1.3166\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3177 - val_loss: 1.3151\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3652 - val_loss: 1.3145\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3416 - val_loss: 1.3146\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3351 - val_loss: 1.3140\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3494 - val_loss: 1.3206\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3394 - val_loss: 1.3169\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3604 - val_loss: 1.3145\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3359 - val_loss: 1.3152\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3373 - val_loss: 1.3158\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3364 - val_loss: 1.3140\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3663 - val_loss: 1.3210\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4025 - val_loss: 1.3528\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3260 - val_loss: 1.3232\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3145 - val_loss: 1.3163\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3149\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3499 - val_loss: 1.3338\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3164 - val_loss: 1.3140\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2711 - val_loss: 1.3142\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3501 - val_loss: 1.3208\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3373 - val_loss: 1.3142\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3662 - val_loss: 1.3197\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3047 - val_loss: 1.3148\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3403 - val_loss: 1.3153\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3269 - val_loss: 1.3141\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3242 - val_loss: 1.3140\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3217 - val_loss: 1.3175\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3290 - val_loss: 1.3289\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3104 - val_loss: 1.3145\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3443 - val_loss: 1.3174\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3488 - val_loss: 1.3140\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3037 - val_loss: 1.3186\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3272 - val_loss: 1.3168\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3372 - val_loss: 1.3262\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3428 - val_loss: 1.3179\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2958 - val_loss: 1.3141\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3301 - val_loss: 1.3227\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3502 - val_loss: 1.3201\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3421 - val_loss: 1.3140\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3291 - val_loss: 1.3215\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3113 - val_loss: 1.3143\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3401 - val_loss: 1.3142\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3223 - val_loss: 1.3182\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3437 - val_loss: 1.3236\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3213 - val_loss: 1.3143\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3480 - val_loss: 1.3199\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3205 - val_loss: 1.3143\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3371 - val_loss: 1.3170\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3320 - val_loss: 1.3141\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3360 - val_loss: 1.3263\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3256 - val_loss: 1.3143\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3566 - val_loss: 1.3217\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3195 - val_loss: 1.3182\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3133 - val_loss: 1.3161\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3317 - val_loss: 1.3142\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3017 - val_loss: 1.3156\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3337 - val_loss: 1.3150\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3141 - val_loss: 1.3141\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2937 - val_loss: 1.3150\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3002 - val_loss: 1.3142\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3224 - val_loss: 1.3146\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3310\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3744 - val_loss: 1.3351\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3602 - val_loss: 1.3160\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3951 - val_loss: 1.3220\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3584 - val_loss: 1.3286\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3158 - val_loss: 1.3318\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3154 - val_loss: 1.3160\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3658 - val_loss: 1.3140\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3536 - val_loss: 1.3193\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3058 - val_loss: 1.3150\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3066 - val_loss: 1.3163\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3461 - val_loss: 1.3176\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3439 - val_loss: 1.3197\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3329 - val_loss: 1.3143\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3209 - val_loss: 1.3149\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3209 - val_loss: 1.3296\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3203 - val_loss: 1.3185\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3053 - val_loss: 1.3147\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3230 - val_loss: 1.3150\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2940 - val_loss: 1.3149\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3392 - val_loss: 1.3246\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3619 - val_loss: 1.3323\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3173 - val_loss: 1.3160\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3114 - val_loss: 1.3152\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3343 - val_loss: 1.3141\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3483 - val_loss: 1.3245\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3312 - val_loss: 1.3149\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3110 - val_loss: 1.3143\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3549 - val_loss: 1.3140\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3044 - val_loss: 1.3168\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2977 - val_loss: 1.3147\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3196 - val_loss: 1.3149\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3196 - val_loss: 1.3258\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3602 - val_loss: 1.3152\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3205 - val_loss: 1.3142\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3395 - val_loss: 1.3141\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3381 - val_loss: 1.3207\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3508 - val_loss: 1.3159\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3010 - val_loss: 1.3140\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3162 - val_loss: 1.3241\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3596 - val_loss: 1.3154\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3051 - val_loss: 1.3239\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3313 - val_loss: 1.3210\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3435 - val_loss: 1.3140\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2967 - val_loss: 1.3154\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2831 - val_loss: 1.3154\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3361 - val_loss: 1.3301\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3311 - val_loss: 1.3186\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3201 - val_loss: 1.3193\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2964 - val_loss: 1.3160\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3408 - val_loss: 1.3432\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3322 - val_loss: 1.3152\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3308 - val_loss: 1.3176\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2647 - val_loss: 1.3243\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3070 - val_loss: 1.3149\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2975 - val_loss: 1.3146\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3253 - val_loss: 1.3343\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3629 - val_loss: 1.3329\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.3180\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3044 - val_loss: 1.3149\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3294 - val_loss: 1.3168\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3314 - val_loss: 1.3152\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3433 - val_loss: 1.3182\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3284 - val_loss: 1.3186\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3542 - val_loss: 1.3149\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3497 - val_loss: 1.3158\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3398 - val_loss: 1.3140\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3438 - val_loss: 1.3143\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3535 - val_loss: 1.3157\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3514 - val_loss: 1.3203\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3521 - val_loss: 1.3211\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3140 - val_loss: 1.3140\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3375 - val_loss: 1.3167\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3354 - val_loss: 1.3374\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3257 - val_loss: 1.3220\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3157 - val_loss: 1.3151\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3334 - val_loss: 1.3166\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3474 - val_loss: 1.3180\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2954 - val_loss: 1.3145\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3125 - val_loss: 1.3200\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3712 - val_loss: 1.3143\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3483 - val_loss: 1.3329\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3414 - val_loss: 1.3143\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3209 - val_loss: 1.3553\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3564 - val_loss: 1.3181\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2870 - val_loss: 1.3174\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3461 - val_loss: 1.3150\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3172 - val_loss: 1.3148\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2996 - val_loss: 1.3653\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3302 - val_loss: 1.3142\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3936 - val_loss: 1.3143\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2940 - val_loss: 1.3169\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3396 - val_loss: 1.3173\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3012 - val_loss: 1.3141\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3397 - val_loss: 1.3196\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3860 - val_loss: 1.3254\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3409 - val_loss: 1.3550\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3366 - val_loss: 1.3142\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3656 - val_loss: 1.3270\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3502 - val_loss: 1.3169\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3369 - val_loss: 1.3190\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3290 - val_loss: 1.3181\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.3183\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3615 - val_loss: 1.3161\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3256 - val_loss: 1.3235\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3367 - val_loss: 1.3406\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3276 - val_loss: 1.3160\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3428 - val_loss: 1.3149\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3348 - val_loss: 1.3327\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3415 - val_loss: 1.3167\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3166 - val_loss: 1.3212\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3220 - val_loss: 1.3276\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3146 - val_loss: 1.3209\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3215 - val_loss: 1.3187\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3112 - val_loss: 1.3156\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3006 - val_loss: 1.3142\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3298 - val_loss: 1.3279\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3163 - val_loss: 1.3212\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3399 - val_loss: 1.3147\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3128 - val_loss: 1.3236\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3378 - val_loss: 1.3141\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3033 - val_loss: 1.3148\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3171 - val_loss: 1.3153\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3043 - val_loss: 1.3240\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3154 - val_loss: 1.3175\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2760 - val_loss: 1.3174\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3774 - val_loss: 1.3293\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3270 - val_loss: 1.3161\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3607 - val_loss: 1.3142\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3195 - val_loss: 1.3141\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3427 - val_loss: 1.3216\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3307 - val_loss: 1.3149\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3333 - val_loss: 1.3231\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3181 - val_loss: 1.3140\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3160 - val_loss: 1.3155\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3552 - val_loss: 1.3260\n",
      "Epoch 326/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3184 - val_loss: 1.3149\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3249 - val_loss: 1.3244\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3559 - val_loss: 1.3164\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3610 - val_loss: 1.3177\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3241\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3556 - val_loss: 1.3170\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3196 - val_loss: 1.3154\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3306 - val_loss: 1.3147\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3559 - val_loss: 1.3165\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3538 - val_loss: 1.3189\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3055 - val_loss: 1.3204\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3171 - val_loss: 1.3250\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3363 - val_loss: 1.3173\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3298 - val_loss: 1.3172\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3470 - val_loss: 1.3140\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2880 - val_loss: 1.3246\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3002 - val_loss: 1.3156\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3203\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3619 - val_loss: 1.3143\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3372 - val_loss: 1.3140\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2887 - val_loss: 1.3150\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2895 - val_loss: 1.3153\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3215 - val_loss: 1.3144\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3481 - val_loss: 1.3172\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3361 - val_loss: 1.3428\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3468 - val_loss: 1.3394\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3019 - val_loss: 1.3199\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3086 - val_loss: 1.3178\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3029 - val_loss: 1.3200\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3416 - val_loss: 1.3390\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3883 - val_loss: 1.3170\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2976 - val_loss: 1.3142\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3161\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3298 - val_loss: 1.3158\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3224 - val_loss: 1.3388\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3633 - val_loss: 1.3233\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3155 - val_loss: 1.3159\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3493 - val_loss: 1.3228\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3025 - val_loss: 1.3141\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3037 - val_loss: 1.3143\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3596 - val_loss: 1.3163\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3255 - val_loss: 1.3143\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3367 - val_loss: 1.3301\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3358 - val_loss: 1.3206\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3173 - val_loss: 1.3141\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3320 - val_loss: 1.3167\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3575 - val_loss: 1.3173\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3001 - val_loss: 1.3184\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3399 - val_loss: 1.3171\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3171 - val_loss: 1.3163\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3233 - val_loss: 1.3349\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3115 - val_loss: 1.3155\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3156 - val_loss: 1.3233\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3095 - val_loss: 1.3147\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3562 - val_loss: 1.3154\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3180 - val_loss: 1.3149\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3001 - val_loss: 1.3174\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3350 - val_loss: 1.3162\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3364 - val_loss: 1.3143\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3001 - val_loss: 1.3155\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3572 - val_loss: 1.3172\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3501 - val_loss: 1.3151\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3286 - val_loss: 1.3144\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3263 - val_loss: 1.3156\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3562 - val_loss: 1.3165\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3315 - val_loss: 1.3146\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.3148\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2450 - val_loss: 1.3177\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3473 - val_loss: 1.3199\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3059 - val_loss: 1.3158\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3057 - val_loss: 1.3145\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3200 - val_loss: 1.3151\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3125 - val_loss: 1.3179\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3238 - val_loss: 1.3144\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3302 - val_loss: 1.3230\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history2 = model2.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 3.7259 - val_loss: 1.4789\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.3147\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3447 - val_loss: 1.3165\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3364 - val_loss: 1.3153\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3838 - val_loss: 1.3155\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3082 - val_loss: 1.3147\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2958 - val_loss: 1.3144\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3606 - val_loss: 1.3151\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3359 - val_loss: 1.3146\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3346 - val_loss: 1.3152\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3054 - val_loss: 1.3153\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 1.3144\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2709 - val_loss: 1.3156\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3542 - val_loss: 1.3158\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3224 - val_loss: 1.3153\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3179 - val_loss: 1.3143\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3059 - val_loss: 1.3144\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2878 - val_loss: 1.3155\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3099 - val_loss: 1.3143\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3446 - val_loss: 1.3149\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3201 - val_loss: 1.3187\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3560 - val_loss: 1.3149\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3233 - val_loss: 1.3196\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3794 - val_loss: 1.3197\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3236 - val_loss: 1.3154\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3368 - val_loss: 1.3143\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3122 - val_loss: 1.3174\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3081 - val_loss: 1.3140\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3265 - val_loss: 1.3161\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3257 - val_loss: 1.3141\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3646 - val_loss: 1.3165\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3389 - val_loss: 1.3154\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3490 - val_loss: 1.3142\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3401 - val_loss: 1.3144\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3289 - val_loss: 1.3170\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3123 - val_loss: 1.3196\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3221 - val_loss: 1.3173\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3047 - val_loss: 1.3150\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3402 - val_loss: 1.3177\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3008 - val_loss: 1.3142\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3234 - val_loss: 1.3148\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3308 - val_loss: 1.3142\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2919 - val_loss: 1.3178\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 1.3201\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3486 - val_loss: 1.3191\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3025 - val_loss: 1.3140\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3250 - val_loss: 1.3139\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3177 - val_loss: 1.3144\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3346 - val_loss: 1.3139\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3279 - val_loss: 1.3147\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3632 - val_loss: 1.3175\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2715 - val_loss: 1.3175\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3071 - val_loss: 1.3151\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3679 - val_loss: 1.3142\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3239 - val_loss: 1.3138\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3358 - val_loss: 1.3150\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3473 - val_loss: 1.3149\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3264 - val_loss: 1.3154\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3491 - val_loss: 1.3177\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3073 - val_loss: 1.3141\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3220 - val_loss: 1.3166\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3256 - val_loss: 1.3148\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3130\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3362 - val_loss: 1.3139\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3552 - val_loss: 1.3144\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3251 - val_loss: 1.3147\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3244 - val_loss: 1.3148\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3680 - val_loss: 1.3175\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3911 - val_loss: 1.3160\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3221 - val_loss: 1.3189\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3102 - val_loss: 1.3163\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3439 - val_loss: 1.3149\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3495 - val_loss: 1.3155\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3235 - val_loss: 1.3154\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3165 - val_loss: 1.3160\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3304 - val_loss: 1.3172\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3022 - val_loss: 1.3222\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3259 - val_loss: 1.3226\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2806 - val_loss: 1.3141\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2938 - val_loss: 1.3163\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3395 - val_loss: 1.3142\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3407 - val_loss: 1.3148\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3518 - val_loss: 1.3142\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3155\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 1.3161\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3021 - val_loss: 1.3167\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2808 - val_loss: 1.3150\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3621 - val_loss: 1.3151\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3323 - val_loss: 1.3147\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3470 - val_loss: 1.3178\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3831 - val_loss: 1.3225\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3598 - val_loss: 1.3177\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3901 - val_loss: 1.3201\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3727 - val_loss: 1.3142\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3507 - val_loss: 1.3137\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3367 - val_loss: 1.3136\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3057 - val_loss: 1.3111\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3475 - val_loss: 1.3220\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3119 - val_loss: 1.3136\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3405 - val_loss: 1.3125\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3033 - val_loss: 1.3124\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3277 - val_loss: 1.3142\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3260 - val_loss: 1.3162\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3314 - val_loss: 1.3142\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3464 - val_loss: 1.3148\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3077 - val_loss: 1.3125\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3480 - val_loss: 1.3133\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3254 - val_loss: 1.3159\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3194 - val_loss: 1.3126\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3502 - val_loss: 1.3148\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3372 - val_loss: 1.3148\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3030 - val_loss: 1.3139\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3341 - val_loss: 1.3124\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3409 - val_loss: 1.3133\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3243 - val_loss: 1.3209\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2973 - val_loss: 1.3159\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.3174\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2988 - val_loss: 1.3140\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3509 - val_loss: 1.3170\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3722 - val_loss: 1.3167\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2975 - val_loss: 1.3140\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3260 - val_loss: 1.3200\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3782 - val_loss: 1.3140\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2886 - val_loss: 1.3140\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3557 - val_loss: 1.3144\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3259 - val_loss: 1.3143\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3532 - val_loss: 1.3153\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3021 - val_loss: 1.3160\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3015 - val_loss: 1.3151\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3129 - val_loss: 1.3153\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3547 - val_loss: 1.3154\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3390 - val_loss: 1.3162\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3310 - val_loss: 1.3161\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3446 - val_loss: 1.3159\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3319 - val_loss: 1.3152\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3580 - val_loss: 1.3146\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3325 - val_loss: 1.3178\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3155\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3354 - val_loss: 1.3195\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3655 - val_loss: 1.3174\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3969 - val_loss: 1.3288\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3142 - val_loss: 1.3148\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3104 - val_loss: 1.3141\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3327 - val_loss: 1.3140\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3444 - val_loss: 1.3145\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3126 - val_loss: 1.3154\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2679 - val_loss: 1.3145\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3450 - val_loss: 1.3164\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3331 - val_loss: 1.3160\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3645 - val_loss: 1.3167\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3009 - val_loss: 1.3144\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3385 - val_loss: 1.3151\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3218 - val_loss: 1.3144\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3229 - val_loss: 1.3171\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3226 - val_loss: 1.3141\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3281 - val_loss: 1.3162\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3049 - val_loss: 1.3155\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3398 - val_loss: 1.3151\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3444 - val_loss: 1.3151\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3007 - val_loss: 1.3143\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3242 - val_loss: 1.3141\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3341 - val_loss: 1.3158\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3398 - val_loss: 1.3187\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2897 - val_loss: 1.3171\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3255 - val_loss: 1.3141\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3407 - val_loss: 1.3203\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3392 - val_loss: 1.3142\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3261 - val_loss: 1.3160\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3092 - val_loss: 1.3143\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3199\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3180 - val_loss: 1.3142\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3427 - val_loss: 1.3142\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3109 - val_loss: 1.3160\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3462 - val_loss: 1.3181\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3194 - val_loss: 1.3159\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3366 - val_loss: 1.3142\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3287 - val_loss: 1.3143\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3141\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3215 - val_loss: 1.3154\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3549 - val_loss: 1.3199\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3168 - val_loss: 1.3143\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3106 - val_loss: 1.3141\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3301 - val_loss: 1.3162\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2994 - val_loss: 1.3149\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3325 - val_loss: 1.3161\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3093 - val_loss: 1.3142\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2919 - val_loss: 1.3154\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2947 - val_loss: 1.3142\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3215 - val_loss: 1.3168\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3370 - val_loss: 1.3141\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3651 - val_loss: 1.3146\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3453 - val_loss: 1.3150\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3894 - val_loss: 1.3163\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3523 - val_loss: 1.3150\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3130 - val_loss: 1.3147\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3100 - val_loss: 1.3144\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3635 - val_loss: 1.3201\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3525 - val_loss: 1.3161\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3023 - val_loss: 1.3163\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3055 - val_loss: 1.3174\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3429 - val_loss: 1.3218\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3441 - val_loss: 1.3144\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3301 - val_loss: 1.3140\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3132 - val_loss: 1.3145\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3151 - val_loss: 1.3160\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3139 - val_loss: 1.3181\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3028 - val_loss: 1.3146\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3218 - val_loss: 1.3151\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2894 - val_loss: 1.3146\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3371 - val_loss: 1.3141\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3567 - val_loss: 1.3152\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3100 - val_loss: 1.3141\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3107 - val_loss: 1.3152\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3284 - val_loss: 1.3157\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3472 - val_loss: 1.3155\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3287 - val_loss: 1.3153\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3084 - val_loss: 1.3140\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3519 - val_loss: 1.3141\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3024 - val_loss: 1.3165\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2964 - val_loss: 1.3141\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3152\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3171 - val_loss: 1.3143\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3552 - val_loss: 1.3265\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3207 - val_loss: 1.3141\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3373 - val_loss: 1.3141\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3176\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3474 - val_loss: 1.3143\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2956 - val_loss: 1.3140\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3126 - val_loss: 1.3193\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3581 - val_loss: 1.3161\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3017 - val_loss: 1.3140\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3281 - val_loss: 1.3144\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3396 - val_loss: 1.3149\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2952 - val_loss: 1.3164\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2807 - val_loss: 1.3140\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3335 - val_loss: 1.3141\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3283 - val_loss: 1.3148\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3147 - val_loss: 1.3145\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2952 - val_loss: 1.3141\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.3195\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3234 - val_loss: 1.3181\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3292 - val_loss: 1.3143\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2547 - val_loss: 1.3214\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2996 - val_loss: 1.3167\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2966 - val_loss: 1.3143\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3241 - val_loss: 1.3168\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3544 - val_loss: 1.3166\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3237 - val_loss: 1.3154\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3022 - val_loss: 1.3142\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3274 - val_loss: 1.3140\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3281 - val_loss: 1.3147\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3380 - val_loss: 1.3191\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3250 - val_loss: 1.3142\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3510 - val_loss: 1.3153\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3455 - val_loss: 1.3185\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3349 - val_loss: 1.3141\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3395 - val_loss: 1.3172\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3514 - val_loss: 1.3160\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3520 - val_loss: 1.3166\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3495 - val_loss: 1.3179\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3116 - val_loss: 1.3154\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3345 - val_loss: 1.3149\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3344 - val_loss: 1.3170\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3211 - val_loss: 1.3143\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3130 - val_loss: 1.3153\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.3168\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3423 - val_loss: 1.3196\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2948 - val_loss: 1.3150\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3095 - val_loss: 1.3195\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3690 - val_loss: 1.3143\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3479 - val_loss: 1.3148\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3356 - val_loss: 1.3161\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3156\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3400 - val_loss: 1.3178\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2827 - val_loss: 1.3158\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3449 - val_loss: 1.3140\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3167 - val_loss: 1.3141\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2979 - val_loss: 1.3152\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3208 - val_loss: 1.3147\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3896 - val_loss: 1.3151\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2886 - val_loss: 1.3143\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3369 - val_loss: 1.3141\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3004 - val_loss: 1.3173\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3337 - val_loss: 1.3182\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3826 - val_loss: 1.3300\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3144\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3162 - val_loss: 1.3144\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3635 - val_loss: 1.3176\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3487 - val_loss: 1.3141\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3377 - val_loss: 1.3142\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3317 - val_loss: 1.3156\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3264 - val_loss: 1.3171\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3584 - val_loss: 1.3170\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3229 - val_loss: 1.3149\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3308 - val_loss: 1.3164\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3238 - val_loss: 1.3149\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3327 - val_loss: 1.3159\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3326 - val_loss: 1.3168\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3341 - val_loss: 1.3219\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3184 - val_loss: 1.3175\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3197 - val_loss: 1.3173\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3113 - val_loss: 1.3172\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3194 - val_loss: 1.3167\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3076 - val_loss: 1.3148\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2981 - val_loss: 1.3144\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3276 - val_loss: 1.3178\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3143 - val_loss: 1.3155\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3370 - val_loss: 1.3243\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3097 - val_loss: 1.3153\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3329 - val_loss: 1.3166\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3003 - val_loss: 1.3143\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3161 - val_loss: 1.3143\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3034 - val_loss: 1.3143\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3133 - val_loss: 1.3165\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2743 - val_loss: 1.3141\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3726 - val_loss: 1.3156\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3229 - val_loss: 1.3160\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3546 - val_loss: 1.3179\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3172 - val_loss: 1.3149\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3407 - val_loss: 1.3154\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3297 - val_loss: 1.3177\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3321 - val_loss: 1.3141\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3120 - val_loss: 1.3141\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3157 - val_loss: 1.3146\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3539 - val_loss: 1.3152\n",
      "Epoch 326/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3124 - val_loss: 1.3182\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3179 - val_loss: 1.3174\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3528 - val_loss: 1.3190\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3620 - val_loss: 1.3146\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3166 - val_loss: 1.3165\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3509 - val_loss: 1.3143\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3141 - val_loss: 1.3149\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3291 - val_loss: 1.3188\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3489 - val_loss: 1.3161\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3516 - val_loss: 1.3180\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3033 - val_loss: 1.3215\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3125 - val_loss: 1.3140\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3349 - val_loss: 1.3158\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3273 - val_loss: 1.3145\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3369 - val_loss: 1.3161\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2840 - val_loss: 1.3173\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.2980 - val_loss: 1.3151\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3384 - val_loss: 1.3145\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3529 - val_loss: 1.3160\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3372 - val_loss: 1.3153\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2855 - val_loss: 1.3164\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2853 - val_loss: 1.3146\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3190 - val_loss: 1.3142\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3432 - val_loss: 1.3140\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3344 - val_loss: 1.3208\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.3384 - val_loss: 1.3221\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2988 - val_loss: 1.3140\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3050 - val_loss: 1.3157\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3006 - val_loss: 1.3141\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3428 - val_loss: 1.3148\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3735 - val_loss: 1.3172\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2954 - val_loss: 1.3142\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3419 - val_loss: 1.3141\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3204 - val_loss: 1.3182\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3183 - val_loss: 1.3172\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3582 - val_loss: 1.3212\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3151 - val_loss: 1.3157\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3466 - val_loss: 1.3141\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.2941 - val_loss: 1.3151\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3015 - val_loss: 1.3142\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3577 - val_loss: 1.3149\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3247 - val_loss: 1.3143\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3340 - val_loss: 1.3200\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3252 - val_loss: 1.3184\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3161 - val_loss: 1.3140\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3284 - val_loss: 1.3154\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3550 - val_loss: 1.3141\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2992 - val_loss: 1.3177\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3379 - val_loss: 1.3166\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3137 - val_loss: 1.3143\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3186 - val_loss: 1.3140\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3062 - val_loss: 1.3182\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3129 - val_loss: 1.3159\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3075 - val_loss: 1.3146\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3517 - val_loss: 1.3234\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3146 - val_loss: 1.3228\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2941 - val_loss: 1.3144\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3289 - val_loss: 1.3140\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3332 - val_loss: 1.3146\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2969 - val_loss: 1.3152\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3545 - val_loss: 1.3157\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3452 - val_loss: 1.3164\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3232 - val_loss: 1.3143\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3208 - val_loss: 1.3171\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3551 - val_loss: 1.3171\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3291 - val_loss: 1.3150\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3248 - val_loss: 1.3142\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2447 - val_loss: 1.3148\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3433 - val_loss: 1.3216\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3020 - val_loss: 1.3179\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3043 - val_loss: 1.3153\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3178 - val_loss: 1.3140\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3099 - val_loss: 1.3159\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3223 - val_loss: 1.3203\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3291 - val_loss: 1.3140\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history3 = model3.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 2s 10ms/step - loss: 808213.6439 - val_loss: 567403.2500\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 598181.0473 - val_loss: 413220.3125\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 427042.4233 - val_loss: 289214.9688\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 313287.1042 - val_loss: 198761.2812\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 197379.0414 - val_loss: 131870.8438\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 130461.9714 - val_loss: 82927.5234\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 82510.1139 - val_loss: 48476.4531\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 48501.7588 - val_loss: 26894.8887\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 27341.2661 - val_loss: 14119.5244\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 17821.6281 - val_loss: 6936.5518\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 7556.1208 - val_loss: 3220.6287\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 3533.8195 - val_loss: 1465.1934\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1837.6283 - val_loss: 837.6850\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1136.8285 - val_loss: 648.4501\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 841.5825 - val_loss: 542.2493\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 722.1682 - val_loss: 461.7827\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 813.9615 - val_loss: 396.7914\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 516.6577 - val_loss: 344.9006\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 464.4692 - val_loss: 302.3100\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 361.9075 - val_loss: 264.8652\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 335.5078 - val_loss: 232.7978\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 299.8016 - val_loss: 205.7288\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 275.5135 - val_loss: 179.7924\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 219.6174 - val_loss: 158.3798\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 196.3245 - val_loss: 126.4685\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 139.6501 - val_loss: 99.7108\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 128.7147 - val_loss: 82.4472\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 107.9158 - val_loss: 72.9138\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 83.5411 - val_loss: 57.7001\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 65.7466 - val_loss: 51.5869\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 59.5712 - val_loss: 43.0979\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 52.9765 - val_loss: 33.7130\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 43.5633 - val_loss: 26.8208\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 30.5067 - val_loss: 20.8111\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 26.3632 - val_loss: 15.6021\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 19.4919 - val_loss: 12.5095\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 15.1435 - val_loss: 9.8845\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 14.9167 - val_loss: 8.1095\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 10.0846 - val_loss: 6.5801\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 7.5375 - val_loss: 5.9148\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 7.4064 - val_loss: 4.8023\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 5.6951 - val_loss: 4.2112\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 4.8091 - val_loss: 3.9288\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 4.4354 - val_loss: 3.5079\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 4.2798 - val_loss: 3.3498\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.6151 - val_loss: 3.1636\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.7429 - val_loss: 3.0792\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.5415 - val_loss: 2.9942\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.3306 - val_loss: 2.9549\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.2322 - val_loss: 2.9434\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.196 - 0s 4ms/step - loss: 3.1803 - val_loss: 2.9060\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 3.0562 - val_loss: 2.8891\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 3.4855 - val_loss: 2.8777\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.8891 - val_loss: 2.8659\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 3.0406 - val_loss: 2.8562\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8885 - val_loss: 2.8472\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8890 - val_loss: 2.8427\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8408 - val_loss: 2.8271\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.9331 - val_loss: 2.8190\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8190 - val_loss: 2.8143\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8396 - val_loss: 2.7971\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.8019 - val_loss: 2.7924\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8457 - val_loss: 2.7672\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8497 - val_loss: 2.7558\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7899 - val_loss: 2.7422\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7180 - val_loss: 2.7279\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7246 - val_loss: 2.7217\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.8144 - val_loss: 2.7067\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.6531 - val_loss: 2.6867\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7231 - val_loss: 2.6727\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.6675 - val_loss: 2.6632\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.6255 - val_loss: 2.6530\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7114 - val_loss: 2.6314\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.6932 - val_loss: 2.6152\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5634 - val_loss: 2.6163\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.6008 - val_loss: 2.5871\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.5151 - val_loss: 2.5759\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5336 - val_loss: 2.5548\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5195 - val_loss: 2.5403\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 2.4965 - val_loss: 2.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5693 - val_loss: 2.5075\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.4983 - val_loss: 2.4878\n",
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 2.4536 - val_loss: 2.4753\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 2.4616 - val_loss: 2.4809\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 2.3905 - val_loss: 2.4391\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2.3266 - val_loss: 2.4659\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.4111 - val_loss: 2.4999\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.4809 - val_loss: 2.4040\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.4367 - val_loss: 2.3714\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.3099 - val_loss: 2.3513\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.3295 - val_loss: 2.3356\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.3674 - val_loss: 2.3135\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.3418 - val_loss: 2.3202\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2.2090 - val_loss: 2.2844\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 2.2019 - val_loss: 2.2875\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2.1741 - val_loss: 2.2370\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.1735 - val_loss: 2.2314\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2.1971 - val_loss: 2.2052\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.1767 - val_loss: 2.1968\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.1951 - val_loss: 2.1732\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.0593 - val_loss: 2.1512\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.0504 - val_loss: 2.1556\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.0881 - val_loss: 2.1350\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.0998 - val_loss: 2.1000\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 2.0819 - val_loss: 2.0794\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9513 - val_loss: 2.0581\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.0496 - val_loss: 2.0368\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.0361 - val_loss: 2.0170\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9106 - val_loss: 2.0043\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9957 - val_loss: 1.9853\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9225 - val_loss: 1.9783\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.8758 - val_loss: 1.9411\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9141 - val_loss: 1.9429\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.8904 - val_loss: 1.9176\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.9432 - val_loss: 1.9128\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.8725 - val_loss: 1.8742\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7840 - val_loss: 1.8500\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7947 - val_loss: 1.8515\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.7962 - val_loss: 1.8171\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.8246 - val_loss: 1.7959\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.6973 - val_loss: 1.7810\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.6747 - val_loss: 1.7661\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.7862 - val_loss: 1.7441\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.6743 - val_loss: 1.7312\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7202 - val_loss: 1.7190\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.7291 - val_loss: 1.7186\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7264 - val_loss: 1.6886\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.6108 - val_loss: 1.6674\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.6632 - val_loss: 1.6512\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.6423 - val_loss: 1.6456\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.6771 - val_loss: 1.6210\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.6119 - val_loss: 1.6410\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.5708 - val_loss: 1.6136\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5580 - val_loss: 1.6025\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.5172 - val_loss: 1.5614\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.4861 - val_loss: 1.6520\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.5012 - val_loss: 1.5630\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.5355 - val_loss: 1.5334\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.4462 - val_loss: 1.5054\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.5056 - val_loss: 1.4929\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.4937 - val_loss: 1.4824\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4485 - val_loss: 1.4587\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4919 - val_loss: 1.4411\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4406 - val_loss: 1.4138\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3581 - val_loss: 1.4293\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3220 - val_loss: 1.3715\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3508 - val_loss: 1.3531\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3789 - val_loss: 1.3333\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2964 - val_loss: 1.4039\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3423 - val_loss: 1.3229\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3023 - val_loss: 1.2675\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2404 - val_loss: 1.2462\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2488 - val_loss: 1.2408\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2144 - val_loss: 1.2106\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1715 - val_loss: 1.2192\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1660 - val_loss: 1.1939\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1492 - val_loss: 1.1655\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1372 - val_loss: 1.1738\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1608 - val_loss: 1.1500\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1365 - val_loss: 1.1327\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1182 - val_loss: 1.1389\n",
      "Epoch 162/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1872 - val_loss: 1.1235\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0753 - val_loss: 1.1089\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0546 - val_loss: 1.0996\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0767 - val_loss: 1.1136\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0871 - val_loss: 1.0878\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0706 - val_loss: 1.0704\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0934 - val_loss: 1.0700\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0403 - val_loss: 1.0864\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0698 - val_loss: 1.0880\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0000 - val_loss: 1.0648\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0158 - val_loss: 1.0325\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0212 - val_loss: 1.1237\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0953 - val_loss: 1.0239\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.9716 - val_loss: 1.0267\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9911 - val_loss: 1.0081\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0187 - val_loss: 0.9998\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0376 - val_loss: 1.0122\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9787 - val_loss: 1.0298\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0686 - val_loss: 0.9829\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9880 - val_loss: 0.9960\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9506 - val_loss: 0.9752\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0052 - val_loss: 0.9905\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9216 - val_loss: 0.9600\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0278 - val_loss: 1.0096\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9787 - val_loss: 0.9489\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9135 - val_loss: 0.9459\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9314 - val_loss: 0.9737\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8952 - val_loss: 0.9366\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9447 - val_loss: 0.9782\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9700 - val_loss: 0.9306\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9496 - val_loss: 1.0074\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.9647\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.9193 - val_loss: 0.9170\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.9233 - val_loss: 0.9076\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9159 - val_loss: 0.9040\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.9012\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9098 - val_loss: 0.9032\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8517 - val_loss: 0.9297\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8862 - val_loss: 0.8895\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0457 - val_loss: 0.9064\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9119 - val_loss: 0.8955\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8533 - val_loss: 0.8991\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8780 - val_loss: 0.9354\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8901 - val_loss: 0.8762\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8572 - val_loss: 0.9202\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8472 - val_loss: 0.9014\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9568 - val_loss: 0.8837\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8446 - val_loss: 0.8824\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8494 - val_loss: 0.8663\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9610 - val_loss: 0.8563\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8293 - val_loss: 0.8608\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8722 - val_loss: 0.8514\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8515 - val_loss: 0.8634\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8343 - val_loss: 0.8473\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9069 - val_loss: 0.8616\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8073 - val_loss: 0.8445\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8419 - val_loss: 0.8425\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8436 - val_loss: 0.9529\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8538 - val_loss: 0.8377\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8318 - val_loss: 0.8843\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8332 - val_loss: 0.8383\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8533 - val_loss: 0.8475\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8838 - val_loss: 0.9049\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8532 - val_loss: 0.8461\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8737 - val_loss: 0.8867\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8329 - val_loss: 0.8545\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.8209\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8709 - val_loss: 0.8235\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.815 - 0s 4ms/step - loss: 0.8163 - val_loss: 0.8181\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8081 - val_loss: 0.8286\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8327 - val_loss: 0.8923\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8942 - val_loss: 0.8735\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8093 - val_loss: 0.8266\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8229 - val_loss: 0.8134\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8101 - val_loss: 0.8615\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8029 - val_loss: 0.9620\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8695 - val_loss: 0.8064\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.9104 - val_loss: 0.8033\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8061 - val_loss: 0.8142\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8233 - val_loss: 0.8146\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8039 - val_loss: 0.7967\n",
      "Epoch 243/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8168 - val_loss: 0.9374\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2373 - val_loss: 0.8552\n",
      "Epoch 245/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8698 - val_loss: 8.1898\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.1945 - val_loss: 0.8159\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7958 - val_loss: 0.8296\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7885 - val_loss: 0.7921\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7429 - val_loss: 0.8320\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7900 - val_loss: 0.7892\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7725 - val_loss: 0.8050\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7854 - val_loss: 0.7935\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7774 - val_loss: 0.8325\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7750 - val_loss: 0.8040\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7736 - val_loss: 0.7877\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8068 - val_loss: 1.2219\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9493 - val_loss: 0.9273\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8698 - val_loss: 0.8021\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7910 - val_loss: 0.7866\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7656 - val_loss: 0.7951\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7557 - val_loss: 0.7819\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7561 - val_loss: 0.7755\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8059 - val_loss: 0.7849\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8225 - val_loss: 0.8963\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8131 - val_loss: 0.7718\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7522 - val_loss: 0.8715\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7471 - val_loss: 2.0275\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2175 - val_loss: 0.7688\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7643 - val_loss: 0.7707\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8171 - val_loss: 0.8268\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8139 - val_loss: 0.7925\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7842 - val_loss: 0.7771\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7826 - val_loss: 0.7971\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8178 - val_loss: 0.8087\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7711 - val_loss: 0.7755\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8025 - val_loss: 0.7790\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7755 - val_loss: 0.8126\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7854 - val_loss: 0.7904\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0498 - val_loss: 0.8158\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7964 - val_loss: 0.9077\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8499 - val_loss: 0.8051\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7905 - val_loss: 0.7500\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7188 - val_loss: 0.8310\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8636 - val_loss: 0.7537\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7577 - val_loss: 0.7620\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7727 - val_loss: 0.7645\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7782 - val_loss: 0.8365\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7943 - val_loss: 1.0679\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.2252 - val_loss: 0.7713\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7854 - val_loss: 0.8404\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9089 - val_loss: 0.7921\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8869 - val_loss: 0.7611\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7662 - val_loss: 0.7413\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.7373\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7700 - val_loss: 0.7736\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7423 - val_loss: 0.7557\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7224 - val_loss: 0.7411\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7406 - val_loss: 0.7333\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7536 - val_loss: 0.7553\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7555 - val_loss: 0.7841\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7379 - val_loss: 0.7315\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7069 - val_loss: 0.7401\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7570 - val_loss: 0.7852\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7168 - val_loss: 0.7641\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7186 - val_loss: 0.9041\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8067 - val_loss: 0.7432\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7362 - val_loss: 0.7297\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7381 - val_loss: 0.7317\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7799 - val_loss: 0.7362\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.0096 - val_loss: 0.7958\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7489 - val_loss: 0.7451\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8993 - val_loss: 0.7575\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8782 - val_loss: 0.7257\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.7410\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6842 - val_loss: 0.7727\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7551 - val_loss: 0.7239\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6920 - val_loss: 0.7128\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7135 - val_loss: 0.7154\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7471 - val_loss: 0.7597\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8999 - val_loss: 0.7563\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7790 - val_loss: 0.8433\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7413 - val_loss: 0.8464\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7617 - val_loss: 0.7091\n",
      "Epoch 324/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6657 - val_loss: 0.7171\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7050 - val_loss: 0.7114\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7351 - val_loss: 0.7100\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9740 - val_loss: 0.8101\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7493 - val_loss: 0.7241\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7393 - val_loss: 0.7169\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6970 - val_loss: 0.8396\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7331 - val_loss: 0.7061\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7258 - val_loss: 0.7002\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6902 - val_loss: 0.7079\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7412 - val_loss: 0.7893\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7152 - val_loss: 0.7024\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.7009\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6757 - val_loss: 0.7054\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7268 - val_loss: 0.6974\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7522 - val_loss: 0.7121\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6883 - val_loss: 0.9186\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7948 - val_loss: 0.6976\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6815 - val_loss: 0.7552\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6939 - val_loss: 0.7823\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7022 - val_loss: 0.6930\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7233 - val_loss: 0.6921\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6766 - val_loss: 0.7050\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6854 - val_loss: 0.7535\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7226 - val_loss: 0.6886\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6928 - val_loss: 0.6944\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6807 - val_loss: 0.6910\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6884 - val_loss: 0.7341\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8607 - val_loss: 1.4056\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8568 - val_loss: 0.6861\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6662 - val_loss: 1.0696\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9500 - val_loss: 0.7130\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6947 - val_loss: 0.6837\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6563 - val_loss: 0.6996\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7076 - val_loss: 0.9659\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3869 - val_loss: 0.7652\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7396 - val_loss: 0.6922\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6856 - val_loss: 0.6816\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6570 - val_loss: 0.9386\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8381 - val_loss: 0.7508\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6920 - val_loss: 0.6842\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6731 - val_loss: 0.6796\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7098 - val_loss: 0.6796\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6583 - val_loss: 0.6765\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7113 - val_loss: 0.6782\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6745 - val_loss: 0.7063\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7163 - val_loss: 0.7240\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6817 - val_loss: 0.6849\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6977 - val_loss: 0.6884\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6617 - val_loss: 0.7341\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7033 - val_loss: 0.6757\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6522 - val_loss: 0.6725\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6506 - val_loss: 0.6924\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6751 - val_loss: 0.6730\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6864 - val_loss: 0.6962\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7206 - val_loss: 0.6709\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6943 - val_loss: 0.6743\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6690 - val_loss: 0.7659\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6895\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6614 - val_loss: 0.6678\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6566 - val_loss: 1.0344\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8401 - val_loss: 0.7046\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6954 - val_loss: 0.6694\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6814 - val_loss: 0.6649\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6589 - val_loss: 1.0702\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.8825 - val_loss: 0.7778\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7151 - val_loss: 0.6856\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6650 - val_loss: 0.6699\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6635 - val_loss: 0.6774\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6524 - val_loss: 0.8275\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8234 - val_loss: 0.6624\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6511 - val_loss: 0.6618\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6629 - val_loss: 0.7066\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6295 - val_loss: 0.7011\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6540 - val_loss: 0.9779\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7674 - val_loss: 0.7537\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7219 - val_loss: 0.6881\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history4 = model4.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 2s 10ms/step - loss: 704.5160 - val_loss: 19.9188\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 17.7756 - val_loss: 8.0881\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 8.5241 - val_loss: 6.1603\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 7.1718 - val_loss: 4.8075\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 4.9424 - val_loss: 3.9598\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 3.8215 - val_loss: 4.4719\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 4.4023 - val_loss: 5.6062\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 5.6262 - val_loss: 3.1946\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.7089 - val_loss: 2.2290\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.1645 - val_loss: 1.8624\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9781 - val_loss: 1.7799\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.0158 - val_loss: 2.2085\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.9411 - val_loss: 1.5332\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.7741 - val_loss: 2.0775\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7087 - val_loss: 1.4223\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.6172 - val_loss: 2.2234\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.8543 - val_loss: 1.4188\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5701 - val_loss: 2.0748\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.7562 - val_loss: 1.3061\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3669 - val_loss: 1.6989\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5250 - val_loss: 1.5311\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9421 - val_loss: 1.1640\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3675 - val_loss: 1.1446\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2495 - val_loss: 1.1112\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3980 - val_loss: 1.2351\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3311 - val_loss: 53.3620\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 50.0340 - val_loss: 4.1472\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 4.4782 - val_loss: 2.5053\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 3.3162 - val_loss: 1.8497\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.0401 - val_loss: 1.4703\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.3604 - val_loss: 1.1733\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.1795 - val_loss: 1.0461\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0808 - val_loss: 1.2019\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2643 - val_loss: 0.9641\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0005 - val_loss: 0.9139\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.0820 - val_loss: 0.9647\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.1653 - val_loss: 1.9552\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.2696 - val_loss: 0.8755\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.2764 - val_loss: 0.9042\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.958 - 0s 4ms/step - loss: 0.9598 - val_loss: 0.9112\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.4529 - val_loss: 0.8826\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0416 - val_loss: 0.8453\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0469 - val_loss: 2.4120\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3652 - val_loss: 10.8187\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.1585 - val_loss: 1.0509\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9035 - val_loss: 0.8884\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 2.0437\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2054 - val_loss: 1.5797\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1693 - val_loss: 0.8338\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8751 - val_loss: 0.8944\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9303 - val_loss: 0.8660\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5379 - val_loss: 0.8110\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9837 - val_loss: 0.9350\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1097 - val_loss: 0.8160\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9649 - val_loss: 0.8596\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1829 - val_loss: 1.8303\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4375 - val_loss: 1.0951\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9892 - val_loss: 1.1978\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1943 - val_loss: 1.2604\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0588 - val_loss: 0.8707\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 0.7784\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1883 - val_loss: 1.1822\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9824 - val_loss: 1.0245\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.9468 - val_loss: 0.7758\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.1652 - val_loss: 1.6901\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2835 - val_loss: 1.3469\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9994 - val_loss: 0.8627\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2787 - val_loss: 0.8816\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2455 - val_loss: 1.8991\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5208 - val_loss: 1.5640\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5211 - val_loss: 5.5269\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 5.9395 - val_loss: 1.4769\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 6.8078 - val_loss: 0.7573\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9850 - val_loss: 1.5541\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0676 - val_loss: 0.7321\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2259 - val_loss: 0.8091\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7911 - val_loss: 0.7143\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7219 - val_loss: 0.7140\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7337 - val_loss: 0.7116\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5563 - val_loss: 0.9138\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7523 - val_loss: 0.7059\n",
      "Epoch 82/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8890 - val_loss: 1.4828\n",
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 1.0485\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3449 - val_loss: 0.8539\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8427 - val_loss: 0.8548\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7658 - val_loss: 0.7034\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9199 - val_loss: 6.5565\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 7.8342 - val_loss: 3.5292\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.2172 - val_loss: 0.8176\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7998 - val_loss: 0.7808\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7544 - val_loss: 0.7071\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8898 - val_loss: 1.0022\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8567 - val_loss: 0.7931\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7713 - val_loss: 0.7048\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7590 - val_loss: 8.0511\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 5.6825 - val_loss: 1.3064\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 13.6863 - val_loss: 0.7404\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7360 - val_loss: 0.6832\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7900 - val_loss: 0.6659\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7475 - val_loss: 0.6684\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8619 - val_loss: 0.6932\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7066 - val_loss: 0.6931\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7792 - val_loss: 0.7263\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7500 - val_loss: 0.6898\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6721 - val_loss: 1.1026\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8518 - val_loss: 0.6985\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2125 - val_loss: 0.6781\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7900 - val_loss: 0.8647\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8834 - val_loss: 0.6655\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7289 - val_loss: 6.3390\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 4.8857 - val_loss: 0.7827\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.9097 - val_loss: 0.6554\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8560 - val_loss: 0.6440\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.7357\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.7596 - val_loss: 0.6698\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.3879 - val_loss: 14.4600\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 5.8110 - val_loss: 1.6359\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9704 - val_loss: 0.6449\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.9984 - val_loss: 1.0027\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.6656 - val_loss: 0.6713\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6367 - val_loss: 0.6519\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8046 - val_loss: 4.2712\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 22.8485 - val_loss: 4.2887\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.7696 - val_loss: 0.6400\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.8708 - val_loss: 0.6396\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7747 - val_loss: 0.6789\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7899 - val_loss: 0.7203\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.6808 - val_loss: 0.6926\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6666 - val_loss: 0.6510\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.7368 - val_loss: 1.1708\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7832 - val_loss: 0.6378\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7192 - val_loss: 0.6897\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.9462 - val_loss: 0.6356\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6346 - val_loss: 0.9441\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.252 - 0s 4ms/step - loss: 2.2020 - val_loss: 0.6841\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6740 - val_loss: 0.7080\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8202 - val_loss: 0.6229\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7239 - val_loss: 0.6629\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3502 - val_loss: 2.5870\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.6113 - val_loss: 0.6933\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7978 - val_loss: 0.6440\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6537 - val_loss: 0.7650\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6947 - val_loss: 0.7002\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.8858 - val_loss: 3.3309\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5389 - val_loss: 0.6995\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0686 - val_loss: 0.7819\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7006 - val_loss: 1.8083\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.4035 - val_loss: 1.8779\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.0044 - val_loss: 0.9624\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.0521 - val_loss: 1.3415\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8670 - val_loss: 1.1368\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.8249\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6871 - val_loss: 0.6732\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.0849 - val_loss: 1.1111\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.9290 - val_loss: 0.7904\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.1094 - val_loss: 4.5247\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.9885 - val_loss: 6.3517\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 3.9957 - val_loss: 4.7641\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.7544 - val_loss: 0.6378\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7484 - val_loss: 0.6490\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0042 - val_loss: 1.3105\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2754 - val_loss: 0.7019\n",
      "Epoch 163/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6595 - val_loss: 0.6901\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6641 - val_loss: 0.6442\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.1478 - val_loss: 0.6874\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7617 - val_loss: 0.6917\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7026 - val_loss: 0.7111\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8316 - val_loss: 0.6985\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6354 - val_loss: 0.6553\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6620 - val_loss: 0.7879\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8236 - val_loss: 0.6524\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8793 - val_loss: 0.6818\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6996 - val_loss: 0.8747\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3586 - val_loss: 0.6281\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7448 - val_loss: 0.6390\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6562 - val_loss: 0.6516\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8268 - val_loss: 1.1002\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4636 - val_loss: 0.6458\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6133 - val_loss: 0.6391\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 0.6233\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7386 - val_loss: 0.9898\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5864 - val_loss: 4.0709\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 4.7398 - val_loss: 0.6138\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6311 - val_loss: 0.6293\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7157 - val_loss: 0.6030\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 0.7518\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6897 - val_loss: 0.6230\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 0.6230\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6258 - val_loss: 1.4642\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7518 - val_loss: 0.6117\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0754 - val_loss: 0.7636\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8136 - val_loss: 0.6774\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6819 - val_loss: 0.6230\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6178 - val_loss: 0.5991\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6986 - val_loss: 0.6695\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2265 - val_loss: 0.6917\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5959 - val_loss: 0.6366\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.0663 - val_loss: 0.6247\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6673 - val_loss: 0.6405\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6173 - val_loss: 0.6006\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9644 - val_loss: 0.6099\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6429 - val_loss: 0.7316\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8539 - val_loss: 1.4126\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.6203 - val_loss: 0.6142\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6198 - val_loss: 0.6204\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6216 - val_loss: 0.6530\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6238 - val_loss: 0.6480\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6660 - val_loss: 0.7814\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9766 - val_loss: 0.6968\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6594 - val_loss: 0.7927\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9851 - val_loss: 0.8654\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8890 - val_loss: 0.6990\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6317 - val_loss: 0.5952\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6048 - val_loss: 0.5963\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6577 - val_loss: 0.6387\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6296 - val_loss: 0.5888\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 5.9144 - val_loss: 0.6383\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7186 - val_loss: 0.6139\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6222 - val_loss: 0.6590\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 2.6582 - val_loss: 0.7998\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.1514 - val_loss: 0.7236\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0410 - val_loss: 0.6147\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6219 - val_loss: 1.1479\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7235 - val_loss: 0.6638\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6313 - val_loss: 0.7266\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9370 - val_loss: 1.0270\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8094 - val_loss: 0.6541\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6702 - val_loss: 0.6188\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6846 - val_loss: 0.8073\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7608 - val_loss: 0.6063\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6393 - val_loss: 1.2377\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6927 - val_loss: 0.7763\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6337 - val_loss: 0.7214\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7897 - val_loss: 1.7296\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.6391 - val_loss: 0.8210\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7106 - val_loss: 1.3145\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6321 - val_loss: 0.7001\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6358 - val_loss: 0.7223\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.4381 - val_loss: 0.6294\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7188 - val_loss: 1.1021\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 5.5651 - val_loss: 0.7682\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.4209 - val_loss: 5.6906\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.7738 - val_loss: 0.9842\n",
      "Epoch 244/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 2.0679 - val_loss: 0.6077\n",
      "Epoch 245/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5657 - val_loss: 0.6016\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5753 - val_loss: 0.5956\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.5939\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 0.7001\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6015 - val_loss: 0.6046\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5545 - val_loss: 0.6359\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5904 - val_loss: 0.6248\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0799 - val_loss: 0.5952\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7862 - val_loss: 0.6192\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 0.5978\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5878 - val_loss: 1.1522\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1673 - val_loss: 1.5916\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3460 - val_loss: 0.5862\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6243 - val_loss: 0.5812\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7230 - val_loss: 0.5950\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 1.0175\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2992 - val_loss: 0.8924\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7279 - val_loss: 0.5971\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7755 - val_loss: 0.5877\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.8891\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 0.6062\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5918 - val_loss: 0.5929\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6294 - val_loss: 1.8593\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8652 - val_loss: 0.8665\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6502 - val_loss: 0.7106\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.8574 - val_loss: 12.7398\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.9990 - val_loss: 0.5955\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 0.6587\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7607 - val_loss: 0.5883\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6271 - val_loss: 0.6029\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5822 - val_loss: 0.5876\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6087\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6487 - val_loss: 0.9452\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6350 - val_loss: 0.6283\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0450 - val_loss: 0.6228\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7384 - val_loss: 0.6245\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6037 - val_loss: 0.7708\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9416 - val_loss: 0.5852\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5785 - val_loss: 0.5890\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0628 - val_loss: 0.5964\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7510 - val_loss: 0.6585\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6061 - val_loss: 0.5860\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6430 - val_loss: 1.0376\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8629 - val_loss: 0.5751\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 12.4964 - val_loss: 1.8247\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9652 - val_loss: 0.6371\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1472 - val_loss: 0.5781\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6895 - val_loss: 0.5820\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6056 - val_loss: 0.6174\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6405\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6066 - val_loss: 0.6205\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6112 - val_loss: 0.7916\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.6655\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7167 - val_loss: 0.6520\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6539 - val_loss: 0.8353\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6774 - val_loss: 0.6459\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5927 - val_loss: 0.7215\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6937 - val_loss: 0.5750\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5953 - val_loss: 0.6864\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 2.9112 - val_loss: 0.5845\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5547 - val_loss: 0.5751\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5711 - val_loss: 0.5795\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6342 - val_loss: 0.7322\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6096 - val_loss: 0.6030\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5703 - val_loss: 0.5778\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6808 - val_loss: 0.9592\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8009 - val_loss: 0.6075\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8167 - val_loss: 0.7226\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8025 - val_loss: 0.6774\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5938 - val_loss: 0.6068\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5708 - val_loss: 0.5846\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7451 - val_loss: 0.6061\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5967 - val_loss: 1.6337\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1340 - val_loss: 2.9405\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.5707 - val_loss: 0.5864\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5519 - val_loss: 0.6964\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6169 - val_loss: 0.7219\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6711 - val_loss: 1.0815\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9536 - val_loss: 0.6476\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5395 - val_loss: 0.5972\n",
      "Epoch 325/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5754 - val_loss: 0.5951\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7299 - val_loss: 0.5765\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6351 - val_loss: 0.5805\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8287 - val_loss: 1.0879\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1337 - val_loss: 0.8732\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.9935 - val_loss: 1.9858\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3617 - val_loss: 0.5823\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5688 - val_loss: 0.7707\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6224 - val_loss: 0.5864\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.4796 - val_loss: 2.1603\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3191 - val_loss: 0.6687\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5850 - val_loss: 0.5825\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 2.5866\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 3.1351 - val_loss: 1.1183\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.9139 - val_loss: 0.5805\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5582 - val_loss: 0.7102\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7511 - val_loss: 2.9888\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.1937 - val_loss: 0.5899\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5782 - val_loss: 0.7221\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7836 - val_loss: 0.6081\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7182 - val_loss: 0.5787\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5658 - val_loss: 0.5911\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7532 - val_loss: 0.5929\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5539 - val_loss: 0.5752\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5658 - val_loss: 0.5803\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5687 - val_loss: 3.0724\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0746 - val_loss: 0.6066\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6113 - val_loss: 0.6231\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 1.3992\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 0.5960\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7871 - val_loss: 0.5956\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6870 - val_loss: 0.7127\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8572 - val_loss: 0.5841\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5689 - val_loss: 0.6723\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5545 - val_loss: 0.5875\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5728 - val_loss: 0.6311\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5702 - val_loss: 0.6048\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5532 - val_loss: 0.8306\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0198 - val_loss: 0.5949\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5696 - val_loss: 0.5779\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5692 - val_loss: 0.5855\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5918 - val_loss: 0.7387\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5570 - val_loss: 0.5752\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6552 - val_loss: 1.1351\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8661 - val_loss: 0.5990\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6557 - val_loss: 1.2226\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6852 - val_loss: 0.5696\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6300 - val_loss: 0.5756\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7539 - val_loss: 1.3447\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7703 - val_loss: 0.8600\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.6062\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5552 - val_loss: 0.6679\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5460 - val_loss: 0.6038\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7054 - val_loss: 0.5948\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5491 - val_loss: 0.6851\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 5.1112 - val_loss: 0.6210\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.5853\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5187 - val_loss: 0.5951\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.6813\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5593 - val_loss: 0.5871\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6395 - val_loss: 0.5768\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8181 - val_loss: 0.5852\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6519 - val_loss: 0.6039\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5646 - val_loss: 0.6095\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6366 - val_loss: 0.5969\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5409 - val_loss: 0.6492\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5706 - val_loss: 0.5702\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6784 - val_loss: 0.5779\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5749 - val_loss: 1.8706\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.0457 - val_loss: 0.6061\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6308 - val_loss: 0.9435\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.7171 - val_loss: 0.6268\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.1855 - val_loss: 1.7039\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7582 - val_loss: 0.8380\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6660 - val_loss: 0.5702\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5675 - val_loss: 0.6312\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history5 = model5.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 2s 8ms/step - loss: 10.7763 - val_loss: 5.2978\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 4.2154 - val_loss: 2.5868\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 2.3950 - val_loss: 1.9923\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.8445 - val_loss: 1.3436\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3989 - val_loss: 1.3184\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3071 - val_loss: 1.3157\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2946 - val_loss: 1.3152\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3603 - val_loss: 1.3153\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3353 - val_loss: 1.3157\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3342 - val_loss: 1.3166\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3043 - val_loss: 1.3165\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3129 - val_loss: 1.3171\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.2705 - val_loss: 1.3147\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3541 - val_loss: 1.3154\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3210 - val_loss: 1.3162\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3174 - val_loss: 1.3154\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3049 - val_loss: 1.3141\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2888 - val_loss: 1.3158\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3091 - val_loss: 1.3155\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3437 - val_loss: 1.3161\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3185 - val_loss: 1.3156\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3536 - val_loss: 1.3157\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3225 - val_loss: 1.3158\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3774 - val_loss: 1.3155\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3220 - val_loss: 1.3148\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3355 - val_loss: 1.3147\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3120 - val_loss: 1.3149\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3066 - val_loss: 1.3144\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3237 - val_loss: 1.3135\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3239 - val_loss: 1.3153\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3647 - val_loss: 1.3166\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3380 - val_loss: 1.3145\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3462 - val_loss: 1.3146\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3360 - val_loss: 1.3161\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3270 - val_loss: 1.3147\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3097 - val_loss: 1.3156\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3185 - val_loss: 1.3149\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3036 - val_loss: 1.3151\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3392 - val_loss: 1.3140\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2987 - val_loss: 1.3141\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3200 - val_loss: 1.3126\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3293 - val_loss: 1.3133\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2889 - val_loss: 1.3136\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3117 - val_loss: 1.3136\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3450 - val_loss: 1.3122\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2985 - val_loss: 1.3114\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3201 - val_loss: 1.3095\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3156 - val_loss: 1.3094\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3320 - val_loss: 1.3085\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3223 - val_loss: 1.3073\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3574 - val_loss: 1.3095\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2654 - val_loss: 1.3078\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2999 - val_loss: 1.3016\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3569 - val_loss: 1.3033\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3063 - val_loss: 1.2574\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3061 - val_loss: 1.3032\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3148 - val_loss: 1.3130\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3231 - val_loss: 1.2733\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3349 - val_loss: 1.3155\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3091 - val_loss: 1.3148\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3213 - val_loss: 1.3145\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3247 - val_loss: 1.3145\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3318 - val_loss: 1.3125\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3353 - val_loss: 1.3121\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3521 - val_loss: 1.3078\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.3146 - val_loss: 1.3210\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3275 - val_loss: 1.3171\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3675 - val_loss: 1.3187\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 1.3900 - val_loss: 1.3180\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.3201 - val_loss: 1.3217\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3065 - val_loss: 1.3154\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3335 - val_loss: 1.3027\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.3310 - val_loss: 1.2810\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.2723 - val_loss: 1.1696\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2126 - val_loss: 1.2758\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.2430 - val_loss: 1.1793\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.1502 - val_loss: 1.1578\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 1.2503 - val_loss: 1.1796\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0650 - val_loss: 1.0141\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0126 - val_loss: 1.1564\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0405 - val_loss: 0.9737\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0736 - val_loss: 1.0266\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 5ms/step - loss: 1.0618 - val_loss: 0.9256\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.9779 - val_loss: 0.8320\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8677 - val_loss: 1.0443\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8921 - val_loss: 0.8445\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7943 - val_loss: 0.7821\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.8236 - val_loss: 0.8367\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.8410 - val_loss: 0.7753\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8152 - val_loss: 0.7503\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7814 - val_loss: 0.8856\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.8439 - val_loss: 0.7337\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7788 - val_loss: 0.7061\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7321 - val_loss: 0.6836\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6788 - val_loss: 0.7398\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7063 - val_loss: 0.7712\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7731 - val_loss: 0.7067\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.6521\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6833 - val_loss: 0.6387\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6734 - val_loss: 0.7144\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7241 - val_loss: 0.6831\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7414 - val_loss: 0.7338\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6907 - val_loss: 0.6380\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6957 - val_loss: 0.6630\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6918 - val_loss: 0.7024\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6907 - val_loss: 0.7601\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7328 - val_loss: 0.6491\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6389 - val_loss: 0.7648\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6601 - val_loss: 0.6536\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7220 - val_loss: 0.5992\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6391 - val_loss: 0.5975\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6209 - val_loss: 0.7252\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6759 - val_loss: 0.7421\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6788 - val_loss: 0.6333\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6221 - val_loss: 0.6323\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6690 - val_loss: 0.6274\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 0.6474\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6170 - val_loss: 0.5937\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6391 - val_loss: 0.6452\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6579 - val_loss: 0.9351\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.5989\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6053 - val_loss: 0.6343\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6002 - val_loss: 0.5886\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6483 - val_loss: 0.7847\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.7863 - val_loss: 0.6582\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6559 - val_loss: 0.6892\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6297 - val_loss: 0.5799\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5776 - val_loss: 0.6072\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.5848\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6688 - val_loss: 0.5855\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6247 - val_loss: 0.5894\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6668 - val_loss: 0.6408\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 1.0641 - val_loss: 0.8419\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.7736 - val_loss: 0.6421\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6156 - val_loss: 0.6041\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6240 - val_loss: 0.5971\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6128 - val_loss: 0.5973\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6431 - val_loss: 0.6702\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6670 - val_loss: 0.6073\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5853 - val_loss: 0.5697\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6019 - val_loss: 0.5946\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 0.5995\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5840 - val_loss: 0.5545\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5912 - val_loss: 0.5659\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5867 - val_loss: 0.5932\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5589 - val_loss: 0.5686\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5684 - val_loss: 0.5683\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5897 - val_loss: 0.5556\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6440 - val_loss: 0.6716\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6324 - val_loss: 0.5523\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5293 - val_loss: 0.5905\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5760 - val_loss: 0.5761\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5894 - val_loss: 0.6236\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.5463\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5763 - val_loss: 0.5915\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5697 - val_loss: 0.6005\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6396 - val_loss: 0.6627\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6623 - val_loss: 0.5590\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5723 - val_loss: 0.5779\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5887 - val_loss: 0.5948\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5194 - val_loss: 0.5543\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6024 - val_loss: 0.5581\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5825 - val_loss: 0.5879\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5500 - val_loss: 0.5786\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5787 - val_loss: 0.5401\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5542 - val_loss: 0.5980\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5547 - val_loss: 0.5610\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5544 - val_loss: 0.6271\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6129 - val_loss: 0.6208\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5740 - val_loss: 0.6832\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6689 - val_loss: 0.5445\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5489 - val_loss: 0.5973\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6386\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5974 - val_loss: 0.6666\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5724 - val_loss: 0.5474\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5339 - val_loss: 0.5766\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5471 - val_loss: 0.6896\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5688 - val_loss: 0.5651\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5809 - val_loss: 0.6212\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5860 - val_loss: 0.5933\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 0.7383\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5646 - val_loss: 0.7234\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5958 - val_loss: 0.5742\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5483 - val_loss: 0.5248\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5521 - val_loss: 0.6816\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6084 - val_loss: 0.5400\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5207 - val_loss: 0.5649\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5625 - val_loss: 0.5456\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4914 - val_loss: 0.5302\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5811 - val_loss: 0.5377\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5587 - val_loss: 0.5475\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5523 - val_loss: 0.6826\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6097 - val_loss: 0.5535\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5588 - val_loss: 0.5681\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5906 - val_loss: 0.6354\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5627 - val_loss: 0.5546\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6426 - val_loss: 0.5265\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5472 - val_loss: 0.5222\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5017 - val_loss: 0.5705\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5331 - val_loss: 0.6327\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5737 - val_loss: 0.5552\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5631 - val_loss: 0.5366\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5130 - val_loss: 0.5300\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5452 - val_loss: 0.5266\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5540 - val_loss: 0.5206\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5452 - val_loss: 0.5444\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5797 - val_loss: 0.7053\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5871 - val_loss: 0.5462\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5517 - val_loss: 0.5351\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5432 - val_loss: 0.5262\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5838 - val_loss: 0.5209\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5337 - val_loss: 0.5334\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5251 - val_loss: 0.5610\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5186 - val_loss: 0.5246\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5189 - val_loss: 0.5188\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5245 - val_loss: 0.5188\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5336 - val_loss: 0.5403\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5348 - val_loss: 0.5412\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5521 - val_loss: 0.8619\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6969 - val_loss: 0.5769\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5841 - val_loss: 0.5471\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 0.5494\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5291 - val_loss: 0.5490\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5722 - val_loss: 0.6594\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5749 - val_loss: 0.5226\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5569 - val_loss: 0.6272\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5604 - val_loss: 0.5458\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5342 - val_loss: 0.5371\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5247 - val_loss: 0.5143\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5039 - val_loss: 0.5331\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5216 - val_loss: 0.5251\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5613 - val_loss: 0.5456\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5370 - val_loss: 0.6084\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5500 - val_loss: 0.5374\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5338 - val_loss: 0.6400\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5504 - val_loss: 0.5818\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5257 - val_loss: 0.5216\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5336 - val_loss: 0.5150\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5008 - val_loss: 0.5486\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5169 - val_loss: 0.5632\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5463 - val_loss: 0.5185\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5339 - val_loss: 0.5216\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5166 - val_loss: 0.5681\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5428 - val_loss: 0.5542\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5222 - val_loss: 0.5236\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5333 - val_loss: 0.5172\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5012 - val_loss: 0.5683\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5337 - val_loss: 0.5639\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5789 - val_loss: 0.5933\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5394 - val_loss: 0.6024\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5710 - val_loss: 0.6566\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6318 - val_loss: 0.5719\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5490 - val_loss: 0.5453\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5269 - val_loss: 0.5118\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5106 - val_loss: 0.5162\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5377 - val_loss: 0.5496\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.5473\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5647 - val_loss: 0.5500\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5443 - val_loss: 0.5932\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5558 - val_loss: 0.5494\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5075 - val_loss: 0.5210\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5094 - val_loss: 0.5475\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5145 - val_loss: 0.5314\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5207 - val_loss: 0.5164\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5339 - val_loss: 0.6298\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 0.5184\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5170 - val_loss: 0.6096\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5559 - val_loss: 0.5815\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5218 - val_loss: 0.5244\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5410 - val_loss: 0.5378\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5213 - val_loss: 0.5303\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5546 - val_loss: 0.5232\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5511 - val_loss: 0.5433\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5627 - val_loss: 0.5118\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5097 - val_loss: 0.6102\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5323 - val_loss: 0.5091\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5128 - val_loss: 0.5313\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.6152 - val_loss: 0.5494\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5210 - val_loss: 0.5936\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5342 - val_loss: 0.5336\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4911 - val_loss: 0.5437\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5316 - val_loss: 0.5236\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5141 - val_loss: 0.5372\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5360 - val_loss: 0.5157\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5091 - val_loss: 0.5255\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5216 - val_loss: 0.5085\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5350 - val_loss: 0.5316\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5208 - val_loss: 0.5037\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.6511 - val_loss: 0.5349\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5492 - val_loss: 0.6086\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5701 - val_loss: 0.5262\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5371 - val_loss: 0.5359\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5281 - val_loss: 0.5481\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5258 - val_loss: 0.5634\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5381 - val_loss: 0.5128\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4981 - val_loss: 0.5115\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4994 - val_loss: 0.5291\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5227 - val_loss: 0.5312\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5770 - val_loss: 0.5190\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5171 - val_loss: 0.5392\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4989 - val_loss: 0.5056\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4754 - val_loss: 0.5066\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4879 - val_loss: 0.5516\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4890 - val_loss: 0.5031\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4799 - val_loss: 0.5240\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5751 - val_loss: 0.5560\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4931 - val_loss: 0.5499\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5530 - val_loss: 0.5108\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5214 - val_loss: 0.5059\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5021 - val_loss: 0.5093\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - val_loss: 0.5146\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5046 - val_loss: 0.5075\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5207 - val_loss: 0.5179\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5461 - val_loss: 0.5338\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4941 - val_loss: 0.5050\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5250 - val_loss: 0.5115\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4953 - val_loss: 0.5029\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5015 - val_loss: 0.5893\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5599 - val_loss: 0.6648\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5714 - val_loss: 0.5265\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5062 - val_loss: 0.5082\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5122 - val_loss: 0.5378\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5954 - val_loss: 0.5133\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4866 - val_loss: 0.6849\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5654 - val_loss: 0.5422\n",
      "Epoch 326/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5050 - val_loss: 0.5498\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4972 - val_loss: 0.5329\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4999 - val_loss: 0.5253\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5037 - val_loss: 0.5014\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4749 - val_loss: 0.5601\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5089 - val_loss: 0.5103\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5010 - val_loss: 0.5235\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4862 - val_loss: 0.5010\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4978 - val_loss: 0.5028\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5136 - val_loss: 0.5054\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5067 - val_loss: 0.5428\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4859 - val_loss: 0.5663\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5237 - val_loss: 0.4953\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5163 - val_loss: 0.5346\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5087 - val_loss: 0.4952\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4966 - val_loss: 0.5049\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5220 - val_loss: 0.5246\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5065 - val_loss: 0.5600\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5217 - val_loss: 0.5706\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5814 - val_loss: 0.5052\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4893 - val_loss: 0.5220\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4947 - val_loss: 0.5063\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4854 - val_loss: 0.4922\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4908 - val_loss: 0.5013\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4766 - val_loss: 0.5166\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5123 - val_loss: 0.5381\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5411 - val_loss: 0.5877\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5097 - val_loss: 0.5024\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4724 - val_loss: 0.4956\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5074 - val_loss: 0.5071\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5095 - val_loss: 0.4974\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4765 - val_loss: 0.5025\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4973 - val_loss: 0.5013\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4924 - val_loss: 0.4942\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4828 - val_loss: 0.5408\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5086 - val_loss: 0.4896\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4579 - val_loss: 0.4944\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4905 - val_loss: 0.5061\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4951 - val_loss: 0.5448\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5037 - val_loss: 0.5353\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4944 - val_loss: 0.4885\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4706 - val_loss: 0.4945\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5167 - val_loss: 0.5205\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5039 - val_loss: 0.5288\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 0.5067\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4923 - val_loss: 0.5241\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5156 - val_loss: 0.5008\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4585 - val_loss: 0.4981\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4670 - val_loss: 0.4962\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4835 - val_loss: 0.5458\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4970 - val_loss: 0.4948\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4821 - val_loss: 0.5089\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4974 - val_loss: 0.6067\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5186 - val_loss: 0.5060\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5028 - val_loss: 0.4875\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4841 - val_loss: 0.6484\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.5449 - val_loss: 0.5272\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4863 - val_loss: 0.5038\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4799 - val_loss: 0.5107\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.5030 - val_loss: 0.4852\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.4984 - val_loss: 0.4978\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4900 - val_loss: 0.5823\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5453 - val_loss: 0.5304\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.5023 - val_loss: 0.5458\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.5000 - val_loss: 0.4956\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4807 - val_loss: 0.4913\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4876 - val_loss: 0.4870\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.4470 - val_loss: 0.6099\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5038 - val_loss: 0.5138\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4827 - val_loss: 0.5477\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.5350 - val_loss: 0.4956\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4456 - val_loss: 0.4927\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.4759 - val_loss: 0.5682\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.481 - 0s 4ms/step - loss: 0.4863 - val_loss: 0.5294\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.4905 - val_loss: 0.4914\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history6 = model6.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,041\n",
      "Trainable params: 1,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "model2.summary()\n",
    "model3.summary()\n",
    "model4.summary()\n",
    "model5.summary()\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Hidden_layer</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>activation_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>-0.000122335</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>-0.00685839</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu, sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>-1.78934e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh, softmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>0.476327</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>0.519603</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu,relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.626026</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu,relu,sigmoid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2_score  Hidden_layer  Learning_rate      activation_fn\n",
       "model_1 -0.000122335             2         0.0100          relu,relu\n",
       "model_2  -0.00685839             2         0.0100      relu, sigmoid\n",
       "model_3 -1.78934e-06             2         0.0100      tanh, softmax\n",
       "model_4     0.476327             2         0.0001          relu,relu\n",
       "model_5     0.519603             3         0.0010     relu,relu,relu\n",
       "model_6     0.626026             3         0.0010  relu,relu,sigmoid"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r2_score of six models with different parameter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "col = ['R2_score'] \n",
    "ind = ['model_%.0g'%i for i in range(1,7)]\n",
    "summary1 = pd.DataFrame(index=ind, columns=col) #summary table\n",
    "\n",
    "j = 0\n",
    "for i in [model1,model2,model3,model4,model5,model6]: \n",
    "    y_predv = i.predict(X_valid)\n",
    "    summary1.iloc[j,0] = r2_score(Y_valid, y_predv) #R2_score when applying on validation set\n",
    "    j = j+1\n",
    "summary1\n",
    "\n",
    "#Details of each models\n",
    "des = {'Hidden_layer': [2, 2,2,2,3,3], 'Learning_rate': [0.01, 0.01, 0.01, 0.0001,0.001,0.001], 'activation_fn': ['relu,relu', 'relu, sigmoid','tanh, softmax','relu,relu','relu,relu,relu', 'relu,relu,sigmoid'] }\n",
    "desdf = pd.DataFrame(des, index=ind)\n",
    "\n",
    "#Combine two tables (performance and Details of each models)\n",
    "summaryfinal = pd.concat([summary1 ,desdf], axis = 1 )\n",
    "\n",
    "summaryfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>-0.000251876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.631266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2_score\n",
       "model_1 -0.000251876\n",
       "model_6     0.631266"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################Step 3 Apply the model on testing set#############################\n",
    "col = ['R2_score']\n",
    "ind = ['model_%.0g'%i for i in [1,6]]\n",
    "summary2 = pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "j = 0\n",
    "for i in [model1,model6]:\n",
    "    y_pred = i.predict(X_test) #applying models on testing set\n",
    "    summary2.iloc[j,0] = r2_score(Y_test, y_pred) #R2_score when applying on testing set\n",
    "    j = j+1\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 4 Analyze the testing results #############################\n",
    "Y_pred6 = model6.predict(X_test)\n",
    "error = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    errors = abs(Y_pred6[i,0]- Y_test[i])  #Calucate absolute value of error\n",
    "    error.append(errors )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary3 = pd.DataFrame(\n",
    "{'Y_value': Y_test,\n",
    " 'Y_hat': Y_pred6[:,0], \n",
    " 'abs(error)': error  # Calucate absolute value of error\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind2 = ['feature_%.0g'%i for i in [1,6]]\n",
    "X_testdf = pd.DataFrame(X_test, columns= ca_house_db.feature_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([summary3 ,X_testdf], axis = 1 ) #merge data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top  = total.sort_values(by='abs(error)', ascending=False).head(10) #sorting the dataframe following to abs of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average/Meadian/max/min of each features.\n",
    "\n",
    "avg = pd.DataFrame(total.mean(axis = 0)).T #mean\n",
    "med = pd.DataFrame(total.median(axis = 0)).T \n",
    "maxs = pd.DataFrame(total.max(axis = 0)).T \n",
    "mins = pd.DataFrame(total.min(axis = 0)).T\n",
    "top.loc[\"mean_sample\",:] = avg.iloc[0,:] \n",
    "top.loc[\"median_sample\",:] = med.iloc[0,:] \n",
    "top.loc[\"max_sample\",:] = maxs.iloc[0,:]\n",
    "top.loc[\"mins_sample\",:] = mins.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_value</th>\n",
       "      <th>Y_hat</th>\n",
       "      <th>abs(error)</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.193820</td>\n",
       "      <td>3.806190</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.373272</td>\n",
       "      <td>1.055300</td>\n",
       "      <td>2690.000000</td>\n",
       "      <td>12.396313</td>\n",
       "      <td>34.020000</td>\n",
       "      <td>-118.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.193822</td>\n",
       "      <td>3.806188</td>\n",
       "      <td>1.169600</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.436000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>1349.000000</td>\n",
       "      <td>5.396000</td>\n",
       "      <td>37.870000</td>\n",
       "      <td>-122.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.193838</td>\n",
       "      <td>3.806172</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.425197</td>\n",
       "      <td>1.125984</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>2.833071</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>-120.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.193840</td>\n",
       "      <td>3.806170</td>\n",
       "      <td>4.203900</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.753927</td>\n",
       "      <td>1.031414</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>4.612565</td>\n",
       "      <td>37.190000</td>\n",
       "      <td>-121.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8325</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.297806</td>\n",
       "      <td>3.702204</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.297872</td>\n",
       "      <td>1.175532</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1.610372</td>\n",
       "      <td>37.780000</td>\n",
       "      <td>-122.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>1.125000</td>\n",
       "      <td>4.814892</td>\n",
       "      <td>3.689892</td>\n",
       "      <td>12.538100</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>6.888889</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>33.960000</td>\n",
       "      <td>-117.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.324971</td>\n",
       "      <td>3.675039</td>\n",
       "      <td>5.206600</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.445652</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>3.380435</td>\n",
       "      <td>33.510000</td>\n",
       "      <td>-117.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.357489</td>\n",
       "      <td>3.642511</td>\n",
       "      <td>2.353600</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.826563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>3.973438</td>\n",
       "      <td>34.050000</td>\n",
       "      <td>-118.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.359542</td>\n",
       "      <td>3.640468</td>\n",
       "      <td>4.975700</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.049608</td>\n",
       "      <td>1.101828</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>5.208877</td>\n",
       "      <td>34.470000</td>\n",
       "      <td>-119.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.191810</td>\n",
       "      <td>3.558190</td>\n",
       "      <td>3.729200</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>-121.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sample</th>\n",
       "      <td>2.066012</td>\n",
       "      <td>2.142076</td>\n",
       "      <td>0.529594</td>\n",
       "      <td>3.871337</td>\n",
       "      <td>28.619864</td>\n",
       "      <td>5.445038</td>\n",
       "      <td>1.099305</td>\n",
       "      <td>1422.299612</td>\n",
       "      <td>3.113793</td>\n",
       "      <td>35.632167</td>\n",
       "      <td>-119.565215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_sample</th>\n",
       "      <td>1.785000</td>\n",
       "      <td>1.919566</td>\n",
       "      <td>0.423880</td>\n",
       "      <td>3.522700</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.236540</td>\n",
       "      <td>1.047404</td>\n",
       "      <td>1165.000000</td>\n",
       "      <td>2.823360</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_sample</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>4.816358</td>\n",
       "      <td>3.806190</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>25.636364</td>\n",
       "      <td>28566.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mins_sample</th>\n",
       "      <td>0.149990</td>\n",
       "      <td>-0.566310</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y_value     Y_hat  abs(error)     MedInc   HouseAge  \\\n",
       "1902           5.000010  1.193820    3.806190   0.499900  29.000000   \n",
       "7378           5.000010  1.193822    3.806188   1.169600  52.000000   \n",
       "2781           5.000010  1.193838    3.806172   0.702500  19.000000   \n",
       "5291           5.000010  1.193840    3.806170   4.203900  11.000000   \n",
       "8325           5.000010  1.297806    3.702204   0.854300  27.000000   \n",
       "4604           1.125000  4.814892    3.689892  12.538100  29.000000   \n",
       "8206           5.000010  1.324971    3.675039   5.206600   4.000000   \n",
       "4739           5.000000  1.357489    3.642511   2.353600  26.000000   \n",
       "6857           5.000010  1.359542    3.640468   4.975700  35.000000   \n",
       "9313           4.750000  1.191810    3.558190   3.729200   6.000000   \n",
       "mean_sample    2.066012  2.142076    0.529594   3.871337  28.619864   \n",
       "median_sample  1.785000  1.919566    0.423880   3.522700  29.000000   \n",
       "max_sample     5.000010  4.816358    3.806190  15.000100  52.000000   \n",
       "mins_sample    0.149990 -0.566310    0.000060   0.499900   1.000000   \n",
       "\n",
       "                 AveRooms  AveBedrms    Population     AveOccup   Latitude  \\\n",
       "1902             2.373272   1.055300   2690.000000    12.396313  34.020000   \n",
       "7378             2.436000   0.944000   1349.000000     5.396000  37.870000   \n",
       "2781             2.425197   1.125984   1799.000000     2.833071  35.300000   \n",
       "5291             6.753927   1.031414    881.000000     4.612565  37.190000   \n",
       "8325             2.297872   1.175532   1211.000000     1.610372  37.780000   \n",
       "4604             6.888889   1.222222     50.000000     2.777778  33.960000   \n",
       "8206            10.500000   1.445652    311.000000     3.380435  33.510000   \n",
       "4739             2.826563   1.000000   2543.000000     3.973438  34.050000   \n",
       "6857             7.049608   1.101828   1995.000000     5.208877  34.470000   \n",
       "9313             4.583333   1.083333     69.000000     2.875000  37.800000   \n",
       "mean_sample      5.445038   1.099305   1422.299612     3.113793  35.632167   \n",
       "median_sample    5.236540   1.047404   1165.000000     2.823360  34.260000   \n",
       "max_sample     141.909091  25.636364  28566.000000  1243.333333  41.950000   \n",
       "mins_sample      0.846154   0.375000      5.000000     0.692308  32.540000   \n",
       "\n",
       "                Longitude  \n",
       "1902          -118.280000  \n",
       "7378          -122.250000  \n",
       "2781          -120.670000  \n",
       "5291          -121.740000  \n",
       "8325          -122.420000  \n",
       "4604          -117.440000  \n",
       "8206          -117.320000  \n",
       "4739          -118.310000  \n",
       "6857          -119.670000  \n",
       "9313          -121.290000  \n",
       "mean_sample   -119.565215  \n",
       "median_sample -118.510000  \n",
       "max_sample    -114.490000  \n",
       "mins_sample   -124.300000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "############End Part4############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-3aa8a9bdb2c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "total.mean(axis = 0).shape\n",
    "df.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanv = total.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.mean(axis = 0).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from compiler.ast import flatten\n",
    "avg = pd.DataFrame(total.mean(axis = 0)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model1.evaluate(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict  = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('MSE:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))\n",
    "print('r2_score', r2_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss_df1 = pd.DataFrame(model1.history.history)\n",
    "\n",
    "\n",
    "#loss_df1.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "plot_loss(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
