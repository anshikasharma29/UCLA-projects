{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5bb1b42c4322>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from util import func_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "#from util import func_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "#from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_house_db = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ...,\n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]), 'frame': None, 'target_names': ['MedHouseVal'], 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(ca_house_db.data.shape)\n",
    "print(ca_house_db.target.shape)\n",
    "print(ca_house_db.feature_names)\n",
    "print(ca_house_db.DESCR)\n",
    "print(ca_house_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "#from util import func_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "#from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5684eb98951b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error \n",
    "\n",
    "print(\"version: \", tf.__version__)\n",
    "print(\"Hub bersion: \", hub.__version__)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ca_house_db.target\n",
    "X = ca_house_db.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 1 Data splitting################################\n",
    "#split samples into two halves (traning process and testing process)\n",
    "X_1, X_test, Y_1, Y_test = train_test_split(X,Y,train_size = 0.5,random_state = 0)\n",
    "#subset of 2064 samples for validation purpose and the rest 8256 samples for training\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_1,Y_1,train_size = (8256/X_1.shape[0]),random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10320, 8) (10320, 8) (10320,) (8256, 8) (2064, 8) (8256,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape, X_test.shape, Y_1.shape, X_train.shape,X_valid.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 2 Model selection################################\n",
    "#Apecify at least three sets of hyper-parameters \n",
    "#Parameter includes 1.number of hidden layers 2.learning rate 3.activation fn\n",
    "# define the keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "seed_value = 0\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model1.add(Dense(15,activation='relu')) #hidden layer2\n",
    "model1.add(Dense(1)) #outputlayer\n",
    "model1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model2.add(Dense(15,activation='sigmoid')) #hidden layer2, activation fn = \"sigmoid\"\n",
    "model2.add(Dense(1)) #outputlayer\n",
    "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(15,activation='tanh')) #hidden layer1, activation fn = \"tanh\"\n",
    "model3.add(Dense(15,activation='softmax')) #hidden layer2, activation fn = \"softmax\"\n",
    "model3.add(Dense(1)) #outputlayer\n",
    "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),loss='mse') #learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model4.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model4.add(Dense(1)) #outputlayer\n",
    "model4.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss='mse') #learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(15,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model5.add(Dense(1)) #outputlayer\n",
    "model5.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='mse') #learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "model6 = Sequential()\n",
    "model6.add(Dense(20,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model6.add(Dense(20,activation='relu')) #hidden layer1, activation fn = \"relu\"\n",
    "model6.add(Dense(20,activation='sigmoid')) #hidden layer1, activation fn = \"sigmoid\"\n",
    "model6.add(Dense(1))  #outputlayer\n",
    "model6.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='mse') #learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 113234.2198 - val_loss: 19.9821\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 39.3364 - val_loss: 16.4531\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 16.1020 - val_loss: 13.4301\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 15.1897 - val_loss: 12.1108\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 11.9924 - val_loss: 10.5625\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 9.9325 - val_loss: 7.6282\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 6.6069 - val_loss: 3.8587\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.6572 - val_loss: 2.6913\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.9001 - val_loss: 2.6004\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.7630 - val_loss: 2.1207\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.4032 - val_loss: 2.0698\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.1172 - val_loss: 1.5948\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7380 - val_loss: 1.6554\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9933 - val_loss: 1.6172\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5246 - val_loss: 1.1893\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2958 - val_loss: 2.1231\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3423 - val_loss: 1.0392\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6129 - val_loss: 1.2525\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1680 - val_loss: 1.0093\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4081 - val_loss: 0.9523\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0779 - val_loss: 1.5609\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2276 - val_loss: 0.9003\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2066 - val_loss: 0.9699\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1395 - val_loss: 0.8249\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9257 - val_loss: 0.8063\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0128 - val_loss: 42.8703\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 16.3860 - val_loss: 1.0312\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4214 - val_loss: 0.8623\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0790 - val_loss: 1.5848\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2514 - val_loss: 1.1428\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2296 - val_loss: 0.8058\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9784 - val_loss: 0.8097\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3672 - val_loss: 0.9502\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9697 - val_loss: 0.7637\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8741 - val_loss: 0.7928\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9224 - val_loss: 0.7750\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9890 - val_loss: 0.8124\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2917 - val_loss: 1.1218\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0642 - val_loss: 0.7119\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7598 - val_loss: 0.7945\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8931 - val_loss: 0.6696\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0783 - val_loss: 0.7532\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9272 - val_loss: 0.6936\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9632 - val_loss: 9.4322\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.9805 - val_loss: 2.9346\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5428 - val_loss: 0.7143\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7736 - val_loss: 0.7388\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7785 - val_loss: 0.8751\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7813 - val_loss: 0.8636\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7838 - val_loss: 0.9185\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7794 - val_loss: 0.6721\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1046 - val_loss: 0.6472\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8815 - val_loss: 0.6706\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0635 - val_loss: 0.6436\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7539 - val_loss: 0.6660\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7598 - val_loss: 0.9653\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8530 - val_loss: 0.8078\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8888 - val_loss: 2.6397\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3259 - val_loss: 0.8125\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1864 - val_loss: 0.6425\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7542 - val_loss: 0.6258\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0072 - val_loss: 0.6444\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8095 - val_loss: 2.3506\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0462 - val_loss: 0.7125\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1336 - val_loss: 0.8730\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4559 - val_loss: 14.6282\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 13.9016 - val_loss: 1.0237\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8001 - val_loss: 0.7334\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8828 - val_loss: 0.6430\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8365 - val_loss: 0.6472\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8428 - val_loss: 4.1771\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.1576 - val_loss: 0.9297\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1759 - val_loss: 0.9274\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1646 - val_loss: 2.2593\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4528 - val_loss: 0.6503\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7384 - val_loss: 0.8439\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7787 - val_loss: 0.6614\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.8067 - val_loss: 0.7225\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7546 - val_loss: 0.6434\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 12.0372 - val_loss: 1.7535\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5380 - val_loss: 3.0557\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.9753 - val_loss: 6.5123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.4827 - val_loss: 3.5680\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.6371 - val_loss: 0.7017\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7722 - val_loss: 0.6954\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6743 - val_loss: 1.1497\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8570 - val_loss: 2.0758\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 11.5709 - val_loss: 1.1688\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5775 - val_loss: 0.8081\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0372 - val_loss: 0.7817\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4442 - val_loss: 23.5359\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 119.9110 - val_loss: 24.7631\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 13.2966 - val_loss: 1.3550\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3835 - val_loss: 1.1638\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1930 - val_loss: 1.1684\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6275 - val_loss: 0.9638\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9990 - val_loss: 0.8964\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9249 - val_loss: 0.9694\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9747 - val_loss: 0.8327\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8691 - val_loss: 0.8190\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9205 - val_loss: 0.8826\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0771 - val_loss: 0.8146\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9676 - val_loss: 0.8100\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 0.9175\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9023 - val_loss: 1.2754\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0620 - val_loss: 0.8596\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1560 - val_loss: 0.7738\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9228 - val_loss: 1.3842\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9745 - val_loss: 1.0282\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8361 - val_loss: 4.7008\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.2718 - val_loss: 0.7294\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9042 - val_loss: 0.6866\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9357 - val_loss: 0.6725\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6847 - val_loss: 0.6779\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7126 - val_loss: 1.0772\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2842 - val_loss: 0.6879\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6905 - val_loss: 0.6880\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7134 - val_loss: 0.6748\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6960 - val_loss: 0.6766\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8341 - val_loss: 0.8703\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8533 - val_loss: 1.0586\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1894 - val_loss: 51.3282\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 56.0895 - val_loss: 6.6687\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.2709 - val_loss: 0.7247\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2046 - val_loss: 0.6847\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7126 - val_loss: 0.6837\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7795 - val_loss: 0.8605\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1743 - val_loss: 0.7257\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7253 - val_loss: 0.6994\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6883 - val_loss: 1.8052\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9831 - val_loss: 0.6657\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7188 - val_loss: 0.6767\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0165 - val_loss: 0.6966\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8889 - val_loss: 0.8536\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8181 - val_loss: 0.6653\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7141 - val_loss: 0.8398\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7858 - val_loss: 0.6392\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6834 - val_loss: 0.7234\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7039 - val_loss: 0.6448\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6758 - val_loss: 1.1032\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8557 - val_loss: 0.7618\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7124 - val_loss: 1.6177\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9696 - val_loss: 0.7259\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8949 - val_loss: 0.6528\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3029 - val_loss: 0.6374\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9685 - val_loss: 6.2130\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6238 - val_loss: 1.8204\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3165 - val_loss: 0.9732\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.4753 - val_loss: 31.4779\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 11.9060 - val_loss: 1.3933\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0605 - val_loss: 0.9123\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7313 - val_loss: 0.6357\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6641 - val_loss: 0.6265\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6767 - val_loss: 0.6319\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7534 - val_loss: 0.8439\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9338\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0442 - val_loss: 1.3241\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9619 - val_loss: 0.9431\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7551 - val_loss: 1.0586\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8769 - val_loss: 0.6940\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8606 - val_loss: 0.6308\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6971 - val_loss: 0.6587\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8120 - val_loss: 0.6666\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6240 - val_loss: 0.6755\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6790 - val_loss: 0.7681\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6985 - val_loss: 0.8352\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9044 - val_loss: 0.6925\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0905 - val_loss: 2.5350\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9951 - val_loss: 0.6957\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7357 - val_loss: 15.4408\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7.6461 - val_loss: 0.7092\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.5665 - val_loss: 0.7195\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7721 - val_loss: 0.6206\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8860 - val_loss: 0.7334\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6645 - val_loss: 0.7065\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6775 - val_loss: 0.6831\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6606 - val_loss: 0.6134\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6319 - val_loss: 0.6564\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6789 - val_loss: 0.6716\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6660 - val_loss: 0.6243\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6311 - val_loss: 0.7157\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6551 - val_loss: 0.8948\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0428 - val_loss: 0.6152\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6263 - val_loss: 0.6164\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7334 - val_loss: 0.5988\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6210 - val_loss: 0.6769\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6208\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.5953\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6431 - val_loss: 1.1374\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7962 - val_loss: 0.6016\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6559 - val_loss: 0.6949\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1256 - val_loss: 0.6426\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6413 - val_loss: 0.6015\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6430 - val_loss: 0.5878\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6150 - val_loss: 0.5866\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6264 - val_loss: 0.5893\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7623 - val_loss: 0.5813\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8011 - val_loss: 0.9209\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.9885 - val_loss: 1.7051\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4951 - val_loss: 1.3206\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.9309 - val_loss: 0.9479\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0847 - val_loss: 0.7346\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7943 - val_loss: 0.9132\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8376 - val_loss: 0.7002\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7183 - val_loss: 0.8168\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8022 - val_loss: 0.6448\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6713 - val_loss: 0.6823\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7426 - val_loss: 0.6520\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6762 - val_loss: 0.6577\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6644 - val_loss: 0.6320\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6789 - val_loss: 0.6828\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7004 - val_loss: 0.6168\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6746 - val_loss: 0.6241\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6262 - val_loss: 0.6492\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6619 - val_loss: 0.6241\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6483 - val_loss: 0.6358\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6157\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6775 - val_loss: 0.8038\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7158 - val_loss: 0.6521\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0408 - val_loss: 0.6538\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0771 - val_loss: 0.6096\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6098\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6210 - val_loss: 0.6134\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6274 - val_loss: 0.6496\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6581 - val_loss: 0.6312\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6634 - val_loss: 0.7273\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7196 - val_loss: 0.5955\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7119 - val_loss: 0.9641\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7530 - val_loss: 0.8498\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6936 - val_loss: 0.5839\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6125\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.6191\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7439 - val_loss: 0.5909\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5801 - val_loss: 0.9695\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8722 - val_loss: 0.6040\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6568 - val_loss: 0.5898\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.5859 - val_loss: 0.5709\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6202 - val_loss: 0.5838\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6800 - val_loss: 0.5756\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6123 - val_loss: 1.5121\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8863 - val_loss: 0.6308\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6690 - val_loss: 0.6153\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7734 - val_loss: 0.7568\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1340 - val_loss: 0.6315\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6037\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5785\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5874 - val_loss: 0.5781\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5757 - val_loss: 0.6377\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.5636\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.5767\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5869 - val_loss: 0.5554\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7856 - val_loss: 0.6718\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6346 - val_loss: 0.5821\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7163 - val_loss: 0.5972\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 1.1311\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7260 - val_loss: 0.8378\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6392 - val_loss: 0.5631\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.5465\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6715 - val_loss: 0.6041\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6172 - val_loss: 0.6081\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5481 - val_loss: 0.5568\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5864 - val_loss: 0.6429\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6654 - val_loss: 0.5999\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5630 - val_loss: 0.5331\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5615\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5373 - val_loss: 0.6761\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 0.6559\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5870 - val_loss: 2.4668\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2876 - val_loss: 0.8854\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8844 - val_loss: 0.6250\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6757 - val_loss: 0.6223\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6679 - val_loss: 0.6080\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7326 - val_loss: 0.7226\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7078 - val_loss: 0.7114\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6165 - val_loss: 0.6099\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6243 - val_loss: 0.6157\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.5895\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5917 - val_loss: 0.6380\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5614\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5920 - val_loss: 0.6271\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5618 - val_loss: 0.5673\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5704 - val_loss: 0.8667\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6677 - val_loss: 0.6547\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 0.5885\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6301 - val_loss: 0.6293\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6388 - val_loss: 0.6036\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6116 - val_loss: 0.5805\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6508 - val_loss: 0.5729\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6477 - val_loss: 0.5454\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5514\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.5654\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 0.7987\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.5548\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5438 - val_loss: 0.6292\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.5138\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6035 - val_loss: 0.5801\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.5755\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6760 - val_loss: 0.5209\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.6629\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5643 - val_loss: 0.5046\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5419\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5784 - val_loss: 0.6359\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6625 - val_loss: 0.5917\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6387 - val_loss: 0.5560\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6371\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.5496\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5604 - val_loss: 0.5660\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5531 - val_loss: 0.5827\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.5383\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.7141\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5957 - val_loss: 0.6094\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.5314\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7531 - val_loss: 0.6338\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 0.6066\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6585\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6161\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.6346\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6050\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6632\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6334 - val_loss: 0.5879\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6861\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6701 - val_loss: 0.5896\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.5983\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5741\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.5670\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.5871\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6439\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6782\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 0.5636\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.8065\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 0.5735\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.5762\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5629 - val_loss: 0.5588\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6151 - val_loss: 0.5689\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5938 - val_loss: 0.6228\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5897 - val_loss: 0.5640\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5624 - val_loss: 0.6261\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6528 - val_loss: 0.6062\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6286 - val_loss: 0.5920\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6240 - val_loss: 0.5545\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5741 - val_loss: 0.5478\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5980\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5913 - val_loss: 0.6824\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6597 - val_loss: 0.5353\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5387 - val_loss: 0.5186\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5315 - val_loss: 0.5505\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5471 - val_loss: 0.5264\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.5128\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7575 - val_loss: 0.5658\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5665 - val_loss: 0.5708\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5765\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6140\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5676 - val_loss: 0.5520\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.8394\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6617 - val_loss: 0.5424\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.5500\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.9653\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7166 - val_loss: 0.5490\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5722 - val_loss: 0.5717\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.5452\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5554 - val_loss: 0.5442\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5372 - val_loss: 1.0745\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7573 - val_loss: 0.5647\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5557 - val_loss: 0.5424\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5253\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5487 - val_loss: 0.5353\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5365 - val_loss: 0.7399\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7176 - val_loss: 0.5270\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5269\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5562 - val_loss: 0.5698\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.5581\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6222\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.5858\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.5708\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5543 - val_loss: 0.5211\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.5301\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.5292\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5171\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5415 - val_loss: 0.7245\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6743 - val_loss: 0.5114\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5149\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4960 - val_loss: 0.5027\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5047 - val_loss: 0.5092\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5183 - val_loss: 0.7142\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.5216\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5150\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5393\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5489\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.4971\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 0.5093\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5054 - val_loss: 0.5473\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.4918\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.5176\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5650 - val_loss: 0.5891\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 0.5740\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5027\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.4944\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.4964\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 1.0800\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.5085\n"
     ]
    }
   ],
   "source": [
    "#Step2\n",
    "# Train the the FNN model on the training samples\n",
    "#iteration. = samplesize/batch size\n",
    "#gradient weight u\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "history1 = model1.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 5.3673 - val_loss: 1.3182\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2964 - val_loss: 1.3154\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3449 - val_loss: 1.3250\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.3155\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3842 - val_loss: 1.3141\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3104 - val_loss: 1.3142\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2987 - val_loss: 1.3146\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3611 - val_loss: 1.3178\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3375 - val_loss: 1.3141\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3348 - val_loss: 1.3148\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3062 - val_loss: 1.3142\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3161\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2716 - val_loss: 1.3150\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3556 - val_loss: 1.3157\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3239 - val_loss: 1.3153\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3185 - val_loss: 1.3152\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3067 - val_loss: 1.3145\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2895 - val_loss: 1.3146\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3134 - val_loss: 1.3142\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3456 - val_loss: 1.3160\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3255 - val_loss: 1.3147\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3559 - val_loss: 1.3194\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3300 - val_loss: 1.3157\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3795 - val_loss: 1.3446\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3276 - val_loss: 1.3171\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3394 - val_loss: 1.3185\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3144 - val_loss: 1.3144\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3104 - val_loss: 1.3157\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3304 - val_loss: 1.3155\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3265 - val_loss: 1.3143\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3648 - val_loss: 1.3169\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3403 - val_loss: 1.3150\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3509 - val_loss: 1.3158\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3408 - val_loss: 1.3152\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3346 - val_loss: 1.3324\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3144 - val_loss: 1.3238\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3227 - val_loss: 1.3187\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3050 - val_loss: 1.3154\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 1.3152\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3034 - val_loss: 1.3146\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3290 - val_loss: 1.3173\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3329 - val_loss: 1.3143\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2928 - val_loss: 1.3141\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3151 - val_loss: 1.3142\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3468 - val_loss: 1.3279\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3040 - val_loss: 1.3150\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3275 - val_loss: 1.3149\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3203 - val_loss: 1.3140\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3367 - val_loss: 1.3191\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3318 - val_loss: 1.3242\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3672 - val_loss: 1.3140\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2792 - val_loss: 1.3142\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3086 - val_loss: 1.3217\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3718 - val_loss: 1.3173\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3272 - val_loss: 1.3207\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3399 - val_loss: 1.3140\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3498 - val_loss: 1.3213\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3301 - val_loss: 1.3156\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3536 - val_loss: 1.3171\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3108 - val_loss: 1.3163\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3252 - val_loss: 1.3143\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3291 - val_loss: 1.3161\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3372 - val_loss: 1.3163\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3385 - val_loss: 1.3248\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3574 - val_loss: 1.3152\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3269 - val_loss: 1.3141\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3251 - val_loss: 1.3146\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3695 - val_loss: 1.3152\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3909 - val_loss: 1.3196\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3255 - val_loss: 1.3145\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3125 - val_loss: 1.3256\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3504 - val_loss: 1.3204\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3547 - val_loss: 1.3167\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3267 - val_loss: 1.3142\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3198 - val_loss: 1.3204\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3329 - val_loss: 1.3151\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3063 - val_loss: 1.3140\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3287 - val_loss: 1.3141\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2906 - val_loss: 1.3144\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3037 - val_loss: 1.3200\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3548 - val_loss: 1.3162\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 1.3147\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3541 - val_loss: 1.3174\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3194 - val_loss: 1.3154\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3169 - val_loss: 1.3141\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3046 - val_loss: 1.3192\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2838 - val_loss: 1.3188\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3703 - val_loss: 1.3175\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.3151\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3504 - val_loss: 1.3153\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3817 - val_loss: 1.3304\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3623 - val_loss: 1.3154\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3911 - val_loss: 1.3172\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3733 - val_loss: 1.3140\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3530 - val_loss: 1.3233\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3397 - val_loss: 1.3190\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3065 - val_loss: 1.3140\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3473 - val_loss: 1.3158\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3157 - val_loss: 1.3145\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3462 - val_loss: 1.3124\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3051 - val_loss: 1.3165\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3325 - val_loss: 1.3145\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3286 - val_loss: 1.3184\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3329 - val_loss: 1.3142\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3490 - val_loss: 1.3286\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3143 - val_loss: 1.3174\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3544 - val_loss: 1.3157\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3305 - val_loss: 1.3175\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3223 - val_loss: 1.3155\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3535 - val_loss: 1.3174\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3439 - val_loss: 1.3178\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3049 - val_loss: 1.3371\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3421 - val_loss: 1.3141\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3433 - val_loss: 1.3294\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3273 - val_loss: 1.3201\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2981 - val_loss: 1.3181\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3395 - val_loss: 1.3143\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3008 - val_loss: 1.3141\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3620 - val_loss: 1.3143\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3739 - val_loss: 1.3145\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3072 - val_loss: 1.3244\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3273 - val_loss: 1.3166\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3778 - val_loss: 1.3160\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2870 - val_loss: 1.3146\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3567 - val_loss: 1.3140\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3303 - val_loss: 1.3215\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3552 - val_loss: 1.3176\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3085 - val_loss: 1.3168\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3032 - val_loss: 1.3148\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3180 - val_loss: 1.3177\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3675 - val_loss: 1.3148\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3417 - val_loss: 1.3155\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3355 - val_loss: 1.3146\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3504 - val_loss: 1.3207\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3403 - val_loss: 1.3200\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3616 - val_loss: 1.3144\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3364 - val_loss: 1.3167\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3378 - val_loss: 1.3173\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3364 - val_loss: 1.3140\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3664 - val_loss: 1.3205\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4022 - val_loss: 1.3535\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3275 - val_loss: 1.3207\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3140 - val_loss: 1.3154\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3375 - val_loss: 1.3164\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3514 - val_loss: 1.3392\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3171 - val_loss: 1.3140\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2710 - val_loss: 1.3141\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3512 - val_loss: 1.3201\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.3141\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3662 - val_loss: 1.3227\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3057 - val_loss: 1.3149\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3149\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3277 - val_loss: 1.3141\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3243 - val_loss: 1.3140\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3218 - val_loss: 1.3170\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3290 - val_loss: 1.3329\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3116 - val_loss: 1.3154\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3452 - val_loss: 1.3173\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3489 - val_loss: 1.3140\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3040 - val_loss: 1.3181\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3286 - val_loss: 1.3189\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3377 - val_loss: 1.3260\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3428 - val_loss: 1.3187\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2965 - val_loss: 1.3140\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3303 - val_loss: 1.3296\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3524 - val_loss: 1.3169\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3425 - val_loss: 1.3144\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3297 - val_loss: 1.3230\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3109 - val_loss: 1.3142\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3404 - val_loss: 1.3141\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3234 - val_loss: 1.3195\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3439 - val_loss: 1.3258\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3209 - val_loss: 1.3140\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3484 - val_loss: 1.3179\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3203 - val_loss: 1.3141\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3376 - val_loss: 1.3188\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3315 - val_loss: 1.3148\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3364 - val_loss: 1.3316\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3254 - val_loss: 1.3147\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3571 - val_loss: 1.3186\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3188 - val_loss: 1.3196\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3138 - val_loss: 1.3165\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3322 - val_loss: 1.3143\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3021 - val_loss: 1.3145\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3341 - val_loss: 1.3154\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3141 - val_loss: 1.3143\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2941 - val_loss: 1.3146\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3002 - val_loss: 1.3145\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3217 - val_loss: 1.3140\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.3369\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3755 - val_loss: 1.3433\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3639 - val_loss: 1.3168\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3963 - val_loss: 1.3214\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3584 - val_loss: 1.3270\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3164 - val_loss: 1.3348\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3167 - val_loss: 1.3158\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3659 - val_loss: 1.3141\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3542 - val_loss: 1.3177\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3057 - val_loss: 1.3143\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3062 - val_loss: 1.3170\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3468 - val_loss: 1.3176\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3440 - val_loss: 1.3206\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3334 - val_loss: 1.3142\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3216 - val_loss: 1.3148\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3220 - val_loss: 1.3368\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3221 - val_loss: 1.3198\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3057 - val_loss: 1.3145\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3232 - val_loss: 1.3155\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2942 - val_loss: 1.3153\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3400 - val_loss: 1.3271\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3630 - val_loss: 1.3360\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3187 - val_loss: 1.3163\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3115 - val_loss: 1.3169\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.3142\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3487 - val_loss: 1.3247\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3315 - val_loss: 1.3150\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3111 - val_loss: 1.3146\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3552 - val_loss: 1.3144\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3053 - val_loss: 1.3183\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2976 - val_loss: 1.3141\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3201 - val_loss: 1.3153\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3195 - val_loss: 1.3249\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3604 - val_loss: 1.3149\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3210 - val_loss: 1.3140\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3397 - val_loss: 1.3140\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3384 - val_loss: 1.3213\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3515 - val_loss: 1.3153\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3007 - val_loss: 1.3141\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3169 - val_loss: 1.3243\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3599 - val_loss: 1.3152\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3050 - val_loss: 1.3253\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3212\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3436 - val_loss: 1.3140\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2970 - val_loss: 1.3154\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2837 - val_loss: 1.3166\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3362 - val_loss: 1.3353\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3182\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3200 - val_loss: 1.3168\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2966 - val_loss: 1.3149\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3410 - val_loss: 1.3419\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3325 - val_loss: 1.3141\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3312 - val_loss: 1.3191\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2668 - val_loss: 1.3221\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3083 - val_loss: 1.3141\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2983 - val_loss: 1.3144\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3252 - val_loss: 1.3318\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3627 - val_loss: 1.3342\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3279 - val_loss: 1.3203\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3044 - val_loss: 1.3149\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3298 - val_loss: 1.3161\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3316 - val_loss: 1.3162\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3449 - val_loss: 1.3180\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3290 - val_loss: 1.3172\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3541 - val_loss: 1.3154\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3496 - val_loss: 1.3173\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3409 - val_loss: 1.3140\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3442 - val_loss: 1.3149\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3534 - val_loss: 1.3155\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3514 - val_loss: 1.3224\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3530 - val_loss: 1.3208\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3144 - val_loss: 1.3141\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3374 - val_loss: 1.3153\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.3380\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3257 - val_loss: 1.3223\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3159 - val_loss: 1.3150\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3333 - val_loss: 1.3177\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3494 - val_loss: 1.3181\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2958 - val_loss: 1.3146\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3179\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3712 - val_loss: 1.3144\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3481 - val_loss: 1.3349\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3411 - val_loss: 1.3141\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3205 - val_loss: 1.3490\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3566 - val_loss: 1.3188\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2872 - val_loss: 1.3176\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3463 - val_loss: 1.3147\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3174 - val_loss: 1.3143\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3000 - val_loss: 1.3658\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3301 - val_loss: 1.3140\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3942 - val_loss: 1.3144\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2957 - val_loss: 1.3189\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3399 - val_loss: 1.3185\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3010 - val_loss: 1.3149\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3406 - val_loss: 1.3192\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3859 - val_loss: 1.3305\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3421 - val_loss: 1.3660\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3387 - val_loss: 1.3140\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3659 - val_loss: 1.3254\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3503 - val_loss: 1.3162\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.3163\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3292 - val_loss: 1.3203\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3310 - val_loss: 1.3202\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3620 - val_loss: 1.3183\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3269 - val_loss: 1.3251\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3372 - val_loss: 1.3501\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3282 - val_loss: 1.3152\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3445 - val_loss: 1.3155\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3349 - val_loss: 1.3337\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3419 - val_loss: 1.3161\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3166 - val_loss: 1.3212\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3223 - val_loss: 1.3255\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3146 - val_loss: 1.3216\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3221\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3115 - val_loss: 1.3164\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3008 - val_loss: 1.3140\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3298 - val_loss: 1.3268\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3165 - val_loss: 1.3199\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3396 - val_loss: 1.3146\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3217\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3383 - val_loss: 1.3142\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3030 - val_loss: 1.3149\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3173 - val_loss: 1.3158\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3046 - val_loss: 1.3263\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3159 - val_loss: 1.3173\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2763 - val_loss: 1.3173\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3780 - val_loss: 1.3278\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3268 - val_loss: 1.3165\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3609 - val_loss: 1.3140\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3194 - val_loss: 1.3141\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3428 - val_loss: 1.3270\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3317 - val_loss: 1.3159\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3333 - val_loss: 1.3227\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3175 - val_loss: 1.3141\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3161 - val_loss: 1.3151\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3554 - val_loss: 1.3242\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3195 - val_loss: 1.3144\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3257 - val_loss: 1.3312\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3569 - val_loss: 1.3157\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3614 - val_loss: 1.3186\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3188 - val_loss: 1.3267\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3555 - val_loss: 1.3195\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3198 - val_loss: 1.3143\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3313 - val_loss: 1.3146\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3560 - val_loss: 1.3159\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3544 - val_loss: 1.3207\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3056 - val_loss: 1.3211\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3166 - val_loss: 1.3233\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3363 - val_loss: 1.3193\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3297 - val_loss: 1.3215\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3491 - val_loss: 1.3140\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2886 - val_loss: 1.3236\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3007 - val_loss: 1.3156\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3436 - val_loss: 1.3187\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3614 - val_loss: 1.3141\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3373 - val_loss: 1.3142\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2898 - val_loss: 1.3143\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2911 - val_loss: 1.3148\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3216 - val_loss: 1.3151\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3482 - val_loss: 1.3162\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3364 - val_loss: 1.3404\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3469 - val_loss: 1.3371\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3016 - val_loss: 1.3188\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3086 - val_loss: 1.3182\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3033 - val_loss: 1.3207\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3415 - val_loss: 1.3465\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3907 - val_loss: 1.3172\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2976 - val_loss: 1.3142\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3430 - val_loss: 1.3173\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3313 - val_loss: 1.3172\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3235 - val_loss: 1.3393\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3636 - val_loss: 1.3244\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3157 - val_loss: 1.3153\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3490 - val_loss: 1.3246\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3037 - val_loss: 1.3140\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3034 - val_loss: 1.3154\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3599 - val_loss: 1.3148\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3264 - val_loss: 1.3149\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3374 - val_loss: 1.3306\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 1.3177\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3174 - val_loss: 1.3151\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3332 - val_loss: 1.3164\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3578 - val_loss: 1.3180\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3002 - val_loss: 1.3179\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3403 - val_loss: 1.3164\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3179 - val_loss: 1.3166\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3239 - val_loss: 1.3362\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3119 - val_loss: 1.3148\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3160 - val_loss: 1.3246\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3098 - val_loss: 1.3148\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3570 - val_loss: 1.3150\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3184 - val_loss: 1.3142\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3018 - val_loss: 1.3183\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3351 - val_loss: 1.3152\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3368 - val_loss: 1.3140\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3013 - val_loss: 1.3162\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3579 - val_loss: 1.3164\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3509 - val_loss: 1.3161\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3300 - val_loss: 1.3158\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3262 - val_loss: 1.3143\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3557 - val_loss: 1.3157\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3317 - val_loss: 1.3140\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3316 - val_loss: 1.3160\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2448 - val_loss: 1.3187\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3477 - val_loss: 1.3201\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3064 - val_loss: 1.3140\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3070 - val_loss: 1.3144\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3204 - val_loss: 1.3148\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3132 - val_loss: 1.3181\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3237 - val_loss: 1.3146\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3306 - val_loss: 1.3278\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history2 = model2.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 3.7259 - val_loss: 1.4789\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.3147\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3447 - val_loss: 1.3165\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3364 - val_loss: 1.3153\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3838 - val_loss: 1.3155\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3082 - val_loss: 1.3147\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2958 - val_loss: 1.3144\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3606 - val_loss: 1.3151\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3359 - val_loss: 1.3146\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3346 - val_loss: 1.3152\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3054 - val_loss: 1.3153\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3144\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2709 - val_loss: 1.3156\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3542 - val_loss: 1.3158\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3224 - val_loss: 1.3153\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3179 - val_loss: 1.3143\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3059 - val_loss: 1.3144\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2878 - val_loss: 1.3155\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3099 - val_loss: 1.3143\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3446 - val_loss: 1.3149\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3201 - val_loss: 1.3187\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3560 - val_loss: 1.3149\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3233 - val_loss: 1.3196\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3794 - val_loss: 1.3197\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3236 - val_loss: 1.3154\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3368 - val_loss: 1.3143\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3122 - val_loss: 1.3174\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3081 - val_loss: 1.3140\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3265 - val_loss: 1.3161\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3257 - val_loss: 1.3141\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3646 - val_loss: 1.3165\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3389 - val_loss: 1.3154\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3490 - val_loss: 1.3142\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3401 - val_loss: 1.3144\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3289 - val_loss: 1.3170\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3123 - val_loss: 1.3195\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3221 - val_loss: 1.3173\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3047 - val_loss: 1.3150\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3402 - val_loss: 1.3177\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3009 - val_loss: 1.3142\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3234 - val_loss: 1.3149\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3308 - val_loss: 1.3143\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2919 - val_loss: 1.3178\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3128 - val_loss: 1.3197\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3485 - val_loss: 1.3193\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3020 - val_loss: 1.3135\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3248 - val_loss: 1.3137\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3183 - val_loss: 1.3143\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3344 - val_loss: 1.3137\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3279 - val_loss: 1.3145\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3631 - val_loss: 1.3178\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2714 - val_loss: 1.3178\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3065 - val_loss: 1.3151\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3677 - val_loss: 1.3144\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3238 - val_loss: 1.3141\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3352 - val_loss: 1.3153\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3475 - val_loss: 1.3150\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3265 - val_loss: 1.3145\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3496 - val_loss: 1.3178\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3073 - val_loss: 1.3142\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3221 - val_loss: 1.3169\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3256 - val_loss: 1.3149\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.3139\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3363 - val_loss: 1.3137\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3553 - val_loss: 1.3143\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3249 - val_loss: 1.3120\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3240 - val_loss: 1.3143\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3683 - val_loss: 1.3149\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3907 - val_loss: 1.3159\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3220 - val_loss: 1.3187\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3102 - val_loss: 1.3158\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3437 - val_loss: 1.3141\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3494 - val_loss: 1.3147\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3233 - val_loss: 1.3147\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3165 - val_loss: 1.3147\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3311 - val_loss: 1.3157\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3023 - val_loss: 1.3213\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3257 - val_loss: 1.3218\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2805 - val_loss: 1.3130\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2937 - val_loss: 1.3154\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3390 - val_loss: 1.3134\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3402 - val_loss: 1.3134\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3516 - val_loss: 1.3142\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3188 - val_loss: 1.3152\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3128 - val_loss: 1.3161\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3015 - val_loss: 1.3188\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2796 - val_loss: 1.3137\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3610 - val_loss: 1.3144\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3324 - val_loss: 1.3144\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3456 - val_loss: 1.3163\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3830 - val_loss: 1.3236\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3587 - val_loss: 1.3143\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3899 - val_loss: 1.3187\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3727 - val_loss: 1.3107\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3486 - val_loss: 1.3138\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3365 - val_loss: 1.3136\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3057 - val_loss: 1.3141\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3475 - val_loss: 1.3239\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3149\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3405 - val_loss: 1.3158\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3037 - val_loss: 1.3164\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.3126\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3259 - val_loss: 1.3121\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3286 - val_loss: 1.3112\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3461 - val_loss: 1.3135\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3082 - val_loss: 1.3085\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3472 - val_loss: 1.3109\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3256 - val_loss: 1.3126\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3177 - val_loss: 1.3089\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3496 - val_loss: 1.3120\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.3126\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3100 - val_loss: 1.3177\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.3154\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3413 - val_loss: 1.3163\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3268 - val_loss: 1.3174\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2939 - val_loss: 1.3157\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3274 - val_loss: 1.3180\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2986 - val_loss: 1.3141\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3507 - val_loss: 1.3170\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3721 - val_loss: 1.3166\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2974 - val_loss: 1.3140\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3260 - val_loss: 1.3194\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3779 - val_loss: 1.3140\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2884 - val_loss: 1.3140\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3555 - val_loss: 1.3146\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3258 - val_loss: 1.3143\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3532 - val_loss: 1.3154\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3020 - val_loss: 1.3161\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3014 - val_loss: 1.3150\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3128 - val_loss: 1.3153\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3546 - val_loss: 1.3153\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3390 - val_loss: 1.3163\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3309 - val_loss: 1.3161\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3445 - val_loss: 1.3159\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3319 - val_loss: 1.3152\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3580 - val_loss: 1.3146\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3325 - val_loss: 1.3176\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3354 - val_loss: 1.3155\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3354 - val_loss: 1.3196\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3655 - val_loss: 1.3174\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3968 - val_loss: 1.3216\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3130 - val_loss: 1.3147\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3105 - val_loss: 1.3140\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3327 - val_loss: 1.3141\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3440 - val_loss: 1.3146\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3126 - val_loss: 1.3153\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2679 - val_loss: 1.3146\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3451 - val_loss: 1.3165\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3332 - val_loss: 1.3158\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3644 - val_loss: 1.3167\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3010 - val_loss: 1.3144\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3385 - val_loss: 1.3152\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3219 - val_loss: 1.3143\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3230 - val_loss: 1.3170\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3226 - val_loss: 1.3141\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3281 - val_loss: 1.3161\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3050 - val_loss: 1.3155\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3399 - val_loss: 1.3150\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3444 - val_loss: 1.3150\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3008 - val_loss: 1.3143\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3242 - val_loss: 1.3141\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3342 - val_loss: 1.3158\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3398 - val_loss: 1.3186\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2897 - val_loss: 1.3171\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3255 - val_loss: 1.3141\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3199\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3390 - val_loss: 1.3144\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3261 - val_loss: 1.3158\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3093 - val_loss: 1.3143\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3355 - val_loss: 1.3199\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3180 - val_loss: 1.3142\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3427 - val_loss: 1.3142\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3108 - val_loss: 1.3160\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3462 - val_loss: 1.3183\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3195 - val_loss: 1.3158\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3366 - val_loss: 1.3142\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3288 - val_loss: 1.3144\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3355 - val_loss: 1.3141\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3154\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3549 - val_loss: 1.3201\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3168 - val_loss: 1.3143\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3106 - val_loss: 1.3141\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3300 - val_loss: 1.3162\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2995 - val_loss: 1.3150\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3325 - val_loss: 1.3161\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3093 - val_loss: 1.3142\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2919 - val_loss: 1.3154\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2947 - val_loss: 1.3142\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3169\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 1.3141\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3651 - val_loss: 1.3146\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3453 - val_loss: 1.3150\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3894 - val_loss: 1.3163\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3523 - val_loss: 1.3150\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3130 - val_loss: 1.3147\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3100 - val_loss: 1.3144\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3635 - val_loss: 1.3201\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3525 - val_loss: 1.3161\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3023 - val_loss: 1.3163\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3056 - val_loss: 1.3174\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 1.3218\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3441 - val_loss: 1.3144\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3301 - val_loss: 1.3140\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3132 - val_loss: 1.3145\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3151 - val_loss: 1.3160\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3139 - val_loss: 1.3181\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3028 - val_loss: 1.3146\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3218 - val_loss: 1.3151\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2894 - val_loss: 1.3146\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3371 - val_loss: 1.3141\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3567 - val_loss: 1.3152\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3100 - val_loss: 1.3141\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3107 - val_loss: 1.3152\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3284 - val_loss: 1.3157\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3472 - val_loss: 1.3155\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3287 - val_loss: 1.3153\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3084 - val_loss: 1.3140\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3519 - val_loss: 1.3141\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3024 - val_loss: 1.3165\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2964 - val_loss: 1.3141\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3190 - val_loss: 1.3152\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3171 - val_loss: 1.3143\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3552 - val_loss: 1.3265\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3207 - val_loss: 1.3141\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3373 - val_loss: 1.3141\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3355 - val_loss: 1.3176\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3474 - val_loss: 1.3143\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2956 - val_loss: 1.3140\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3126 - val_loss: 1.3193\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3581 - val_loss: 1.3161\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3017 - val_loss: 1.3140\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3281 - val_loss: 1.3144\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3396 - val_loss: 1.3149\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2952 - val_loss: 1.3164\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2807 - val_loss: 1.3140\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3335 - val_loss: 1.3141\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3283 - val_loss: 1.3148\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3147 - val_loss: 1.3145\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2952 - val_loss: 1.3141\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.3195\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3234 - val_loss: 1.3181\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3292 - val_loss: 1.3143\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2547 - val_loss: 1.3214\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2996 - val_loss: 1.3167\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2966 - val_loss: 1.3143\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3241 - val_loss: 1.3168\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3544 - val_loss: 1.3166\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3237 - val_loss: 1.3154\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3022 - val_loss: 1.3142\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3274 - val_loss: 1.3140\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3281 - val_loss: 1.3147\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3380 - val_loss: 1.3191\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3250 - val_loss: 1.3142\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3510 - val_loss: 1.3153\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3455 - val_loss: 1.3185\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3349 - val_loss: 1.3141\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3395 - val_loss: 1.3172\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3514 - val_loss: 1.3160\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3520 - val_loss: 1.3166\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3495 - val_loss: 1.3179\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3116 - val_loss: 1.3154\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3345 - val_loss: 1.3149\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3344 - val_loss: 1.3170\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3211 - val_loss: 1.3143\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3130 - val_loss: 1.3153\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.3169\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3423 - val_loss: 1.3196\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2948 - val_loss: 1.3150\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3095 - val_loss: 1.3195\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3690 - val_loss: 1.3143\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3479 - val_loss: 1.3148\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3356 - val_loss: 1.3161\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3156\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3400 - val_loss: 1.3178\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2827 - val_loss: 1.3158\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3449 - val_loss: 1.3140\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3167 - val_loss: 1.3141\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2979 - val_loss: 1.3152\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3208 - val_loss: 1.3147\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3896 - val_loss: 1.3151\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2886 - val_loss: 1.3143\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.3141\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3004 - val_loss: 1.3173\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3337 - val_loss: 1.3182\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3826 - val_loss: 1.3300\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3406 - val_loss: 1.3144\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3162 - val_loss: 1.3144\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3635 - val_loss: 1.3176\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3487 - val_loss: 1.3141\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3377 - val_loss: 1.3142\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3317 - val_loss: 1.3156\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3264 - val_loss: 1.3171\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3584 - val_loss: 1.3170\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3229 - val_loss: 1.3149\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3308 - val_loss: 1.3164\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3238 - val_loss: 1.3149\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3327 - val_loss: 1.3159\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3326 - val_loss: 1.3168\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3341 - val_loss: 1.3219\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3184 - val_loss: 1.3175\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3197 - val_loss: 1.3173\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3113 - val_loss: 1.3172\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3194 - val_loss: 1.3167\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3076 - val_loss: 1.3148\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2981 - val_loss: 1.3144\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3276 - val_loss: 1.3178\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3143 - val_loss: 1.3155\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 1.3243\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3097 - val_loss: 1.3153\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3329 - val_loss: 1.3166\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3003 - val_loss: 1.3143\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3161 - val_loss: 1.3143\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3034 - val_loss: 1.3143\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3133 - val_loss: 1.3165\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2743 - val_loss: 1.3141\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3726 - val_loss: 1.3156\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3229 - val_loss: 1.3160\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3546 - val_loss: 1.3179\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3172 - val_loss: 1.3149\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3154\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3297 - val_loss: 1.3177\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3321 - val_loss: 1.3141\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3120 - val_loss: 1.3141\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3157 - val_loss: 1.3147\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3539 - val_loss: 1.3152\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3124 - val_loss: 1.3182\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3179 - val_loss: 1.3174\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3528 - val_loss: 1.3190\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3620 - val_loss: 1.3146\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3166 - val_loss: 1.3165\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3509 - val_loss: 1.3143\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3141 - val_loss: 1.3149\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3291 - val_loss: 1.3188\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3489 - val_loss: 1.3161\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3516 - val_loss: 1.3180\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3033 - val_loss: 1.3215\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3125 - val_loss: 1.3140\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3349 - val_loss: 1.3158\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3273 - val_loss: 1.3145\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.3161\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2840 - val_loss: 1.3173\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2980 - val_loss: 1.3151\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3384 - val_loss: 1.3145\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3529 - val_loss: 1.3160\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3372 - val_loss: 1.3153\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2855 - val_loss: 1.3164\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2853 - val_loss: 1.3146\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3190 - val_loss: 1.3142\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3432 - val_loss: 1.3140\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3344 - val_loss: 1.3208\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3384 - val_loss: 1.3221\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2988 - val_loss: 1.3140\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3050 - val_loss: 1.3157\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3006 - val_loss: 1.3141\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3428 - val_loss: 1.3148\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3735 - val_loss: 1.3172\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2954 - val_loss: 1.3142\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3419 - val_loss: 1.3141\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3204 - val_loss: 1.3182\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3183 - val_loss: 1.3172\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3582 - val_loss: 1.3212\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3151 - val_loss: 1.3157\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3466 - val_loss: 1.3141\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2941 - val_loss: 1.3151\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3015 - val_loss: 1.3142\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3577 - val_loss: 1.3149\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3247 - val_loss: 1.3143\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3340 - val_loss: 1.3200\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3252 - val_loss: 1.3184\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3161 - val_loss: 1.3140\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3284 - val_loss: 1.3154\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3550 - val_loss: 1.3141\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2992 - val_loss: 1.3177\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3379 - val_loss: 1.3166\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3137 - val_loss: 1.3143\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3186 - val_loss: 1.3140\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3062 - val_loss: 1.3182\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3129 - val_loss: 1.3159\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3075 - val_loss: 1.3146\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3517 - val_loss: 1.3234\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3146 - val_loss: 1.3228\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2941 - val_loss: 1.3144\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3289 - val_loss: 1.3140\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3332 - val_loss: 1.3146\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2969 - val_loss: 1.3152\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3545 - val_loss: 1.3157\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3452 - val_loss: 1.3164\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3232 - val_loss: 1.3143\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3208 - val_loss: 1.3171\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3551 - val_loss: 1.3171\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3291 - val_loss: 1.3150\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3248 - val_loss: 1.3142\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2447 - val_loss: 1.3148\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3433 - val_loss: 1.3216\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3020 - val_loss: 1.3179\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3043 - val_loss: 1.3153\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3178 - val_loss: 1.3140\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3099 - val_loss: 1.3159\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3223 - val_loss: 1.3203\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3291 - val_loss: 1.3140\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history3 = model3.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 808213.6553 - val_loss: 567403.2500\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 598181.0426 - val_loss: 413220.3125\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 427042.4219 - val_loss: 289214.9688\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 313287.1037 - val_loss: 198761.2812\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 197379.0426 - val_loss: 131870.8438\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 130461.9763 - val_loss: 82927.5234\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 82510.1200 - val_loss: 48476.4531\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 48501.7588 - val_loss: 26894.8867\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 27341.2635 - val_loss: 14119.5225\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 17821.6249 - val_loss: 6936.5518\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7556.1209 - val_loss: 3220.6289\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3533.8195 - val_loss: 1465.1934\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1837.6283 - val_loss: 837.6850\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1136.8283 - val_loss: 648.4501\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 841.5824 - val_loss: 542.2491\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 722.1680 - val_loss: 461.7825\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 813.9616 - val_loss: 396.7912\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 516.6576 - val_loss: 344.9004\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 464.4690 - val_loss: 302.3098\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 361.9074 - val_loss: 264.8650\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 335.5075 - val_loss: 232.7977\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 299.8015 - val_loss: 205.7287\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 275.5133 - val_loss: 179.7923\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 219.6173 - val_loss: 158.3796\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 196.3244 - val_loss: 126.4683\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 139.6500 - val_loss: 99.7107\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 128.7146 - val_loss: 82.4472\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 107.9157 - val_loss: 72.9137\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 83.5410 - val_loss: 57.7001\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 65.7466 - val_loss: 51.5869\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 59.5711 - val_loss: 43.0979\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 52.9765 - val_loss: 33.7130\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 43.5632 - val_loss: 26.8208\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 30.5067 - val_loss: 20.8111\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 26.3632 - val_loss: 15.6021\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 19.4919 - val_loss: 12.5094\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 15.1435 - val_loss: 9.8845\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 14.9167 - val_loss: 8.1095\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 10.0846 - val_loss: 6.5801\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7.5375 - val_loss: 5.9148\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7.4064 - val_loss: 4.8023\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 5.6951 - val_loss: 4.2112\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.8091 - val_loss: 3.9288\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.4354 - val_loss: 3.5079\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.2798 - val_loss: 3.3498\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.6151 - val_loss: 3.1636\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.7429 - val_loss: 3.0792\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.5415 - val_loss: 2.9942\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.3306 - val_loss: 2.9549\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.2322 - val_loss: 2.9434\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.1803 - val_loss: 2.9060\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.0562 - val_loss: 2.8891\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.4854 - val_loss: 2.8777\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.8891 - val_loss: 2.8659\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.0406 - val_loss: 2.8562\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8885 - val_loss: 2.8472\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8890 - val_loss: 2.8427\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8408 - val_loss: 2.8271\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.9331 - val_loss: 2.8190\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8190 - val_loss: 2.8143\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8396 - val_loss: 2.7971\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8019 - val_loss: 2.7924\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8457 - val_loss: 2.7672\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8497 - val_loss: 2.7558\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7899 - val_loss: 2.7422\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7180 - val_loss: 2.7279\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7246 - val_loss: 2.7217\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.8144 - val_loss: 2.7067\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6531 - val_loss: 2.6867\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7231 - val_loss: 2.6727\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6675 - val_loss: 2.6632\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6255 - val_loss: 2.6530\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7114 - val_loss: 2.6314\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6932 - val_loss: 2.6152\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5634 - val_loss: 2.6163\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.6008 - val_loss: 2.5871\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5151 - val_loss: 2.5759\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5336 - val_loss: 2.5548\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5195 - val_loss: 2.5403\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.4965 - val_loss: 2.5220\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.5693 - val_loss: 2.5075\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4983 - val_loss: 2.4878\n",
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4536 - val_loss: 2.4753\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4616 - val_loss: 2.4809\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3905 - val_loss: 2.4391\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3266 - val_loss: 2.4659\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4111 - val_loss: 2.4999\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4809 - val_loss: 2.4040\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4367 - val_loss: 2.3714\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3099 - val_loss: 2.3513\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3295 - val_loss: 2.3356\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3674 - val_loss: 2.3135\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.3418 - val_loss: 2.3202\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.2090 - val_loss: 2.2845\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.2019 - val_loss: 2.2875\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1741 - val_loss: 2.2370\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1735 - val_loss: 2.2314\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1971 - val_loss: 2.2052\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1767 - val_loss: 2.1968\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1951 - val_loss: 2.1732\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0593 - val_loss: 2.1512\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.0504 - val_loss: 2.1556\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0881 - val_loss: 2.1350\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0998 - val_loss: 2.1000\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0819 - val_loss: 2.0794\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9514 - val_loss: 2.0581\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0496 - val_loss: 2.0368\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0361 - val_loss: 2.0170\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9106 - val_loss: 2.0043\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9957 - val_loss: 1.9854\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9226 - val_loss: 1.9784\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8758 - val_loss: 1.9412\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9141 - val_loss: 1.9429\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8905 - val_loss: 1.9176\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9433 - val_loss: 1.9128\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8725 - val_loss: 1.8743\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7840 - val_loss: 1.8501\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7947 - val_loss: 1.8516\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 1.8172\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8246 - val_loss: 1.7960\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6973 - val_loss: 1.7810\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6747 - val_loss: 1.7661\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7862 - val_loss: 1.7442\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6744 - val_loss: 1.7313\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7203 - val_loss: 1.7190\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7291 - val_loss: 1.7186\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7264 - val_loss: 1.6886\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6109 - val_loss: 1.6675\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6633 - val_loss: 1.6512\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6424 - val_loss: 1.6458\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6772 - val_loss: 1.6211\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.6120 - val_loss: 1.6411\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 1.5709 - val_loss: 1.6137\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5581 - val_loss: 1.6025\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5172 - val_loss: 1.5615\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4861 - val_loss: 1.6521\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5012 - val_loss: 1.5630\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5355 - val_loss: 1.5335\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4463 - val_loss: 1.5056\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5057 - val_loss: 1.4930\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4939 - val_loss: 1.4826\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.4588\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4921 - val_loss: 1.4413\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4407 - val_loss: 1.4139\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3582 - val_loss: 1.4294\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3221 - val_loss: 1.3716\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3509 - val_loss: 1.3532\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3790 - val_loss: 1.3334\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2964 - val_loss: 1.4040\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3424 - val_loss: 1.3230\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3024 - val_loss: 1.2676\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2404 - val_loss: 1.2463\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2488 - val_loss: 1.2409\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2144 - val_loss: 1.2107\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1715 - val_loss: 1.2192\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1660 - val_loss: 1.1939\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1492 - val_loss: 1.1655\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1372 - val_loss: 1.1738\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1609 - val_loss: 1.1500\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1366 - val_loss: 1.1328\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1184 - val_loss: 1.1390\n",
      "Epoch 162/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1874 - val_loss: 1.1236\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0754 - val_loss: 1.1090\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0546 - val_loss: 1.0998\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0768 - val_loss: 1.1137\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0871 - val_loss: 1.0879\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0707 - val_loss: 1.0705\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0935 - val_loss: 1.0701\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0403 - val_loss: 1.0865\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0880\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0649\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0158 - val_loss: 1.0326\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0212 - val_loss: 1.1237\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0953 - val_loss: 1.0239\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9716 - val_loss: 1.0267\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 1.0081\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0187 - val_loss: 0.9999\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0376 - val_loss: 1.0123\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9787 - val_loss: 1.0299\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0686 - val_loss: 0.9829\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9880 - val_loss: 0.9961\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9507 - val_loss: 0.9753\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0052 - val_loss: 0.9905\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9217 - val_loss: 0.9600\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0279 - val_loss: 1.0097\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9787 - val_loss: 0.9490\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9135 - val_loss: 0.9460\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9314 - val_loss: 0.9737\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8953 - val_loss: 0.9366\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9447 - val_loss: 0.9783\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9701 - val_loss: 0.9307\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9497 - val_loss: 1.0074\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9569 - val_loss: 0.9647\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.9171\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9233 - val_loss: 0.9076\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9159 - val_loss: 0.9041\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9433 - val_loss: 0.9012\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9098 - val_loss: 0.9033\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8517 - val_loss: 0.9297\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8862 - val_loss: 0.8895\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0456 - val_loss: 0.9065\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9119 - val_loss: 0.8955\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8533 - val_loss: 0.8991\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8780 - val_loss: 0.9353\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8901 - val_loss: 0.8763\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8572 - val_loss: 0.9202\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8472 - val_loss: 0.9014\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 0.8837\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8446 - val_loss: 0.8824\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8494 - val_loss: 0.8663\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9611 - val_loss: 0.8563\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8293 - val_loss: 0.8609\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8722 - val_loss: 0.8514\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8515 - val_loss: 0.8634\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8343 - val_loss: 0.8473\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9069 - val_loss: 0.8616\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8074 - val_loss: 0.8445\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8419 - val_loss: 0.8425\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8436 - val_loss: 0.9529\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8538 - val_loss: 0.8377\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8318 - val_loss: 0.8844\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8332 - val_loss: 0.8383\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8533 - val_loss: 0.8476\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8838 - val_loss: 0.9050\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8533 - val_loss: 0.8461\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8737 - val_loss: 0.8867\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8329 - val_loss: 0.8545\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8081 - val_loss: 0.8209\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8708 - val_loss: 0.8236\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8163 - val_loss: 0.8181\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8081 - val_loss: 0.8286\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8328 - val_loss: 0.8922\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8941 - val_loss: 0.8735\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8093 - val_loss: 0.8266\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8229 - val_loss: 0.8135\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8101 - val_loss: 0.8615\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8030 - val_loss: 0.9619\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8695 - val_loss: 0.8065\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9105 - val_loss: 0.8033\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8061 - val_loss: 0.8142\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8232 - val_loss: 0.8146\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8039 - val_loss: 0.7967\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8168 - val_loss: 0.9375\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2367 - val_loss: 0.8552\n",
      "Epoch 245/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8697 - val_loss: 8.1614\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.1867 - val_loss: 0.8152\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7955 - val_loss: 0.8296\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7885 - val_loss: 0.7920\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7429 - val_loss: 0.8324\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7901 - val_loss: 0.7892\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7725 - val_loss: 0.8049\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7854 - val_loss: 0.7935\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7774 - val_loss: 0.8330\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7749 - val_loss: 0.8041\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7736 - val_loss: 0.7877\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8068 - val_loss: 1.2249\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9497 - val_loss: 0.9285\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8701 - val_loss: 0.8019\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7909 - val_loss: 0.7867\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7656 - val_loss: 0.7950\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7555 - val_loss: 0.7819\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7561 - val_loss: 0.7755\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8056 - val_loss: 0.7851\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8226 - val_loss: 0.8963\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8125 - val_loss: 0.7717\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7523 - val_loss: 0.8721\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7472 - val_loss: 2.0152\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2130 - val_loss: 0.7688\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7644 - val_loss: 0.7706\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8173 - val_loss: 0.8277\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8138 - val_loss: 0.7915\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7847 - val_loss: 0.7772\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7830 - val_loss: 0.7972\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8188 - val_loss: 0.8094\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7715 - val_loss: 0.7755\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8022 - val_loss: 0.7789\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7755 - val_loss: 0.8131\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7855 - val_loss: 0.7897\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0494 - val_loss: 0.8152\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7962 - val_loss: 0.9082\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8505 - val_loss: 0.8050\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7903 - val_loss: 0.7501\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7189 - val_loss: 0.8315\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8643 - val_loss: 0.7537\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7577 - val_loss: 0.7619\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7727 - val_loss: 0.7645\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7782 - val_loss: 0.8365\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7942 - val_loss: 1.0681\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2254 - val_loss: 0.7713\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7854 - val_loss: 0.8405\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9089 - val_loss: 0.7921\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8868 - val_loss: 0.7611\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7661 - val_loss: 0.7413\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7317 - val_loss: 0.7373\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7699 - val_loss: 0.7737\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7423 - val_loss: 0.7556\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7224 - val_loss: 0.7411\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7406 - val_loss: 0.7333\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7536 - val_loss: 0.7552\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7554 - val_loss: 0.7840\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7379 - val_loss: 0.7315\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7069 - val_loss: 0.7401\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7569 - val_loss: 0.7852\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7167 - val_loss: 0.7641\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7186 - val_loss: 0.9044\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8068 - val_loss: 0.7432\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7361 - val_loss: 0.7297\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7380 - val_loss: 0.7316\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7799 - val_loss: 0.7361\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0101 - val_loss: 0.7958\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7489 - val_loss: 0.7451\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8992 - val_loss: 0.7576\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8780 - val_loss: 0.7256\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7480 - val_loss: 0.7410\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6841 - val_loss: 0.7727\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7551 - val_loss: 0.7239\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6920 - val_loss: 0.7127\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7135 - val_loss: 0.7154\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7470 - val_loss: 0.7597\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8999 - val_loss: 0.7563\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7790 - val_loss: 0.8434\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7413 - val_loss: 0.8464\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7617 - val_loss: 0.7091\n",
      "Epoch 324/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6657 - val_loss: 0.7171\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7050 - val_loss: 0.7114\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7351 - val_loss: 0.7100\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.8104\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.7234\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7391 - val_loss: 0.7168\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6969 - val_loss: 0.8398\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7330 - val_loss: 0.7061\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7258 - val_loss: 0.7002\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6902 - val_loss: 0.7079\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7412 - val_loss: 0.7893\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7152 - val_loss: 0.7023\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7212 - val_loss: 0.7009\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6757 - val_loss: 0.7053\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7267 - val_loss: 0.6974\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7523 - val_loss: 0.7122\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6883 - val_loss: 0.9184\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7947 - val_loss: 0.6976\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.7552\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6939 - val_loss: 0.7822\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7022 - val_loss: 0.6930\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7233 - val_loss: 0.6921\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6766 - val_loss: 0.7050\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6854 - val_loss: 0.7535\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7226 - val_loss: 0.6886\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6928 - val_loss: 0.6944\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6807 - val_loss: 0.6909\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6884 - val_loss: 0.7341\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8610 - val_loss: 1.4101\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8576 - val_loss: 0.6861\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6662 - val_loss: 1.0687\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9489 - val_loss: 0.7129\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6947 - val_loss: 0.6837\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6563 - val_loss: 0.6996\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7076 - val_loss: 0.9657\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3867 - val_loss: 0.7652\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7395 - val_loss: 0.6922\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6856 - val_loss: 0.6816\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6570 - val_loss: 0.9387\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8382 - val_loss: 0.7507\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6919 - val_loss: 0.6842\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6731 - val_loss: 0.6796\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7098 - val_loss: 0.6795\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6583 - val_loss: 0.6765\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7113 - val_loss: 0.6782\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6745 - val_loss: 0.7063\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7163 - val_loss: 0.7240\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 0.6849\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.6885\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6617 - val_loss: 0.7341\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7033 - val_loss: 0.6757\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6522 - val_loss: 0.6725\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6506 - val_loss: 0.6924\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6751 - val_loss: 0.6730\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6864 - val_loss: 0.6961\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7206 - val_loss: 0.6709\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6943 - val_loss: 0.6743\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6690 - val_loss: 0.7659\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6724 - val_loss: 0.6895\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6614 - val_loss: 0.6678\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6566 - val_loss: 1.0343\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8400 - val_loss: 0.7045\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6954 - val_loss: 0.6694\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6814 - val_loss: 0.6649\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6589 - val_loss: 1.0698\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8823 - val_loss: 0.7780\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7151 - val_loss: 0.6855\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6650 - val_loss: 0.6698\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6635 - val_loss: 0.6774\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6524 - val_loss: 0.8275\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8235 - val_loss: 0.6624\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6511 - val_loss: 0.6618\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6628 - val_loss: 0.7067\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6295 - val_loss: 0.7011\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6540 - val_loss: 0.9779\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7674 - val_loss: 0.7536\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7218 - val_loss: 0.6881\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history4 = model4.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 704.5160 - val_loss: 19.9187\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 17.7756 - val_loss: 8.0882\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 8.5240 - val_loss: 6.1603\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7.1717 - val_loss: 4.8075\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.9424 - val_loss: 3.9599\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.8215 - val_loss: 4.4717\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.4021 - val_loss: 5.6065\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 5.6259 - val_loss: 3.1941\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7087 - val_loss: 2.2291\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.1645 - val_loss: 1.8624\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9780 - val_loss: 1.7800\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0159 - val_loss: 2.2087\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9410 - val_loss: 1.5330\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7741 - val_loss: 2.0775\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7086 - val_loss: 1.4223\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6172 - val_loss: 2.2226\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.8537 - val_loss: 1.4186\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5701 - val_loss: 2.0749\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7563 - val_loss: 1.3061\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3668 - val_loss: 1.6974\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5250 - val_loss: 1.5314\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9428 - val_loss: 1.1640\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3675 - val_loss: 1.1446\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2495 - val_loss: 1.1112\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3979 - val_loss: 1.2353\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3311 - val_loss: 53.3431\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 50.0188 - val_loss: 4.1489\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.4766 - val_loss: 2.5050\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.3162 - val_loss: 1.8498\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.0399 - val_loss: 1.4701\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3607 - val_loss: 1.1732\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1796 - val_loss: 1.0461\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0808 - val_loss: 1.2017\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2644 - val_loss: 0.9641\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 0.9139\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0820 - val_loss: 0.9645\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1652 - val_loss: 1.9550\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2691 - val_loss: 0.8755\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2765 - val_loss: 0.9045\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9111\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4532 - val_loss: 0.8827\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0417 - val_loss: 0.8453\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0469 - val_loss: 2.4104\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3649 - val_loss: 10.8206\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.1582 - val_loss: 1.0504\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9034 - val_loss: 0.8886\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 2.0450\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2059 - val_loss: 1.5810\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1699 - val_loss: 0.8338\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8751 - val_loss: 0.8942\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.8660\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.5378 - val_loss: 0.8109\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9837 - val_loss: 0.9348\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1099 - val_loss: 0.8160\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 0.8592\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1822 - val_loss: 1.8296\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.4379 - val_loss: 1.0942\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.2005\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1963 - val_loss: 1.2606\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0589 - val_loss: 0.8707\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9990 - val_loss: 0.7784\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1881 - val_loss: 1.1829\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9826 - val_loss: 1.0245\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.9467 - val_loss: 0.7757\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1655 - val_loss: 1.6907\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2836 - val_loss: 1.3473\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 0.8626\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2784 - val_loss: 0.8817\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2460 - val_loss: 1.9004\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5218 - val_loss: 1.5604\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5179 - val_loss: 5.4952\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 5.9074 - val_loss: 1.6220\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 7.1395 - val_loss: 0.7731\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.5870\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0784 - val_loss: 0.7330\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1924 - val_loss: 0.8055\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7871 - val_loss: 0.7140\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7185 - val_loss: 0.7143\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7342 - val_loss: 0.7113\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5620 - val_loss: 0.9226\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7545 - val_loss: 0.7093\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7565 - val_loss: 1.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0131 - val_loss: 0.7266\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7394 - val_loss: 0.7533\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9008 - val_loss: 1.6625\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.7267 - val_loss: 0.9491\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.6833 - val_loss: 1.0135\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1508 - val_loss: 0.8192\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7330 - val_loss: 0.6976\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8395 - val_loss: 0.7368\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7570 - val_loss: 0.7031\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7573 - val_loss: 0.6926\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7678 - val_loss: 1.0904\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.0133 - val_loss: 1.8043\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3593 - val_loss: 17.9719\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.7297 - val_loss: 0.6731\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 3.2050 - val_loss: 0.7872\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.1478 - val_loss: 0.8728\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0216 - val_loss: 0.8845\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9200 - val_loss: 0.8997\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3522 - val_loss: 2.8933\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.0127\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3032 - val_loss: 4.4781\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4112 - val_loss: 0.9979\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.1236\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3128 - val_loss: 0.6927\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4142 - val_loss: 0.8032\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6963 - val_loss: 0.6837\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7507 - val_loss: 0.6637\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7841 - val_loss: 6.2208\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 9.9027 - val_loss: 4.7439\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.7822 - val_loss: 1.1433\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1803 - val_loss: 0.7665\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7237 - val_loss: 0.6514\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8653 - val_loss: 0.7097\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7316 - val_loss: 0.9327\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7214 - val_loss: 0.6495\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7464 - val_loss: 0.6601\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9987 - val_loss: 0.7439\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2950 - val_loss: 1.0549\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7821 - val_loss: 0.7208\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7198 - val_loss: 1.3548\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 6.0021 - val_loss: 0.6616\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7219 - val_loss: 0.7780\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8347 - val_loss: 0.9897\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9112 - val_loss: 0.7022\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8481 - val_loss: 0.6451\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7427 - val_loss: 0.6482\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6783 - val_loss: 0.6555\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6561 - val_loss: 1.1351\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6664 - val_loss: 1.4135\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3774 - val_loss: 0.6790\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2914 - val_loss: 0.8538\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4399 - val_loss: 0.9853\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.7833 - val_loss: 0.7038\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6712 - val_loss: 0.6544\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7071 - val_loss: 0.6408\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6893 - val_loss: 0.6583\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7393 - val_loss: 0.8366\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2314 - val_loss: 0.6572\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.8693\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7257 - val_loss: 0.6390\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8703 - val_loss: 1.0169\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7053 - val_loss: 0.6216\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6404 - val_loss: 0.6696\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6511 - val_loss: 0.6521\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9385 - val_loss: 1.9703\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.1885 - val_loss: 0.6364\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6477 - val_loss: 0.6206\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 5.9760 - val_loss: 9.5562\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.8972 - val_loss: 4.7957\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.7369 - val_loss: 0.8397\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.6316\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6800\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7997 - val_loss: 1.0006\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1971 - val_loss: 0.6978\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7699 - val_loss: 0.6225\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0041 - val_loss: 1.0706\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8478 - val_loss: 0.6943\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8586 - val_loss: 0.6145\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6951 - val_loss: 0.6132\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6608 - val_loss: 0.6199\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5386 - val_loss: 0.7399\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6932 - val_loss: 0.6758\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3825 - val_loss: 0.6639\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 0.6998\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6475\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6959 - val_loss: 0.6211\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9244 - val_loss: 0.6378\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7768 - val_loss: 4.1799\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.2423 - val_loss: 1.2755\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.3287 - val_loss: 0.6339\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6284 - val_loss: 0.6116\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8719 - val_loss: 0.6165\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7670 - val_loss: 0.6374\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.6016\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5166 - val_loss: 0.6302\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0222 - val_loss: 0.6308\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6737 - val_loss: 0.6136\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6409 - val_loss: 0.6229\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7126 - val_loss: 1.8192\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9237 - val_loss: 0.8384\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2814 - val_loss: 0.8732\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6706 - val_loss: 0.6046\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7833 - val_loss: 0.6029\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6492 - val_loss: 0.9121\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.6308\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6341 - val_loss: 0.7111\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8881 - val_loss: 0.8865\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6682 - val_loss: 0.6002\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7693 - val_loss: 0.6518\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8068 - val_loss: 0.7327\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6653 - val_loss: 0.6208\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8503 - val_loss: 0.7151\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5268 - val_loss: 0.5945\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.6087 - val_loss: 1.3280\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.4976 - val_loss: 0.6602\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3035 - val_loss: 0.6465\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6341\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6586 - val_loss: 0.8421\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9334 - val_loss: 0.7618\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6991 - val_loss: 1.3913\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.7113 - val_loss: 0.6855\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 7.9959 - val_loss: 0.9278\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6519 - val_loss: 0.6091\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5854 - val_loss: 0.6108\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.6375\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6527 - val_loss: 0.6392\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5914 - val_loss: 0.6094\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 0.7121\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6960 - val_loss: 0.6014\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7969 - val_loss: 0.6504\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6142 - val_loss: 0.6095\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.5972\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5797 - val_loss: 0.5977\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6611 - val_loss: 0.5977\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6183 - val_loss: 0.5959\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6248 - val_loss: 0.6283\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6311\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9969 - val_loss: 0.7612\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9391 - val_loss: 0.6775\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1015 - val_loss: 0.6230\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 1.5349\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9120 - val_loss: 0.6282\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.7443\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9127 - val_loss: 1.2311\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8798 - val_loss: 0.6501\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6670 - val_loss: 0.6463\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.7545\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7469 - val_loss: 0.7022\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6266 - val_loss: 0.6964\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7136 - val_loss: 0.8177\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6344 - val_loss: 0.7194\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7582 - val_loss: 1.3414\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3414 - val_loss: 0.6635\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6218 - val_loss: 1.9308\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8347 - val_loss: 0.9420\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9153 - val_loss: 0.6703\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4868 - val_loss: 0.6308\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6294 - val_loss: 0.7082\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.9347 - val_loss: 1.0826\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7595 - val_loss: 0.6017\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7113 - val_loss: 0.6694\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0869 - val_loss: 0.6640\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6227 - val_loss: 0.6425\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6091\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8904 - val_loss: 0.7049\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1322 - val_loss: 0.6049\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 0.6136\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5953 - val_loss: 0.6548\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4109 - val_loss: 1.4523\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 3.6413 - val_loss: 0.9715\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.2304 - val_loss: 0.5901\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7476 - val_loss: 0.6192\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6170 - val_loss: 6.6021\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4172 - val_loss: 0.7184\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6404 - val_loss: 1.1740\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6806 - val_loss: 0.5874\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6922 - val_loss: 0.6226\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6560\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9653 - val_loss: 0.6494\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6645 - val_loss: 0.6492\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6080 - val_loss: 0.5942\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 0.5870\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6123\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6394 - val_loss: 3.3164\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2312 - val_loss: 0.6877\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6923 - val_loss: 0.5876\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6307 - val_loss: 0.9532\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8599 - val_loss: 0.5989\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.6297\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6634 - val_loss: 0.5972\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5909 - val_loss: 0.5856\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7038 - val_loss: 0.6602\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5858 - val_loss: 0.5941\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6086\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7195 - val_loss: 0.6172\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6058 - val_loss: 1.6276\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 8.1773 - val_loss: 0.6000\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6431\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5924 - val_loss: 0.7080\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6762 - val_loss: 0.5774\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5612 - val_loss: 0.5791\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8843 - val_loss: 0.6871\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8485 - val_loss: 0.8648\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7517 - val_loss: 0.6225\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8008 - val_loss: 0.5913\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7532 - val_loss: 1.0479\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 9.9512 - val_loss: 0.7074\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6900 - val_loss: 0.6213\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6115 - val_loss: 0.6036\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5937 - val_loss: 0.6049\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6312 - val_loss: 0.5984\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.5953\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.5932\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5803 - val_loss: 0.6021\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.6431\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8234 - val_loss: 0.6297\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5827 - val_loss: 1.1185\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8644 - val_loss: 0.6174\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 1.0571\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7252 - val_loss: 0.5835\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 0.7062\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.2112 - val_loss: 0.6261\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.5929\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5604 - val_loss: 0.5778\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5918 - val_loss: 0.6311\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 0.5912\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5602 - val_loss: 0.9622\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2929 - val_loss: 0.6484\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7210 - val_loss: 0.7795\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9182 - val_loss: 1.1950\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4775 - val_loss: 0.9086\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7212 - val_loss: 0.6190\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.6889\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7719 - val_loss: 0.5875\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5543 - val_loss: 0.6342\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6589 - val_loss: 1.1773\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2644 - val_loss: 0.5919\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5621 - val_loss: 0.6566\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5856 - val_loss: 0.5849\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0820 - val_loss: 3.9958\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1655 - val_loss: 0.6461\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.5876\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5827 - val_loss: 0.5815\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6344 - val_loss: 0.5842\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6207 - val_loss: 0.5847\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7711 - val_loss: 0.9180\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9767 - val_loss: 0.6975\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 2.1813\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4554 - val_loss: 0.6215\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6322 - val_loss: 0.6266\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.6150\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.5088 - val_loss: 5.5320\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 2.4985 - val_loss: 1.5796\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7845 - val_loss: 0.6031\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5496 - val_loss: 0.7073\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7956 - val_loss: 0.6231\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6344 - val_loss: 0.5811\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5612 - val_loss: 0.7956\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6776 - val_loss: 0.5828\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.5828\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6423 - val_loss: 0.5982\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 0.5885\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.7633\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.4805 - val_loss: 1.5936\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0099 - val_loss: 0.6195\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5693 - val_loss: 0.5982\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.6072\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5784 - val_loss: 3.4660\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1700 - val_loss: 0.6098\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6092 - val_loss: 0.6199\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 1.3752\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7177 - val_loss: 0.5919\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7705 - val_loss: 0.6055\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6655 - val_loss: 0.6898\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7885 - val_loss: 0.5894\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5732 - val_loss: 0.8011\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.5937\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.6380\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5690 - val_loss: 0.5927\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.8891\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7188 - val_loss: 0.5772\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 4.8450 - val_loss: 0.6287\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5672 - val_loss: 0.6527\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.6185\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5897 - val_loss: 0.6255\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5906 - val_loss: 0.6118\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.6920\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5737 - val_loss: 0.6002\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6483 - val_loss: 0.5918\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6205 - val_loss: 0.6939\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 0.8256\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.5881\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 1.6555\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7978 - val_loss: 0.8804\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6842 - val_loss: 0.8241\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0045 - val_loss: 0.5865\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5403 - val_loss: 0.6985\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7420 - val_loss: 0.6314\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.6161\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5960\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8177 - val_loss: 0.5886\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.5697\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8448 - val_loss: 0.7795\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1475 - val_loss: 0.6389\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7135 - val_loss: 0.6096\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5651 - val_loss: 0.6327\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.5981\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.6379\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5807\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6928 - val_loss: 0.5840\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5716 - val_loss: 2.1008\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2954 - val_loss: 0.6037\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6953\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 0.6223\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6215 - val_loss: 0.5851\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 0.7002\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2004 - val_loss: 1.0267\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7402 - val_loss: 0.7212\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history5 = model5.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 10.7762 - val_loss: 5.2978\n",
      "Epoch 2/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 4.2154 - val_loss: 2.5868\n",
      "Epoch 3/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 2.3950 - val_loss: 1.9923\n",
      "Epoch 4/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.8445 - val_loss: 1.3436\n",
      "Epoch 5/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3989 - val_loss: 1.3184\n",
      "Epoch 6/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3073 - val_loss: 1.3160\n",
      "Epoch 7/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.2956 - val_loss: 1.3152\n",
      "Epoch 8/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3603 - val_loss: 1.3153\n",
      "Epoch 9/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3353 - val_loss: 1.3155\n",
      "Epoch 10/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3340 - val_loss: 1.3157\n",
      "Epoch 11/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3046 - val_loss: 1.3153\n",
      "Epoch 12/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3123 - val_loss: 1.3155\n",
      "Epoch 13/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2698 - val_loss: 1.3153\n",
      "Epoch 14/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3537 - val_loss: 1.3157\n",
      "Epoch 15/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3213 - val_loss: 1.3154\n",
      "Epoch 16/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3174 - val_loss: 1.3155\n",
      "Epoch 17/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3052 - val_loss: 1.3154\n",
      "Epoch 18/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2870 - val_loss: 1.3159\n",
      "Epoch 19/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3089 - val_loss: 1.3156\n",
      "Epoch 20/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3435 - val_loss: 1.3161\n",
      "Epoch 21/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3181 - val_loss: 1.3152\n",
      "Epoch 22/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3530 - val_loss: 1.3152\n",
      "Epoch 23/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3222 - val_loss: 1.3154\n",
      "Epoch 24/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3772 - val_loss: 1.3167\n",
      "Epoch 25/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3216 - val_loss: 1.3162\n",
      "Epoch 26/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3369 - val_loss: 1.3168\n",
      "Epoch 27/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3111 - val_loss: 1.3145\n",
      "Epoch 28/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3068 - val_loss: 1.3149\n",
      "Epoch 29/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3242 - val_loss: 1.3145\n",
      "Epoch 30/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3237 - val_loss: 1.3155\n",
      "Epoch 31/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3648 - val_loss: 1.3165\n",
      "Epoch 32/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.3151\n",
      "Epoch 33/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3470 - val_loss: 1.3145\n",
      "Epoch 34/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3393 - val_loss: 1.3143\n",
      "Epoch 35/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3248 - val_loss: 1.3114\n",
      "Epoch 36/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3100 - val_loss: 1.3120\n",
      "Epoch 37/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3233 - val_loss: 1.3152\n",
      "Epoch 38/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3033 - val_loss: 1.3148\n",
      "Epoch 39/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3390 - val_loss: 1.3142\n",
      "Epoch 40/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2984 - val_loss: 1.3138\n",
      "Epoch 41/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3192 - val_loss: 1.3130\n",
      "Epoch 42/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3274 - val_loss: 1.3125\n",
      "Epoch 43/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2884 - val_loss: 1.3131\n",
      "Epoch 44/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3099 - val_loss: 1.3135\n",
      "Epoch 45/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3439 - val_loss: 1.3107\n",
      "Epoch 46/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2955 - val_loss: 1.3079\n",
      "Epoch 47/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3193 - val_loss: 1.3152\n",
      "Epoch 48/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3171 - val_loss: 1.3096\n",
      "Epoch 49/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3317 - val_loss: 1.3090\n",
      "Epoch 50/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3214 - val_loss: 1.3071\n",
      "Epoch 51/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3564 - val_loss: 1.3094\n",
      "Epoch 52/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2653 - val_loss: 1.3048\n",
      "Epoch 53/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3057 - val_loss: 1.3062\n",
      "Epoch 54/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3610 - val_loss: 1.3030\n",
      "Epoch 55/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3145 - val_loss: 1.3041\n",
      "Epoch 56/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3209 - val_loss: 1.3149\n",
      "Epoch 57/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3462 - val_loss: 1.3172\n",
      "Epoch 58/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3253 - val_loss: 1.3139\n",
      "Epoch 59/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3481 - val_loss: 1.3142\n",
      "Epoch 60/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3067 - val_loss: 1.3143\n",
      "Epoch 61/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3124\n",
      "Epoch 62/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3248 - val_loss: 1.3126\n",
      "Epoch 63/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3344 - val_loss: 1.3115\n",
      "Epoch 64/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 1.3116\n",
      "Epoch 65/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3537 - val_loss: 1.3110\n",
      "Epoch 66/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3238 - val_loss: 1.3114\n",
      "Epoch 67/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3219 - val_loss: 1.3092\n",
      "Epoch 68/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3665 - val_loss: 1.3103\n",
      "Epoch 69/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3875 - val_loss: 1.3135\n",
      "Epoch 70/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3184 - val_loss: 1.3098\n",
      "Epoch 71/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3052 - val_loss: 1.3064\n",
      "Epoch 72/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3028\n",
      "Epoch 73/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3442 - val_loss: 1.3152\n",
      "Epoch 74/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3222 - val_loss: 1.3132\n",
      "Epoch 75/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2922 - val_loss: 1.3581\n",
      "Epoch 76/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3140 - val_loss: 1.3154\n",
      "Epoch 77/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2959 - val_loss: 1.3098\n",
      "Epoch 78/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3154 - val_loss: 1.2953\n",
      "Epoch 79/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.2260 - val_loss: 1.1038\n",
      "Epoch 80/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1902 - val_loss: 1.3084\n",
      "Epoch 81/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.3128 - val_loss: 1.1403\n",
      "Epoch 82/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1161 - val_loss: 1.0982\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 1.0501 - val_loss: 1.1977\n",
      "Epoch 84/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 1.1980 - val_loss: 0.9357\n",
      "Epoch 85/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.9265 - val_loss: 0.9938\n",
      "Epoch 86/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8818 - val_loss: 0.8813\n",
      "Epoch 87/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8009 - val_loss: 0.7573\n",
      "Epoch 88/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8419 - val_loss: 0.7307\n",
      "Epoch 89/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8021 - val_loss: 0.9114\n",
      "Epoch 90/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.8061 - val_loss: 0.7074\n",
      "Epoch 91/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7491 - val_loss: 0.8726\n",
      "Epoch 92/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7937 - val_loss: 0.7038\n",
      "Epoch 93/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7423 - val_loss: 0.7301\n",
      "Epoch 94/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7336 - val_loss: 0.7529\n",
      "Epoch 95/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7166 - val_loss: 0.6659\n",
      "Epoch 96/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6796 - val_loss: 0.9048\n",
      "Epoch 97/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7599 - val_loss: 0.6708\n",
      "Epoch 98/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6955 - val_loss: 0.6579\n",
      "Epoch 99/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7812 - val_loss: 0.6881\n",
      "Epoch 100/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.7108 - val_loss: 0.6521\n",
      "Epoch 101/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6504 - val_loss: 0.8412\n",
      "Epoch 102/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.7590\n",
      "Epoch 103/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6851 - val_loss: 0.6971\n",
      "Epoch 104/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6971 - val_loss: 0.7112\n",
      "Epoch 105/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6695 - val_loss: 0.7198\n",
      "Epoch 106/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6406 - val_loss: 0.6090\n",
      "Epoch 107/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6638 - val_loss: 0.6022\n",
      "Epoch 108/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6904 - val_loss: 0.7937\n",
      "Epoch 109/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.7017 - val_loss: 0.7007\n",
      "Epoch 110/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6634 - val_loss: 0.6505\n",
      "Epoch 111/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.5838\n",
      "Epoch 112/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 0.6548\n",
      "Epoch 113/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6774 - val_loss: 0.5863\n",
      "Epoch 114/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.5781\n",
      "Epoch 115/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6039 - val_loss: 0.6060\n",
      "Epoch 116/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6237\n",
      "Epoch 117/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.6357\n",
      "Epoch 118/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.5844\n",
      "Epoch 119/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6223 - val_loss: 0.6274\n",
      "Epoch 120/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6045 - val_loss: 0.5847\n",
      "Epoch 121/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5677 - val_loss: 0.6286\n",
      "Epoch 122/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5611\n",
      "Epoch 123/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.6023\n",
      "Epoch 124/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.7184\n",
      "Epoch 125/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6469 - val_loss: 0.5617\n",
      "Epoch 126/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6913 - val_loss: 0.5743\n",
      "Epoch 127/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5816 - val_loss: 0.5590\n",
      "Epoch 128/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5776\n",
      "Epoch 129/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 0.5650\n",
      "Epoch 130/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6369 - val_loss: 0.6635\n",
      "Epoch 131/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.5589\n",
      "Epoch 132/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6011 - val_loss: 0.5593\n",
      "Epoch 133/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.6874\n",
      "Epoch 134/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5690 - val_loss: 0.5499\n",
      "Epoch 135/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5619\n",
      "Epoch 136/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6220 - val_loss: 0.6053\n",
      "Epoch 137/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5868 - val_loss: 0.5429\n",
      "Epoch 138/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.5724\n",
      "Epoch 139/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6249 - val_loss: 0.5395\n",
      "Epoch 140/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.5492\n",
      "Epoch 141/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.6029\n",
      "Epoch 142/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5903 - val_loss: 0.5304\n",
      "Epoch 143/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 0.5376\n",
      "Epoch 144/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6493 - val_loss: 0.5519\n",
      "Epoch 145/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5861 - val_loss: 0.7140\n",
      "Epoch 146/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.6247 - val_loss: 0.5940\n",
      "Epoch 147/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5645 - val_loss: 0.6009\n",
      "Epoch 148/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5758 - val_loss: 0.5742\n",
      "Epoch 149/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5701 - val_loss: 0.5531\n",
      "Epoch 150/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5447 - val_loss: 0.5279\n",
      "Epoch 151/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5154 - val_loss: 0.5819\n",
      "Epoch 152/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5601 - val_loss: 0.7322\n",
      "Epoch 153/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6561\n",
      "Epoch 154/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6281 - val_loss: 0.5298\n",
      "Epoch 155/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5192 - val_loss: 0.5508\n",
      "Epoch 156/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5513 - val_loss: 0.5526\n",
      "Epoch 157/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5578\n",
      "Epoch 158/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6045 - val_loss: 0.6002\n",
      "Epoch 159/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.6053 - val_loss: 0.5312\n",
      "Epoch 160/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.5393\n",
      "Epoch 161/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.5548\n",
      "Epoch 162/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.5764\n",
      "Epoch 163/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5665 - val_loss: 0.5479\n",
      "Epoch 164/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5179 - val_loss: 0.6269\n",
      "Epoch 165/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5794 - val_loss: 0.5342\n",
      "Epoch 166/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.5912\n",
      "Epoch 167/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5530 - val_loss: 0.5283\n",
      "Epoch 168/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5176\n",
      "Epoch 169/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5774\n",
      "Epoch 170/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5530\n",
      "Epoch 171/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5157\n",
      "Epoch 172/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5219\n",
      "Epoch 173/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5707 - val_loss: 0.6198\n",
      "Epoch 174/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5649\n",
      "Epoch 175/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5162 - val_loss: 0.5553\n",
      "Epoch 176/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5284 - val_loss: 0.6352\n",
      "Epoch 177/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5251\n",
      "Epoch 178/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5917\n",
      "Epoch 179/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.5284\n",
      "Epoch 180/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5208\n",
      "Epoch 181/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5506 - val_loss: 0.5424\n",
      "Epoch 182/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5332 - val_loss: 0.5397\n",
      "Epoch 183/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5118 - val_loss: 0.5116\n",
      "Epoch 184/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5090 - val_loss: 0.5134\n",
      "Epoch 185/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 0.5212\n",
      "Epoch 186/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.7240\n",
      "Epoch 187/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5697 - val_loss: 0.5469\n",
      "Epoch 188/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5648 - val_loss: 0.5491\n",
      "Epoch 189/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5242 - val_loss: 0.5611\n",
      "Epoch 190/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5526 - val_loss: 0.5057\n",
      "Epoch 191/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.6672\n",
      "Epoch 192/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.5367\n",
      "Epoch 193/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5052\n",
      "Epoch 194/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.6024\n",
      "Epoch 195/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5798 - val_loss: 0.5088\n",
      "Epoch 196/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5071\n",
      "Epoch 197/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5172 - val_loss: 0.5296\n",
      "Epoch 198/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5236 - val_loss: 0.5808\n",
      "Epoch 199/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.5093\n",
      "Epoch 200/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.5088\n",
      "Epoch 201/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5589\n",
      "Epoch 202/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5816 - val_loss: 0.5073\n",
      "Epoch 203/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5310\n",
      "Epoch 204/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5139 - val_loss: 0.6240\n",
      "Epoch 205/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5543 - val_loss: 0.5107\n",
      "Epoch 206/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.5629\n",
      "Epoch 207/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5023 - val_loss: 0.7010\n",
      "Epoch 208/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5086\n",
      "Epoch 209/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.4997\n",
      "Epoch 210/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5258\n",
      "Epoch 211/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5406 - val_loss: 0.5192\n",
      "Epoch 212/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5630 - val_loss: 0.5847\n",
      "Epoch 213/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5008 - val_loss: 0.4995\n",
      "Epoch 214/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4872 - val_loss: 0.5159\n",
      "Epoch 215/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.5925\n",
      "Epoch 216/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5539 - val_loss: 0.5144\n",
      "Epoch 217/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.5002\n",
      "Epoch 218/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5037\n",
      "Epoch 219/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5096 - val_loss: 0.5230\n",
      "Epoch 220/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.5434\n",
      "Epoch 221/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5445 - val_loss: 0.5639\n",
      "Epoch 222/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.5376\n",
      "Epoch 223/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5109 - val_loss: 0.5081\n",
      "Epoch 224/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5049 - val_loss: 0.5054\n",
      "Epoch 225/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.7506\n",
      "Epoch 226/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5755\n",
      "Epoch 227/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5135 - val_loss: 0.5372\n",
      "Epoch 228/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5008 - val_loss: 0.5445\n",
      "Epoch 229/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.5089\n",
      "Epoch 230/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5203\n",
      "Epoch 231/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5135\n",
      "Epoch 232/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.5311\n",
      "Epoch 233/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5157 - val_loss: 0.5691\n",
      "Epoch 234/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.4940\n",
      "Epoch 235/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4958 - val_loss: 0.5149\n",
      "Epoch 236/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5216 - val_loss: 0.5060\n",
      "Epoch 237/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5076\n",
      "Epoch 238/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.7185\n",
      "Epoch 239/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.5017\n",
      "Epoch 240/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.5413\n",
      "Epoch 241/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.5054\n",
      "Epoch 242/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.4907\n",
      "Epoch 243/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5967\n",
      "Epoch 244/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 0.5038\n",
      "Epoch 245/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5241\n",
      "Epoch 246/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4948 - val_loss: 0.5179\n",
      "Epoch 247/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5040\n",
      "Epoch 248/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4986 - val_loss: 0.4924\n",
      "Epoch 249/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.6121\n",
      "Epoch 250/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.5024\n",
      "Epoch 251/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.5356\n",
      "Epoch 252/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5096\n",
      "Epoch 253/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.4992\n",
      "Epoch 254/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5041 - val_loss: 0.5081\n",
      "Epoch 255/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.5494\n",
      "Epoch 256/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5080\n",
      "Epoch 257/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.6003\n",
      "Epoch 258/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5476\n",
      "Epoch 259/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5423\n",
      "Epoch 260/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5121 - val_loss: 0.5442\n",
      "Epoch 261/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4870 - val_loss: 0.5467\n",
      "Epoch 262/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.4919\n",
      "Epoch 263/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5073\n",
      "Epoch 264/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5009 - val_loss: 0.5822\n",
      "Epoch 265/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.4936\n",
      "Epoch 266/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.5492\n",
      "Epoch 267/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5481\n",
      "Epoch 268/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5018 - val_loss: 0.4955\n",
      "Epoch 269/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.5243\n",
      "Epoch 270/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5162 - val_loss: 0.5143\n",
      "Epoch 271/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.5316\n",
      "Epoch 272/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5580\n",
      "Epoch 273/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.4961\n",
      "Epoch 274/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.6774\n",
      "Epoch 275/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.4923\n",
      "Epoch 276/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5211 - val_loss: 0.5027\n",
      "Epoch 277/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4964\n",
      "Epoch 278/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.4891\n",
      "Epoch 279/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.5133\n",
      "Epoch 280/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5450 - val_loss: 0.6679\n",
      "Epoch 281/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5527 - val_loss: 0.4986\n",
      "Epoch 282/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4903 - val_loss: 0.5000\n",
      "Epoch 283/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.4922\n",
      "Epoch 284/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4969 - val_loss: 0.5269\n",
      "Epoch 285/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5010\n",
      "Epoch 286/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5830\n",
      "Epoch 287/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.5074\n",
      "Epoch 288/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 0.5150\n",
      "Epoch 289/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 0.4965\n",
      "Epoch 290/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 0.5240\n",
      "Epoch 291/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4900 - val_loss: 0.4967\n",
      "Epoch 292/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.5013\n",
      "Epoch 293/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.4986\n",
      "Epoch 294/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.5132\n",
      "Epoch 295/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4903 - val_loss: 0.4885\n",
      "Epoch 296/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4977 - val_loss: 0.5441\n",
      "Epoch 297/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5139\n",
      "Epoch 298/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5059\n",
      "Epoch 299/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5075 - val_loss: 0.5088\n",
      "Epoch 300/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.5144\n",
      "Epoch 301/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4916 - val_loss: 0.4859\n",
      "Epoch 302/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.5030\n",
      "Epoch 303/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4932 - val_loss: 0.4891\n",
      "Epoch 304/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4717 - val_loss: 0.4992\n",
      "Epoch 305/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4817 - val_loss: 0.5194\n",
      "Epoch 306/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5016 - val_loss: 0.4833\n",
      "Epoch 307/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.5925\n",
      "Epoch 308/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.4800\n",
      "Epoch 309/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5357\n",
      "Epoch 310/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4911\n",
      "Epoch 311/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.4784\n",
      "Epoch 312/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.4776\n",
      "Epoch 313/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4835\n",
      "Epoch 314/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.5046\n",
      "Epoch 315/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.5396\n",
      "Epoch 316/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5137\n",
      "Epoch 317/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4765\n",
      "Epoch 318/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.6515\n",
      "Epoch 319/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.4778\n",
      "Epoch 320/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.5227\n",
      "Epoch 321/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.4823\n",
      "Epoch 322/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.5014\n",
      "Epoch 323/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.4880\n",
      "Epoch 324/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4838\n",
      "Epoch 325/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.5135\n",
      "Epoch 326/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4713 - val_loss: 0.4832\n",
      "Epoch 327/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4769\n",
      "Epoch 328/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4990\n",
      "Epoch 329/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4889\n",
      "Epoch 330/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4833 - val_loss: 0.4947\n",
      "Epoch 331/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4787 - val_loss: 0.5340\n",
      "Epoch 332/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.4887\n",
      "Epoch 333/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4953\n",
      "Epoch 334/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4880 - val_loss: 0.4840\n",
      "Epoch 335/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.5076\n",
      "Epoch 336/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.5213\n",
      "Epoch 337/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5229\n",
      "Epoch 338/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.5306\n",
      "Epoch 339/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.4823\n",
      "Epoch 340/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.5864\n",
      "Epoch 341/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.5191\n",
      "Epoch 342/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4889\n",
      "Epoch 343/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.5095\n",
      "Epoch 344/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4759\n",
      "Epoch 345/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4991\n",
      "Epoch 346/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4856\n",
      "Epoch 347/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4793 - val_loss: 0.4958\n",
      "Epoch 348/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4838 - val_loss: 0.5195\n",
      "Epoch 349/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.4855\n",
      "Epoch 350/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4837\n",
      "Epoch 351/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5361\n",
      "Epoch 352/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5279\n",
      "Epoch 353/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4943 - val_loss: 0.4758\n",
      "Epoch 354/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.4783\n",
      "Epoch 355/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.4810\n",
      "Epoch 356/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.4760\n",
      "Epoch 357/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6006\n",
      "Epoch 358/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.4744\n",
      "Epoch 359/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5419\n",
      "Epoch 360/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4776\n",
      "Epoch 361/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.4913\n",
      "Epoch 362/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.4812\n",
      "Epoch 363/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.4922\n",
      "Epoch 364/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.4916\n",
      "Epoch 365/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5252\n",
      "Epoch 366/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.4947\n",
      "Epoch 367/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.4856\n",
      "Epoch 368/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4921\n",
      "Epoch 369/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.4885\n",
      "Epoch 370/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.4884\n",
      "Epoch 371/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4818\n",
      "Epoch 372/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4941\n",
      "Epoch 373/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.4886\n",
      "Epoch 374/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.5106\n",
      "Epoch 375/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5268\n",
      "Epoch 376/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.5911\n",
      "Epoch 377/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.4866\n",
      "Epoch 378/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.5154\n",
      "Epoch 379/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.5478\n",
      "Epoch 380/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5164 - val_loss: 0.5122\n",
      "Epoch 381/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4827\n",
      "Epoch 382/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4846\n",
      "Epoch 383/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4817\n",
      "Epoch 384/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4858\n",
      "Epoch 385/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4704 - val_loss: 0.4854\n",
      "Epoch 386/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.4887\n",
      "Epoch 387/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.5122\n",
      "Epoch 388/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.6560\n",
      "Epoch 389/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.4844\n",
      "Epoch 390/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4786\n",
      "Epoch 391/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.5089\n",
      "Epoch 392/400\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.4762\n",
      "Epoch 393/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.5089\n",
      "Epoch 394/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.4823\n",
      "Epoch 395/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.5080\n",
      "Epoch 396/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4817 - val_loss: 0.5323\n",
      "Epoch 397/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.5552\n",
      "Epoch 398/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.5826\n",
      "Epoch 399/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4685 - val_loss: 0.4855\n",
      "Epoch 400/400\n",
      "65/65 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4835\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(seed_value)\n",
    "history6 = model6.fit(x=X_train,y=Y_train,\n",
    "          validation_data=(X_valid,Y_valid),\n",
    "          batch_size=128,epochs=400)\n",
    "#model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,041\n",
      "Trainable params: 1,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "model2.summary()\n",
    "model3.summary()\n",
    "model4.summary()\n",
    "model5.summary()\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_score</th>\n",
       "      <th>Hidden_layer</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>activation_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.613045</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>-0.0105236</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu, sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>-1.78577e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh, softmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>0.476374</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>0.451142</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu,relu,relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.632006</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu,relu,sigmoid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2_score  Hidden_layer  Learning_rate      activation_fn\n",
       "model_1     0.613045             2         0.0100          relu,relu\n",
       "model_2   -0.0105236             2         0.0100      relu, sigmoid\n",
       "model_3 -1.78577e-06             2         0.0100      tanh, softmax\n",
       "model_4     0.476374             2         0.0001          relu,relu\n",
       "model_5     0.451142             3         0.0010     relu,relu,relu\n",
       "model_6     0.632006             3         0.0010  relu,relu,sigmoid"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r2_score of six models with different parameter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "col = ['R2_score'] \n",
    "ind = ['model_%.0g'%i for i in range(1,7)]\n",
    "summary1 = pd.DataFrame(index=ind, columns=col) #summary table\n",
    "\n",
    "j = 0\n",
    "for i in [model1,model2,model3,model4,model5,model6]: \n",
    "    y_predv = i.predict(X_valid)\n",
    "    summary1.iloc[j,0] = r2_score(Y_valid, y_predv) #R2_score when applying on validation set\n",
    "    j = j+1\n",
    "summary1\n",
    "\n",
    "#Details of each models\n",
    "des = {'Hidden_layer': [2, 2,2,2,3,3], 'Learning_rate': [0.01, 0.01, 0.01, 0.0001,0.001,0.001], 'activation_fn': ['relu,relu', 'relu, sigmoid','tanh, softmax','relu,relu','relu,relu,relu', 'relu,relu,sigmoid'] }\n",
    "desdf = pd.DataFrame(des, index=ind)\n",
    "\n",
    "#Combine two tables (performance and Details of each models)\n",
    "summaryfinal = pd.concat([summary1 ,desdf], axis = 1 )\n",
    "\n",
    "summaryfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>0.605324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>0.637659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         R2_score\n",
       "model_1  0.605324\n",
       "model_6  0.637659"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################Step 3 Apply the model on testing set#############################\n",
    "col = ['R2_score']\n",
    "ind = ['model_%.0g'%i for i in [1,6]]\n",
    "summary2 = pd.DataFrame(index=ind, columns=col)\n",
    "\n",
    "j = 0\n",
    "for i in [model1,model6]:\n",
    "    y_pred = i.predict(X_test) #applying models on testing set\n",
    "    summary2.iloc[j,0] = r2_score(Y_test, y_pred) #R2_score when applying on testing set\n",
    "    j = j+1\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Step 4 Analyze the testing results #############################\n",
    "Y_pred6 = model6.predict(X_test)\n",
    "error = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    errors = abs(Y_pred6[i,0]- Y_test[i])  #Calucate absolute value of error\n",
    "    error.append(errors )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary3 = pd.DataFrame(\n",
    "{'Y_value': Y_test,\n",
    " 'Y_hat': Y_pred6[:,0], \n",
    " 'abs(error)': error  # Calucate absolute value of error\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ind2 = ['feature_%.0g'%i for i in [1,6]]\n",
    "X_testdf = pd.DataFrame(X_test, columns= ca_house_db.feature_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([summary3 ,X_testdf], axis = 1 ) #merge data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top  = total.sort_values(by='abs(error)', ascending=False).head(10) #sorting the dataframe following to abs of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average/Meadian/max/min of each features.\n",
    "\n",
    "avg = pd.DataFrame(total.mean(axis = 0)).T #mean\n",
    "med = pd.DataFrame(total.median(axis = 0)).T \n",
    "maxs = pd.DataFrame(total.max(axis = 0)).T \n",
    "mins = pd.DataFrame(total.min(axis = 0)).T\n",
    "top.loc[\"mean_sample\",:] = avg.iloc[0,:] \n",
    "top.loc[\"median_sample\",:] = med.iloc[0,:] \n",
    "top.loc[\"max_sample\",:] = maxs.iloc[0,:]\n",
    "top.loc[\"mins_sample\",:] = mins.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_value</th>\n",
       "      <th>Y_hat</th>\n",
       "      <th>abs(error)</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.039630</td>\n",
       "      <td>3.960380</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.373272</td>\n",
       "      <td>1.055300</td>\n",
       "      <td>2690.000000</td>\n",
       "      <td>12.396313</td>\n",
       "      <td>34.020000</td>\n",
       "      <td>-118.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.039669</td>\n",
       "      <td>3.960341</td>\n",
       "      <td>1.169600</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.436000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>1349.000000</td>\n",
       "      <td>5.396000</td>\n",
       "      <td>37.870000</td>\n",
       "      <td>-122.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.052026</td>\n",
       "      <td>3.947984</td>\n",
       "      <td>4.203900</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.753927</td>\n",
       "      <td>1.031414</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>4.612565</td>\n",
       "      <td>37.190000</td>\n",
       "      <td>-121.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.057751</td>\n",
       "      <td>3.942259</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.425197</td>\n",
       "      <td>1.125984</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>2.833071</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>-120.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.268373</td>\n",
       "      <td>3.731637</td>\n",
       "      <td>1.166700</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2.477477</td>\n",
       "      <td>1.108108</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>2.459459</td>\n",
       "      <td>34.150000</td>\n",
       "      <td>-118.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.381632</td>\n",
       "      <td>3.618378</td>\n",
       "      <td>4.975700</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.049608</td>\n",
       "      <td>1.101828</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>5.208877</td>\n",
       "      <td>34.470000</td>\n",
       "      <td>-119.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>1.125000</td>\n",
       "      <td>4.739896</td>\n",
       "      <td>3.614896</td>\n",
       "      <td>12.538100</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>6.888889</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>33.960000</td>\n",
       "      <td>-117.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8325</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.454921</td>\n",
       "      <td>3.545089</td>\n",
       "      <td>0.854300</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.297872</td>\n",
       "      <td>1.175532</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1.610372</td>\n",
       "      <td>37.780000</td>\n",
       "      <td>-122.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.499581</td>\n",
       "      <td>3.500419</td>\n",
       "      <td>2.353600</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.826563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>3.973438</td>\n",
       "      <td>34.050000</td>\n",
       "      <td>-118.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>1.509808</td>\n",
       "      <td>3.490202</td>\n",
       "      <td>4.238600</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.723077</td>\n",
       "      <td>1.169231</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>3.507692</td>\n",
       "      <td>33.830000</td>\n",
       "      <td>-117.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_sample</th>\n",
       "      <td>2.066012</td>\n",
       "      <td>2.135081</td>\n",
       "      <td>0.520458</td>\n",
       "      <td>3.871337</td>\n",
       "      <td>28.619864</td>\n",
       "      <td>5.445038</td>\n",
       "      <td>1.099305</td>\n",
       "      <td>1422.299612</td>\n",
       "      <td>3.113793</td>\n",
       "      <td>35.632167</td>\n",
       "      <td>-119.565215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_sample</th>\n",
       "      <td>1.785000</td>\n",
       "      <td>1.860168</td>\n",
       "      <td>0.410110</td>\n",
       "      <td>3.522700</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.236540</td>\n",
       "      <td>1.047404</td>\n",
       "      <td>1165.000000</td>\n",
       "      <td>2.823360</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_sample</th>\n",
       "      <td>5.000010</td>\n",
       "      <td>4.750894</td>\n",
       "      <td>3.960380</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>25.636364</td>\n",
       "      <td>28566.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mins_sample</th>\n",
       "      <td>0.149990</td>\n",
       "      <td>-0.276588</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y_value     Y_hat  abs(error)     MedInc   HouseAge  \\\n",
       "1902           5.000010  1.039630    3.960380   0.499900  29.000000   \n",
       "7378           5.000010  1.039669    3.960341   1.169600  52.000000   \n",
       "5291           5.000010  1.052026    3.947984   4.203900  11.000000   \n",
       "2781           5.000010  1.057751    3.942259   0.702500  19.000000   \n",
       "8438           5.000010  1.268373    3.731637   1.166700  52.000000   \n",
       "6857           5.000010  1.381632    3.618378   4.975700  35.000000   \n",
       "4604           1.125000  4.739896    3.614896  12.538100  29.000000   \n",
       "8325           5.000010  1.454921    3.545089   0.854300  27.000000   \n",
       "4739           5.000000  1.499581    3.500419   2.353600  26.000000   \n",
       "4128           5.000010  1.509808    3.490202   4.238600   6.000000   \n",
       "mean_sample    2.066012  2.135081    0.520458   3.871337  28.619864   \n",
       "median_sample  1.785000  1.860168    0.410110   3.522700  29.000000   \n",
       "max_sample     5.000010  4.750894    3.960380  15.000100  52.000000   \n",
       "mins_sample    0.149990 -0.276588    0.000213   0.499900   1.000000   \n",
       "\n",
       "                 AveRooms  AveBedrms    Population     AveOccup   Latitude  \\\n",
       "1902             2.373272   1.055300   2690.000000    12.396313  34.020000   \n",
       "7378             2.436000   0.944000   1349.000000     5.396000  37.870000   \n",
       "5291             6.753927   1.031414    881.000000     4.612565  37.190000   \n",
       "2781             2.425197   1.125984   1799.000000     2.833071  35.300000   \n",
       "8438             2.477477   1.108108    273.000000     2.459459  34.150000   \n",
       "6857             7.049608   1.101828   1995.000000     5.208877  34.470000   \n",
       "4604             6.888889   1.222222     50.000000     2.777778  33.960000   \n",
       "8325             2.297872   1.175532   1211.000000     1.610372  37.780000   \n",
       "4739             2.826563   1.000000   2543.000000     3.973438  34.050000   \n",
       "4128             7.723077   1.169231    228.000000     3.507692  33.830000   \n",
       "mean_sample      5.445038   1.099305   1422.299612     3.113793  35.632167   \n",
       "median_sample    5.236540   1.047404   1165.000000     2.823360  34.260000   \n",
       "max_sample     141.909091  25.636364  28566.000000  1243.333333  41.950000   \n",
       "mins_sample      0.846154   0.375000      5.000000     0.692308  32.540000   \n",
       "\n",
       "                Longitude  \n",
       "1902          -118.280000  \n",
       "7378          -122.250000  \n",
       "5291          -121.740000  \n",
       "2781          -120.670000  \n",
       "8438          -118.150000  \n",
       "6857          -119.670000  \n",
       "4604          -117.440000  \n",
       "8325          -122.420000  \n",
       "4739          -118.310000  \n",
       "4128          -117.550000  \n",
       "mean_sample   -119.565215  \n",
       "median_sample -118.510000  \n",
       "max_sample    -114.490000  \n",
       "mins_sample   -124.300000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############End Part4############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.mean(axis = 0).shape\n",
    "df.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanv = total.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.mean(axis = 0).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from compiler.ast import flatten\n",
    "avg = pd.DataFrame(total.mean(axis = 0)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model1.evaluate(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict  = history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(Y_test, y_pred))  \n",
    "print('MSE:', metrics.mean_squared_error(Y_test, y_pred))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))\n",
    "print('r2_score', r2_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss_df1 = pd.DataFrame(model1.history.history)\n",
    "\n",
    "\n",
    "#loss_df1.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "plot_loss(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
